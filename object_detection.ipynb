{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZFk5Vz-zGrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/workspace/ /content/drive/My\\ Drive/tomNjerry_Object_Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ox5gbq1Tb5k",
        "colab_type": "code",
        "outputId": "35ce0dbb-3755-46f3-9607-754dfdb5f737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu==1.14\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (46.3.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIV4jcaSzRhj",
        "colab_type": "code",
        "outputId": "7fdbfacf-cc97-45a3-f999-8680bc61632c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget --header=\"Host: codeload.github.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\" --header=\"Cookie: _octo=GH1.1.853478378.1589687926; logged_in=no; _ga=GA1.2.378810805.1589687926; _gat=1; tz=Asia%2FCalcutta\" --header=\"Connection: keep-alive\" \"https://codeload.github.com/tensorflow/models/zip/r1.13.0\" -c -O 'models-r1.13.0.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-17 04:03:55--  https://codeload.github.com/tensorflow/models/zip/r1.13.0\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘models-r1.13.0.zip’\n",
            "\n",
            "models-r1.13.0.zip      [      <=>           ] 420.44M  15.3MB/s    in 25s     \n",
            "\n",
            "2020-05-17 04:04:20 (17.0 MB/s) - ‘models-r1.13.0.zip’ saved [440860285]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkZve04PzTXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/models-r1.13.0.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvJ81N5Dz0lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoS_hVaU4s1N",
        "colab_type": "code",
        "outputId": "38137739-4af0-420d-9efa-49217cb45b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models-r1.13.0/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models-r1.13.0/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0e2AKtL5JEL",
        "colab_type": "code",
        "outputId": "09f448e6-cddb-43a4-c612-50db4ae796bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%cd /content/models-r1.13.0/research\n",
        "!pip install ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models-r1.13.0/research\n",
            "Processing /content/models-r1.13.0/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.1)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.17)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=801476 sha256=345d355b86496f62ccc312c7efce7b9a20fb5e7f0499cc80a2ff0313f230fa57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ottxyrmc/wheels/0b/9f/3b/ec3e38f35d2fdd8763f762413380303c71b5604ba0491b6caf\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FIk3f76J7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.makedirs('/content/workspace/training_demo/training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt6vrPgh9DxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import glob\n",
        "lst = glob.glob('/content/drive/My Drive/tomjerry/images/train/*')\n",
        "for i in lst:\n",
        "  shutil.copy(i, '/content/workspace/training_demo/images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfD2EITA7p2h",
        "colab_type": "code",
        "outputId": "0e724c25-67d5-4448-de9e-201218a6d984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/workspace/\n",
        "!python partition_dataset.py -x -i training_demo/images -r 0.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRigTqj0874E",
        "colab_type": "code",
        "outputId": "44998592-e7fa-4779-a290-78f3d3971975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/scripts/preprocessing/\n",
        "!python xml_to_csv.py -i /content/workspace/training_demo/images/train -o /content/workspace/training_demo/annotations/train_labels.csv\n",
        "\n",
        "# Create test data:\n",
        "!python xml_to_csv.py -i /content/workspace/training_demo/images/test -o /content/workspace/training_demo/annotations/test_labels.csv\n",
        "\n",
        "# For example\n",
        "# python xml_to_csv.py -i C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\images\\train -o C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\train_labels.csv\n",
        "# python xml_to_csv.py -i C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\images\\test -o C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\test_labels.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/scripts/preprocessing\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MFB7vxfCYyU",
        "colab_type": "code",
        "outputId": "6bf14225-a07b-4fd8-99c1-8cc04005b548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%cd /content/scripts/preprocessing/\n",
        "!python generate_tfrecord.py --label=[tom,jerry] --csv_input=/content/workspace/training_demo/annotations/train_labels.csv --img_path=/content/workspace/training_demo/images/train  --output_path=/content/workspace/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py --label=[tom,jerry] --csv_input=/content/workspace/training_demo/annotations/test_labels.csv --img_path=/content/workspace/training_demo/images/test --output_path=/content/workspace/training_demo/annotations/test.record\n",
        "\n",
        "# For example\n",
        "# python generate_tfrecord.py --label=ship --csv_input=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\train_labels.csv --output_path=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\train.record --img_path=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\images\\train\n",
        "# python generate_tfrecord.py --label=ship --csv_input=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\test_labels.csv --output_path=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\annotations\\test.record --img_path=C:\\Users\\sglvladi\\Documents\\TensorFlow\\workspace\\training_demo\\images\\test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/scripts/preprocessing\n",
            "2020-05-17 05:49:12.214019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/workspace/training_demo/annotations/train.record\n",
            "2020-05-17 05:49:15.943597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/workspace/training_demo/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHeW4xBLIXA0",
        "colab_type": "code",
        "outputId": "9fe54de5-efbe-49b7-8771-3bce8462e074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd /content/\n",
        "!wget --header=\"Host: download.tensorflow.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\" -c -O 'ssd_inception_v2_coco_2018_01_28.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-05-17 08:23:52--  http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.5.240, 2607:f8b0:4004:803::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.5.240|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278114232 (265M) [application/x-tar]\n",
            "Saving to: ‘ssd_inception_v2_coco_2018_01_28.tar.gz’\n",
            "\n",
            "ssd_inception_v2_co 100%[===================>] 265.23M   285MB/s    in 0.9s    \n",
            "\n",
            "2020-05-17 08:23:53 (285 MB/s) - ‘ssd_inception_v2_coco_2018_01_28.tar.gz’ saved [278114232/278114232]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOo2QvzvNBDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf ssd_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNG-pPtHNi5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/ssd_inception_v2_coco_2018_01_28/saved_model/ /content/workspace/training_demo/pre-trained-model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBUdwWyMOHqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/ssd_inception_v2_coco_2018_01_28/checkpoint /content/workspace/training_demo/pre-trained-model/\n",
        "!cp /content/ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb /content/workspace/training_demo/pre-trained-model/\n",
        "!cp /content/ssd_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001 /content/workspace/training_demo/pre-trained-model/\n",
        "!cp /content/ssd_inception_v2_coco_2018_01_28/model.ckpt.index /content/workspace/training_demo/pre-trained-model/\n",
        "!cp /content/ssd_inception_v2_coco_2018_01_28/model.ckpt.meta /content/workspace/training_demo/pre-trained-model/\n",
        "!cp /content/ssd_inception_v2_coco_2018_01_28/pipeline.config /content/workspace/training_demo/pre-trained-model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvhU4G7PG_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/models-r1.13.0/research/object_detection/legacy/train.py /content/workspace/training_demo/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEZK75yfTTt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/models-r1.13.0/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHxrRu_NSSHH",
        "colab_type": "code",
        "outputId": "f1906d80-a9ef-40e2-867f-12d9797ba29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/workspace/training_demo\n",
        "!python train.py --logtostderr --train_dir=/content/workspace/training_demo/training --pipeline_config_path=/content/workspace/training_demo/training/ssd_inception_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "I0517 09:42:11.363179 139851376510848 learning.py:507] global step 6109: loss = 2.7327 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6110: loss = 1.5909 (0.567 sec/step)\n",
            "I0517 09:42:11.931561 139851376510848 learning.py:507] global step 6110: loss = 1.5909 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6111: loss = 1.7126 (0.564 sec/step)\n",
            "I0517 09:42:12.497447 139851376510848 learning.py:507] global step 6111: loss = 1.7126 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6112: loss = 2.2342 (0.605 sec/step)\n",
            "I0517 09:42:13.104063 139851376510848 learning.py:507] global step 6112: loss = 2.2342 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 6113: loss = 1.6965 (0.562 sec/step)\n",
            "I0517 09:42:13.668153 139851376510848 learning.py:507] global step 6113: loss = 1.6965 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6114: loss = 1.7015 (0.584 sec/step)\n",
            "I0517 09:42:14.254466 139851376510848 learning.py:507] global step 6114: loss = 1.7015 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6115: loss = 1.9898 (0.554 sec/step)\n",
            "I0517 09:42:14.810854 139851376510848 learning.py:507] global step 6115: loss = 1.9898 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6116: loss = 2.1968 (0.600 sec/step)\n",
            "I0517 09:42:15.412871 139851376510848 learning.py:507] global step 6116: loss = 2.1968 (0.600 sec/step)\n",
            "INFO:tensorflow:global step 6117: loss = 4.1326 (0.577 sec/step)\n",
            "I0517 09:42:15.991420 139851376510848 learning.py:507] global step 6117: loss = 4.1326 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 6118: loss = 2.2881 (0.548 sec/step)\n",
            "I0517 09:42:16.541527 139851376510848 learning.py:507] global step 6118: loss = 2.2881 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6119: loss = 2.5214 (0.559 sec/step)\n",
            "I0517 09:42:17.105361 139851376510848 learning.py:507] global step 6119: loss = 2.5214 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6120: loss = 1.9341 (0.565 sec/step)\n",
            "I0517 09:42:17.671783 139851376510848 learning.py:507] global step 6120: loss = 1.9341 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6121: loss = 2.4966 (0.546 sec/step)\n",
            "I0517 09:42:18.219892 139851376510848 learning.py:507] global step 6121: loss = 2.4966 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6122: loss = 1.6405 (0.575 sec/step)\n",
            "I0517 09:42:18.796661 139851376510848 learning.py:507] global step 6122: loss = 1.6405 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6123: loss = 2.2327 (0.583 sec/step)\n",
            "I0517 09:42:19.381261 139851376510848 learning.py:507] global step 6123: loss = 2.2327 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6124: loss = 2.7321 (0.559 sec/step)\n",
            "I0517 09:42:19.942779 139851376510848 learning.py:507] global step 6124: loss = 2.7321 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6125: loss = 2.5400 (0.606 sec/step)\n",
            "I0517 09:42:20.550647 139851376510848 learning.py:507] global step 6125: loss = 2.5400 (0.606 sec/step)\n",
            "INFO:tensorflow:global step 6126: loss = 2.5302 (0.538 sec/step)\n",
            "I0517 09:42:21.091098 139851376510848 learning.py:507] global step 6126: loss = 2.5302 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6127: loss = 2.4039 (0.567 sec/step)\n",
            "I0517 09:42:21.660430 139851376510848 learning.py:507] global step 6127: loss = 2.4039 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6128: loss = 1.9054 (0.551 sec/step)\n",
            "I0517 09:42:22.213678 139851376510848 learning.py:507] global step 6128: loss = 1.9054 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6129: loss = 2.0960 (0.588 sec/step)\n",
            "I0517 09:42:22.803445 139851376510848 learning.py:507] global step 6129: loss = 2.0960 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6130: loss = 2.7953 (0.563 sec/step)\n",
            "I0517 09:42:23.368073 139851376510848 learning.py:507] global step 6130: loss = 2.7953 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6131: loss = 2.2875 (0.564 sec/step)\n",
            "I0517 09:42:23.933676 139851376510848 learning.py:507] global step 6131: loss = 2.2875 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6132: loss = 3.5361 (0.567 sec/step)\n",
            "I0517 09:42:24.504012 139851376510848 learning.py:507] global step 6132: loss = 3.5361 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6133: loss = 1.8914 (0.566 sec/step)\n",
            "I0517 09:42:25.072312 139851376510848 learning.py:507] global step 6133: loss = 1.8914 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6134: loss = 1.8866 (0.562 sec/step)\n",
            "I0517 09:42:25.636116 139851376510848 learning.py:507] global step 6134: loss = 1.8866 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6135: loss = 2.2835 (0.544 sec/step)\n",
            "I0517 09:42:26.182108 139851376510848 learning.py:507] global step 6135: loss = 2.2835 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6136: loss = 2.4944 (0.579 sec/step)\n",
            "I0517 09:42:26.762638 139851376510848 learning.py:507] global step 6136: loss = 2.4944 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6137: loss = 3.4962 (0.553 sec/step)\n",
            "I0517 09:42:27.317200 139851376510848 learning.py:507] global step 6137: loss = 3.4962 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6138: loss = 2.2982 (0.587 sec/step)\n",
            "I0517 09:42:27.906062 139851376510848 learning.py:507] global step 6138: loss = 2.2982 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6139: loss = 2.4445 (0.590 sec/step)\n",
            "I0517 09:42:28.498296 139851376510848 learning.py:507] global step 6139: loss = 2.4445 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6140: loss = 1.9375 (0.560 sec/step)\n",
            "I0517 09:42:29.062656 139851376510848 learning.py:507] global step 6140: loss = 1.9375 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6141: loss = 1.9160 (0.582 sec/step)\n",
            "I0517 09:42:29.648026 139851376510848 learning.py:507] global step 6141: loss = 1.9160 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6142: loss = 1.7021 (0.567 sec/step)\n",
            "I0517 09:42:30.216970 139851376510848 learning.py:507] global step 6142: loss = 1.7021 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6143: loss = 2.4087 (0.604 sec/step)\n",
            "I0517 09:42:30.822523 139851376510848 learning.py:507] global step 6143: loss = 2.4087 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 6144: loss = 2.2116 (0.534 sec/step)\n",
            "I0517 09:42:31.358388 139851376510848 learning.py:507] global step 6144: loss = 2.2116 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 6145: loss = 3.6921 (0.561 sec/step)\n",
            "I0517 09:42:31.921794 139851376510848 learning.py:507] global step 6145: loss = 3.6921 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6146: loss = 1.7836 (0.542 sec/step)\n",
            "I0517 09:42:32.465896 139851376510848 learning.py:507] global step 6146: loss = 1.7836 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6147: loss = 2.4065 (0.549 sec/step)\n",
            "I0517 09:42:33.016518 139851376510848 learning.py:507] global step 6147: loss = 2.4065 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6148: loss = 3.4585 (0.582 sec/step)\n",
            "I0517 09:42:33.600406 139851376510848 learning.py:507] global step 6148: loss = 3.4585 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6149: loss = 1.9611 (0.533 sec/step)\n",
            "I0517 09:42:34.135790 139851376510848 learning.py:507] global step 6149: loss = 1.9611 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6150: loss = 2.0315 (0.556 sec/step)\n",
            "I0517 09:42:34.693927 139851376510848 learning.py:507] global step 6150: loss = 2.0315 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6151: loss = 2.0793 (0.549 sec/step)\n",
            "I0517 09:42:35.244958 139851376510848 learning.py:507] global step 6151: loss = 2.0793 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6152: loss = 1.8346 (0.566 sec/step)\n",
            "I0517 09:42:35.812542 139851376510848 learning.py:507] global step 6152: loss = 1.8346 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6153: loss = 2.0428 (0.549 sec/step)\n",
            "I0517 09:42:36.363158 139851376510848 learning.py:507] global step 6153: loss = 2.0428 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6154: loss = 2.8655 (0.586 sec/step)\n",
            "I0517 09:42:36.950963 139851376510848 learning.py:507] global step 6154: loss = 2.8655 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 6155: loss = 2.4455 (0.571 sec/step)\n",
            "I0517 09:42:37.524246 139851376510848 learning.py:507] global step 6155: loss = 2.4455 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6156: loss = 2.5845 (0.556 sec/step)\n",
            "I0517 09:42:38.081686 139851376510848 learning.py:507] global step 6156: loss = 2.5845 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6157: loss = 1.7687 (0.570 sec/step)\n",
            "I0517 09:42:38.653756 139851376510848 learning.py:507] global step 6157: loss = 1.7687 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6158: loss = 3.5077 (0.561 sec/step)\n",
            "I0517 09:42:39.216515 139851376510848 learning.py:507] global step 6158: loss = 3.5077 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6159: loss = 2.0373 (0.571 sec/step)\n",
            "I0517 09:42:39.789907 139851376510848 learning.py:507] global step 6159: loss = 2.0373 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6160: loss = 1.9820 (0.559 sec/step)\n",
            "I0517 09:42:40.350939 139851376510848 learning.py:507] global step 6160: loss = 1.9820 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6161: loss = 2.2439 (0.595 sec/step)\n",
            "I0517 09:42:40.947835 139851376510848 learning.py:507] global step 6161: loss = 2.2439 (0.595 sec/step)\n",
            "INFO:tensorflow:global step 6162: loss = 1.8516 (0.554 sec/step)\n",
            "I0517 09:42:41.503420 139851376510848 learning.py:507] global step 6162: loss = 1.8516 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6163: loss = 1.7829 (0.588 sec/step)\n",
            "I0517 09:42:42.094301 139851376510848 learning.py:507] global step 6163: loss = 1.7829 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6164: loss = 2.3080 (0.580 sec/step)\n",
            "I0517 09:42:42.675874 139851376510848 learning.py:507] global step 6164: loss = 2.3080 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6165: loss = 1.9211 (0.554 sec/step)\n",
            "I0517 09:42:43.231545 139851376510848 learning.py:507] global step 6165: loss = 1.9211 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6166: loss = 3.0711 (0.564 sec/step)\n",
            "I0517 09:42:43.797252 139851376510848 learning.py:507] global step 6166: loss = 3.0711 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6167: loss = 1.8600 (0.561 sec/step)\n",
            "I0517 09:42:44.360755 139851376510848 learning.py:507] global step 6167: loss = 1.8600 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6168: loss = 2.2742 (0.566 sec/step)\n",
            "I0517 09:42:44.928781 139851376510848 learning.py:507] global step 6168: loss = 2.2742 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6169: loss = 1.5425 (0.547 sec/step)\n",
            "I0517 09:42:45.478417 139851376510848 learning.py:507] global step 6169: loss = 1.5425 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6170: loss = 1.9341 (1.145 sec/step)\n",
            "I0517 09:42:46.630203 139851376510848 learning.py:507] global step 6170: loss = 1.9341 (1.145 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6170.\n",
            "I0517 09:42:47.031357 139847641536256 supervisor.py:1050] Recording summary at step 6170.\n",
            "INFO:tensorflow:global step 6171: loss = 3.2065 (0.602 sec/step)\n",
            "I0517 09:42:47.411588 139851376510848 learning.py:507] global step 6171: loss = 3.2065 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6172: loss = 1.8717 (0.602 sec/step)\n",
            "I0517 09:42:48.015016 139851376510848 learning.py:507] global step 6172: loss = 1.8717 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6173: loss = 2.2558 (0.591 sec/step)\n",
            "I0517 09:42:48.608361 139851376510848 learning.py:507] global step 6173: loss = 2.2558 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6174: loss = 1.9891 (0.590 sec/step)\n",
            "I0517 09:42:49.200318 139851376510848 learning.py:507] global step 6174: loss = 1.9891 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6175: loss = 2.1998 (0.560 sec/step)\n",
            "I0517 09:42:49.761815 139851376510848 learning.py:507] global step 6175: loss = 2.1998 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6176: loss = 2.7851 (0.613 sec/step)\n",
            "I0517 09:42:50.377745 139851376510848 learning.py:507] global step 6176: loss = 2.7851 (0.613 sec/step)\n",
            "INFO:tensorflow:global step 6177: loss = 2.2293 (0.571 sec/step)\n",
            "I0517 09:42:50.950509 139851376510848 learning.py:507] global step 6177: loss = 2.2293 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6178: loss = 2.1159 (0.584 sec/step)\n",
            "I0517 09:42:51.536263 139851376510848 learning.py:507] global step 6178: loss = 2.1159 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6179: loss = 2.4402 (0.590 sec/step)\n",
            "I0517 09:42:52.128208 139851376510848 learning.py:507] global step 6179: loss = 2.4402 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6180: loss = 1.6038 (0.578 sec/step)\n",
            "I0517 09:42:52.708447 139851376510848 learning.py:507] global step 6180: loss = 1.6038 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6181: loss = 1.5050 (0.588 sec/step)\n",
            "I0517 09:42:53.298513 139851376510848 learning.py:507] global step 6181: loss = 1.5050 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6182: loss = 2.5530 (0.550 sec/step)\n",
            "I0517 09:42:53.850003 139851376510848 learning.py:507] global step 6182: loss = 2.5530 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6183: loss = 2.4423 (0.591 sec/step)\n",
            "I0517 09:42:54.442399 139851376510848 learning.py:507] global step 6183: loss = 2.4423 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6184: loss = 2.0785 (0.583 sec/step)\n",
            "I0517 09:42:55.026812 139851376510848 learning.py:507] global step 6184: loss = 2.0785 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6185: loss = 1.5811 (0.559 sec/step)\n",
            "I0517 09:42:55.587575 139851376510848 learning.py:507] global step 6185: loss = 1.5811 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6186: loss = 3.4989 (0.570 sec/step)\n",
            "I0517 09:42:56.159622 139851376510848 learning.py:507] global step 6186: loss = 3.4989 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6187: loss = 1.9845 (0.571 sec/step)\n",
            "I0517 09:42:56.733353 139851376510848 learning.py:507] global step 6187: loss = 1.9845 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6188: loss = 2.0923 (0.547 sec/step)\n",
            "I0517 09:42:57.282103 139851376510848 learning.py:507] global step 6188: loss = 2.0923 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6189: loss = 1.8611 (0.553 sec/step)\n",
            "I0517 09:42:57.837203 139851376510848 learning.py:507] global step 6189: loss = 1.8611 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6190: loss = 1.5827 (0.550 sec/step)\n",
            "I0517 09:42:58.389018 139851376510848 learning.py:507] global step 6190: loss = 1.5827 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6191: loss = 2.3813 (0.564 sec/step)\n",
            "I0517 09:42:58.954534 139851376510848 learning.py:507] global step 6191: loss = 2.3813 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6192: loss = 2.3769 (0.592 sec/step)\n",
            "I0517 09:42:59.549159 139851376510848 learning.py:507] global step 6192: loss = 2.3769 (0.592 sec/step)\n",
            "INFO:tensorflow:global step 6193: loss = 1.9562 (0.549 sec/step)\n",
            "I0517 09:43:00.099770 139851376510848 learning.py:507] global step 6193: loss = 1.9562 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6194: loss = 2.7463 (0.556 sec/step)\n",
            "I0517 09:43:00.657454 139851376510848 learning.py:507] global step 6194: loss = 2.7463 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6195: loss = 1.5920 (0.575 sec/step)\n",
            "I0517 09:43:01.234018 139851376510848 learning.py:507] global step 6195: loss = 1.5920 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6196: loss = 1.4472 (0.574 sec/step)\n",
            "I0517 09:43:01.809808 139851376510848 learning.py:507] global step 6196: loss = 1.4472 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6197: loss = 3.3154 (0.561 sec/step)\n",
            "I0517 09:43:02.373691 139851376510848 learning.py:507] global step 6197: loss = 3.3154 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6198: loss = 2.1436 (0.590 sec/step)\n",
            "I0517 09:43:02.965312 139851376510848 learning.py:507] global step 6198: loss = 2.1436 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6199: loss = 1.9996 (0.571 sec/step)\n",
            "I0517 09:43:03.538275 139851376510848 learning.py:507] global step 6199: loss = 1.9996 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6200: loss = 2.4597 (0.564 sec/step)\n",
            "I0517 09:43:04.103894 139851376510848 learning.py:507] global step 6200: loss = 2.4597 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6201: loss = 1.3870 (0.568 sec/step)\n",
            "I0517 09:43:04.673459 139851376510848 learning.py:507] global step 6201: loss = 1.3870 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6202: loss = 2.3399 (0.557 sec/step)\n",
            "I0517 09:43:05.232151 139851376510848 learning.py:507] global step 6202: loss = 2.3399 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6203: loss = 2.0746 (0.588 sec/step)\n",
            "I0517 09:43:05.822227 139851376510848 learning.py:507] global step 6203: loss = 2.0746 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6204: loss = 3.0093 (0.561 sec/step)\n",
            "I0517 09:43:06.385511 139851376510848 learning.py:507] global step 6204: loss = 3.0093 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6205: loss = 2.1630 (0.566 sec/step)\n",
            "I0517 09:43:06.953064 139851376510848 learning.py:507] global step 6205: loss = 2.1630 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6206: loss = 1.5613 (0.597 sec/step)\n",
            "I0517 09:43:07.556008 139851376510848 learning.py:507] global step 6206: loss = 1.5613 (0.597 sec/step)\n",
            "INFO:tensorflow:global step 6207: loss = 2.0627 (0.570 sec/step)\n",
            "I0517 09:43:08.130172 139851376510848 learning.py:507] global step 6207: loss = 2.0627 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6208: loss = 1.9634 (0.538 sec/step)\n",
            "I0517 09:43:08.669858 139851376510848 learning.py:507] global step 6208: loss = 1.9634 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6209: loss = 1.9455 (0.546 sec/step)\n",
            "I0517 09:43:09.217543 139851376510848 learning.py:507] global step 6209: loss = 1.9455 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6210: loss = 3.0490 (0.593 sec/step)\n",
            "I0517 09:43:09.812392 139851376510848 learning.py:507] global step 6210: loss = 3.0490 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6211: loss = 2.5088 (0.562 sec/step)\n",
            "I0517 09:43:10.376069 139851376510848 learning.py:507] global step 6211: loss = 2.5088 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6212: loss = 2.4164 (0.551 sec/step)\n",
            "I0517 09:43:10.928915 139851376510848 learning.py:507] global step 6212: loss = 2.4164 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6213: loss = 1.4874 (0.588 sec/step)\n",
            "I0517 09:43:11.518889 139851376510848 learning.py:507] global step 6213: loss = 1.4874 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6214: loss = 2.0738 (0.564 sec/step)\n",
            "I0517 09:43:12.084488 139851376510848 learning.py:507] global step 6214: loss = 2.0738 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6215: loss = 1.7995 (0.559 sec/step)\n",
            "I0517 09:43:12.645268 139851376510848 learning.py:507] global step 6215: loss = 1.7995 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6216: loss = 1.3778 (0.559 sec/step)\n",
            "I0517 09:43:13.205706 139851376510848 learning.py:507] global step 6216: loss = 1.3778 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6217: loss = 2.0940 (0.555 sec/step)\n",
            "I0517 09:43:13.762363 139851376510848 learning.py:507] global step 6217: loss = 2.0940 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6218: loss = 2.3236 (0.576 sec/step)\n",
            "I0517 09:43:14.340391 139851376510848 learning.py:507] global step 6218: loss = 2.3236 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6219: loss = 1.6891 (0.578 sec/step)\n",
            "I0517 09:43:14.919859 139851376510848 learning.py:507] global step 6219: loss = 1.6891 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6220: loss = 1.7876 (0.570 sec/step)\n",
            "I0517 09:43:15.491175 139851376510848 learning.py:507] global step 6220: loss = 1.7876 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6221: loss = 1.7541 (0.587 sec/step)\n",
            "I0517 09:43:16.079344 139851376510848 learning.py:507] global step 6221: loss = 1.7541 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6222: loss = 1.9656 (0.580 sec/step)\n",
            "I0517 09:43:16.660637 139851376510848 learning.py:507] global step 6222: loss = 1.9656 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6223: loss = 3.4737 (0.555 sec/step)\n",
            "I0517 09:43:17.218135 139851376510848 learning.py:507] global step 6223: loss = 3.4737 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6224: loss = 2.3049 (0.570 sec/step)\n",
            "I0517 09:43:17.790147 139851376510848 learning.py:507] global step 6224: loss = 2.3049 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6225: loss = 2.7485 (0.581 sec/step)\n",
            "I0517 09:43:18.373068 139851376510848 learning.py:507] global step 6225: loss = 2.7485 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 6226: loss = 2.7030 (0.556 sec/step)\n",
            "I0517 09:43:18.931324 139851376510848 learning.py:507] global step 6226: loss = 2.7030 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6227: loss = 1.8783 (0.540 sec/step)\n",
            "I0517 09:43:19.473513 139851376510848 learning.py:507] global step 6227: loss = 1.8783 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6228: loss = 2.0010 (0.528 sec/step)\n",
            "I0517 09:43:20.003744 139851376510848 learning.py:507] global step 6228: loss = 2.0010 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 6229: loss = 2.0957 (0.561 sec/step)\n",
            "I0517 09:43:20.566802 139851376510848 learning.py:507] global step 6229: loss = 2.0957 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6230: loss = 1.7108 (0.553 sec/step)\n",
            "I0517 09:43:21.121447 139851376510848 learning.py:507] global step 6230: loss = 1.7108 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6231: loss = 1.9481 (0.576 sec/step)\n",
            "I0517 09:43:21.700418 139851376510848 learning.py:507] global step 6231: loss = 1.9481 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6232: loss = 1.8568 (0.587 sec/step)\n",
            "I0517 09:43:22.288745 139851376510848 learning.py:507] global step 6232: loss = 1.8568 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6233: loss = 2.6750 (0.552 sec/step)\n",
            "I0517 09:43:22.842839 139851376510848 learning.py:507] global step 6233: loss = 2.6750 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6234: loss = 1.5957 (0.569 sec/step)\n",
            "I0517 09:43:23.414079 139851376510848 learning.py:507] global step 6234: loss = 1.5957 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6235: loss = 2.0742 (0.546 sec/step)\n",
            "I0517 09:43:23.961733 139851376510848 learning.py:507] global step 6235: loss = 2.0742 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6236: loss = 2.0057 (0.582 sec/step)\n",
            "I0517 09:43:24.545851 139851376510848 learning.py:507] global step 6236: loss = 2.0057 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6237: loss = 1.6794 (0.575 sec/step)\n",
            "I0517 09:43:25.122329 139851376510848 learning.py:507] global step 6237: loss = 1.6794 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6238: loss = 1.7870 (0.573 sec/step)\n",
            "I0517 09:43:25.696648 139851376510848 learning.py:507] global step 6238: loss = 1.7870 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6239: loss = 1.5744 (0.568 sec/step)\n",
            "I0517 09:43:26.266067 139851376510848 learning.py:507] global step 6239: loss = 1.5744 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6240: loss = 1.8515 (0.576 sec/step)\n",
            "I0517 09:43:26.844063 139851376510848 learning.py:507] global step 6240: loss = 1.8515 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6241: loss = 1.4571 (0.601 sec/step)\n",
            "I0517 09:43:27.446697 139851376510848 learning.py:507] global step 6241: loss = 1.4571 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 6242: loss = 1.9812 (0.570 sec/step)\n",
            "I0517 09:43:28.018107 139851376510848 learning.py:507] global step 6242: loss = 1.9812 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6243: loss = 1.6312 (0.569 sec/step)\n",
            "I0517 09:43:28.589254 139851376510848 learning.py:507] global step 6243: loss = 1.6312 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6244: loss = 2.0081 (0.549 sec/step)\n",
            "I0517 09:43:29.139821 139851376510848 learning.py:507] global step 6244: loss = 2.0081 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6245: loss = 2.9923 (0.563 sec/step)\n",
            "I0517 09:43:29.704412 139851376510848 learning.py:507] global step 6245: loss = 2.9923 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6246: loss = 2.4075 (0.544 sec/step)\n",
            "I0517 09:43:30.249915 139851376510848 learning.py:507] global step 6246: loss = 2.4075 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6247: loss = 1.9535 (0.565 sec/step)\n",
            "I0517 09:43:30.817366 139851376510848 learning.py:507] global step 6247: loss = 1.9535 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6248: loss = 2.0472 (0.573 sec/step)\n",
            "I0517 09:43:31.392228 139851376510848 learning.py:507] global step 6248: loss = 2.0472 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6249: loss = 2.9565 (0.553 sec/step)\n",
            "I0517 09:43:31.946686 139851376510848 learning.py:507] global step 6249: loss = 2.9565 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6250: loss = 1.8217 (0.602 sec/step)\n",
            "I0517 09:43:32.550318 139851376510848 learning.py:507] global step 6250: loss = 1.8217 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6251: loss = 2.2041 (0.606 sec/step)\n",
            "I0517 09:43:33.157940 139851376510848 learning.py:507] global step 6251: loss = 2.2041 (0.606 sec/step)\n",
            "INFO:tensorflow:global step 6252: loss = 3.0503 (0.568 sec/step)\n",
            "I0517 09:43:33.727670 139851376510848 learning.py:507] global step 6252: loss = 3.0503 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6253: loss = 1.5974 (0.564 sec/step)\n",
            "I0517 09:43:34.293219 139851376510848 learning.py:507] global step 6253: loss = 1.5974 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6254: loss = 1.5913 (0.567 sec/step)\n",
            "I0517 09:43:34.861722 139851376510848 learning.py:507] global step 6254: loss = 1.5913 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6255: loss = 1.8710 (0.540 sec/step)\n",
            "I0517 09:43:35.404938 139851376510848 learning.py:507] global step 6255: loss = 1.8710 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6256: loss = 3.6189 (0.564 sec/step)\n",
            "I0517 09:43:35.973009 139851376510848 learning.py:507] global step 6256: loss = 3.6189 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6257: loss = 1.8551 (0.546 sec/step)\n",
            "I0517 09:43:36.521292 139851376510848 learning.py:507] global step 6257: loss = 1.8551 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6258: loss = 2.0882 (0.552 sec/step)\n",
            "I0517 09:43:37.074817 139851376510848 learning.py:507] global step 6258: loss = 2.0882 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6259: loss = 1.6873 (0.567 sec/step)\n",
            "I0517 09:43:37.643579 139851376510848 learning.py:507] global step 6259: loss = 1.6873 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6260: loss = 1.9691 (0.555 sec/step)\n",
            "I0517 09:43:38.200000 139851376510848 learning.py:507] global step 6260: loss = 1.9691 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6261: loss = 1.6775 (0.574 sec/step)\n",
            "I0517 09:43:38.775773 139851376510848 learning.py:507] global step 6261: loss = 1.6775 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6262: loss = 2.1582 (0.572 sec/step)\n",
            "I0517 09:43:39.350611 139851376510848 learning.py:507] global step 6262: loss = 2.1582 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6263: loss = 2.1359 (0.556 sec/step)\n",
            "I0517 09:43:39.908651 139851376510848 learning.py:507] global step 6263: loss = 2.1359 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6264: loss = 1.3888 (0.554 sec/step)\n",
            "I0517 09:43:40.464657 139851376510848 learning.py:507] global step 6264: loss = 1.3888 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6265: loss = 3.3000 (0.581 sec/step)\n",
            "I0517 09:43:41.048236 139851376510848 learning.py:507] global step 6265: loss = 3.3000 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 6266: loss = 1.8301 (0.590 sec/step)\n",
            "I0517 09:43:41.639602 139851376510848 learning.py:507] global step 6266: loss = 1.8301 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6267: loss = 1.6088 (0.548 sec/step)\n",
            "I0517 09:43:42.189333 139851376510848 learning.py:507] global step 6267: loss = 1.6088 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6268: loss = 2.0203 (0.575 sec/step)\n",
            "I0517 09:43:42.765912 139851376510848 learning.py:507] global step 6268: loss = 2.0203 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6269: loss = 1.8231 (0.599 sec/step)\n",
            "I0517 09:43:43.366517 139851376510848 learning.py:507] global step 6269: loss = 1.8231 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6270: loss = 2.5942 (0.588 sec/step)\n",
            "I0517 09:43:43.956485 139851376510848 learning.py:507] global step 6270: loss = 2.5942 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6271: loss = 3.4846 (0.551 sec/step)\n",
            "I0517 09:43:44.510849 139851376510848 learning.py:507] global step 6271: loss = 3.4846 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6272: loss = 1.5987 (0.594 sec/step)\n",
            "I0517 09:43:45.106837 139851376510848 learning.py:507] global step 6272: loss = 1.5987 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 6273: loss = 2.4621 (0.565 sec/step)\n",
            "I0517 09:43:45.673458 139851376510848 learning.py:507] global step 6273: loss = 2.4621 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6274: loss = 2.9712 (0.537 sec/step)\n",
            "I0517 09:43:46.213007 139851376510848 learning.py:507] global step 6274: loss = 2.9712 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6275: loss = 2.5630 (0.560 sec/step)\n",
            "I0517 09:43:46.774365 139851376510848 learning.py:507] global step 6275: loss = 2.5630 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6276: loss = 2.8088 (0.551 sec/step)\n",
            "I0517 09:43:47.327359 139851376510848 learning.py:507] global step 6276: loss = 2.8088 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6277: loss = 1.7287 (0.563 sec/step)\n",
            "I0517 09:43:47.891905 139851376510848 learning.py:507] global step 6277: loss = 1.7287 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6278: loss = 1.9537 (0.531 sec/step)\n",
            "I0517 09:43:48.424455 139851376510848 learning.py:507] global step 6278: loss = 1.9537 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 6279: loss = 3.2139 (0.570 sec/step)\n",
            "I0517 09:43:48.995789 139851376510848 learning.py:507] global step 6279: loss = 3.2139 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6280: loss = 2.1438 (0.561 sec/step)\n",
            "I0517 09:43:49.558507 139851376510848 learning.py:507] global step 6280: loss = 2.1438 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6281: loss = 2.1728 (0.564 sec/step)\n",
            "I0517 09:43:50.123980 139851376510848 learning.py:507] global step 6281: loss = 2.1728 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6282: loss = 2.1366 (0.576 sec/step)\n",
            "I0517 09:43:50.702345 139851376510848 learning.py:507] global step 6282: loss = 2.1366 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6283: loss = 1.5218 (0.595 sec/step)\n",
            "I0517 09:43:51.299132 139851376510848 learning.py:507] global step 6283: loss = 1.5218 (0.595 sec/step)\n",
            "INFO:tensorflow:global step 6284: loss = 2.3301 (0.591 sec/step)\n",
            "I0517 09:43:51.893235 139851376510848 learning.py:507] global step 6284: loss = 2.3301 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6285: loss = 1.7085 (0.555 sec/step)\n",
            "I0517 09:43:52.450446 139851376510848 learning.py:507] global step 6285: loss = 1.7085 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6286: loss = 2.1293 (0.563 sec/step)\n",
            "I0517 09:43:53.015643 139851376510848 learning.py:507] global step 6286: loss = 2.1293 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6287: loss = 1.3221 (0.548 sec/step)\n",
            "I0517 09:43:53.565086 139851376510848 learning.py:507] global step 6287: loss = 1.3221 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6288: loss = 1.7036 (0.568 sec/step)\n",
            "I0517 09:43:54.134942 139851376510848 learning.py:507] global step 6288: loss = 1.7036 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6289: loss = 2.2718 (0.567 sec/step)\n",
            "I0517 09:43:54.704516 139851376510848 learning.py:507] global step 6289: loss = 2.2718 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6290: loss = 3.9543 (0.574 sec/step)\n",
            "I0517 09:43:55.280574 139851376510848 learning.py:507] global step 6290: loss = 3.9543 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6291: loss = 2.0333 (0.573 sec/step)\n",
            "I0517 09:43:55.854877 139851376510848 learning.py:507] global step 6291: loss = 2.0333 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6292: loss = 3.4505 (0.540 sec/step)\n",
            "I0517 09:43:56.396744 139851376510848 learning.py:507] global step 6292: loss = 3.4505 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6293: loss = 1.7937 (0.565 sec/step)\n",
            "I0517 09:43:56.963274 139851376510848 learning.py:507] global step 6293: loss = 1.7937 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6294: loss = 2.2214 (0.552 sec/step)\n",
            "I0517 09:43:57.516859 139851376510848 learning.py:507] global step 6294: loss = 2.2214 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6295: loss = 1.7694 (0.552 sec/step)\n",
            "I0517 09:43:58.070460 139851376510848 learning.py:507] global step 6295: loss = 1.7694 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6296: loss = 2.0786 (0.544 sec/step)\n",
            "I0517 09:43:58.616436 139851376510848 learning.py:507] global step 6296: loss = 2.0786 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6297: loss = 1.7940 (0.582 sec/step)\n",
            "I0517 09:43:59.200070 139851376510848 learning.py:507] global step 6297: loss = 1.7940 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6298: loss = 2.6907 (0.580 sec/step)\n",
            "I0517 09:43:59.782203 139851376510848 learning.py:507] global step 6298: loss = 2.6907 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6299: loss = 1.2858 (0.583 sec/step)\n",
            "I0517 09:44:00.366796 139851376510848 learning.py:507] global step 6299: loss = 1.2858 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6300: loss = 2.1084 (0.561 sec/step)\n",
            "I0517 09:44:00.933151 139851376510848 learning.py:507] global step 6300: loss = 2.1084 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6301: loss = 3.6877 (0.553 sec/step)\n",
            "I0517 09:44:01.489587 139851376510848 learning.py:507] global step 6301: loss = 3.6877 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6302: loss = 1.6298 (0.560 sec/step)\n",
            "I0517 09:44:02.051798 139851376510848 learning.py:507] global step 6302: loss = 1.6298 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6303: loss = 2.3190 (0.551 sec/step)\n",
            "I0517 09:44:02.604416 139851376510848 learning.py:507] global step 6303: loss = 2.3190 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6304: loss = 3.9313 (0.558 sec/step)\n",
            "I0517 09:44:03.165835 139851376510848 learning.py:507] global step 6304: loss = 3.9313 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6305: loss = 1.6746 (0.558 sec/step)\n",
            "I0517 09:44:03.725842 139851376510848 learning.py:507] global step 6305: loss = 1.6746 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6306: loss = 2.2667 (0.561 sec/step)\n",
            "I0517 09:44:04.288373 139851376510848 learning.py:507] global step 6306: loss = 2.2667 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6307: loss = 2.4794 (0.570 sec/step)\n",
            "I0517 09:44:04.860922 139851376510848 learning.py:507] global step 6307: loss = 2.4794 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6308: loss = 2.7446 (0.545 sec/step)\n",
            "I0517 09:44:05.407688 139851376510848 learning.py:507] global step 6308: loss = 2.7446 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6309: loss = 1.8162 (0.537 sec/step)\n",
            "I0517 09:44:05.945880 139851376510848 learning.py:507] global step 6309: loss = 1.8162 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6310: loss = 2.7497 (0.599 sec/step)\n",
            "I0517 09:44:06.546856 139851376510848 learning.py:507] global step 6310: loss = 2.7497 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6311: loss = 1.9211 (0.576 sec/step)\n",
            "I0517 09:44:07.124575 139851376510848 learning.py:507] global step 6311: loss = 1.9211 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6312: loss = 1.6045 (0.582 sec/step)\n",
            "I0517 09:44:07.708584 139851376510848 learning.py:507] global step 6312: loss = 1.6045 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6313: loss = 3.7069 (0.552 sec/step)\n",
            "I0517 09:44:08.261931 139851376510848 learning.py:507] global step 6313: loss = 3.7069 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6314: loss = 1.9839 (0.603 sec/step)\n",
            "I0517 09:44:08.866362 139851376510848 learning.py:507] global step 6314: loss = 1.9839 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 6315: loss = 1.6310 (0.589 sec/step)\n",
            "I0517 09:44:09.457843 139851376510848 learning.py:507] global step 6315: loss = 1.6310 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6316: loss = 2.3146 (0.562 sec/step)\n",
            "I0517 09:44:10.021760 139851376510848 learning.py:507] global step 6316: loss = 2.3146 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6317: loss = 2.0087 (0.595 sec/step)\n",
            "I0517 09:44:10.618932 139851376510848 learning.py:507] global step 6317: loss = 2.0087 (0.595 sec/step)\n",
            "INFO:tensorflow:global step 6318: loss = 2.3431 (0.563 sec/step)\n",
            "I0517 09:44:11.183813 139851376510848 learning.py:507] global step 6318: loss = 2.3431 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6319: loss = 1.8237 (0.565 sec/step)\n",
            "I0517 09:44:11.750930 139851376510848 learning.py:507] global step 6319: loss = 1.8237 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6320: loss = 3.1804 (0.543 sec/step)\n",
            "I0517 09:44:12.295311 139851376510848 learning.py:507] global step 6320: loss = 3.1804 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6321: loss = 1.8130 (0.555 sec/step)\n",
            "I0517 09:44:12.852551 139851376510848 learning.py:507] global step 6321: loss = 1.8130 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6322: loss = 2.4587 (0.555 sec/step)\n",
            "I0517 09:44:13.409734 139851376510848 learning.py:507] global step 6322: loss = 2.4587 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6323: loss = 2.9993 (0.553 sec/step)\n",
            "I0517 09:44:13.964766 139851376510848 learning.py:507] global step 6323: loss = 2.9993 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6324: loss = 1.6567 (0.543 sec/step)\n",
            "I0517 09:44:14.509921 139851376510848 learning.py:507] global step 6324: loss = 1.6567 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6325: loss = 1.8444 (0.581 sec/step)\n",
            "I0517 09:44:15.093086 139851376510848 learning.py:507] global step 6325: loss = 1.8444 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 6326: loss = 3.2736 (0.560 sec/step)\n",
            "I0517 09:44:15.654467 139851376510848 learning.py:507] global step 6326: loss = 3.2736 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6327: loss = 2.0718 (0.543 sec/step)\n",
            "I0517 09:44:16.200521 139851376510848 learning.py:507] global step 6327: loss = 2.0718 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6328: loss = 1.8851 (0.573 sec/step)\n",
            "I0517 09:44:16.775686 139851376510848 learning.py:507] global step 6328: loss = 1.8851 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6329: loss = 3.0324 (0.550 sec/step)\n",
            "I0517 09:44:17.327091 139851376510848 learning.py:507] global step 6329: loss = 3.0324 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6330: loss = 2.1437 (0.563 sec/step)\n",
            "I0517 09:44:17.891881 139851376510848 learning.py:507] global step 6330: loss = 2.1437 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6331: loss = 2.5663 (0.583 sec/step)\n",
            "I0517 09:44:18.476795 139851376510848 learning.py:507] global step 6331: loss = 2.5663 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6332: loss = 2.2987 (0.555 sec/step)\n",
            "I0517 09:44:19.033025 139851376510848 learning.py:507] global step 6332: loss = 2.2987 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6333: loss = 1.7142 (0.605 sec/step)\n",
            "I0517 09:44:19.639537 139851376510848 learning.py:507] global step 6333: loss = 1.7142 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 6334: loss = 1.8280 (0.557 sec/step)\n",
            "I0517 09:44:20.198474 139851376510848 learning.py:507] global step 6334: loss = 1.8280 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6335: loss = 2.3449 (0.576 sec/step)\n",
            "I0517 09:44:20.775888 139851376510848 learning.py:507] global step 6335: loss = 2.3449 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6336: loss = 1.6291 (0.564 sec/step)\n",
            "I0517 09:44:21.342008 139851376510848 learning.py:507] global step 6336: loss = 1.6291 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6337: loss = 2.0745 (0.557 sec/step)\n",
            "I0517 09:44:21.901159 139851376510848 learning.py:507] global step 6337: loss = 2.0745 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6338: loss = 2.9024 (0.555 sec/step)\n",
            "I0517 09:44:22.458473 139851376510848 learning.py:507] global step 6338: loss = 2.9024 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6339: loss = 1.9416 (0.586 sec/step)\n",
            "I0517 09:44:23.046863 139851376510848 learning.py:507] global step 6339: loss = 1.9416 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 6340: loss = 1.9490 (0.556 sec/step)\n",
            "I0517 09:44:23.604688 139851376510848 learning.py:507] global step 6340: loss = 1.9490 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6341: loss = 2.4109 (0.583 sec/step)\n",
            "I0517 09:44:24.189384 139851376510848 learning.py:507] global step 6341: loss = 2.4109 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6342: loss = 2.4433 (0.552 sec/step)\n",
            "I0517 09:44:24.745189 139851376510848 learning.py:507] global step 6342: loss = 2.4433 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6343: loss = 2.2478 (0.543 sec/step)\n",
            "I0517 09:44:25.291339 139851376510848 learning.py:507] global step 6343: loss = 2.2478 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6344: loss = 2.5148 (0.603 sec/step)\n",
            "I0517 09:44:25.896061 139851376510848 learning.py:507] global step 6344: loss = 2.5148 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 6345: loss = 2.2836 (0.573 sec/step)\n",
            "I0517 09:44:26.470941 139851376510848 learning.py:507] global step 6345: loss = 2.2836 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6346: loss = 1.6550 (0.562 sec/step)\n",
            "I0517 09:44:27.034818 139851376510848 learning.py:507] global step 6346: loss = 1.6550 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6347: loss = 1.4617 (0.576 sec/step)\n",
            "I0517 09:44:27.614078 139851376510848 learning.py:507] global step 6347: loss = 1.4617 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6348: loss = 2.8612 (0.558 sec/step)\n",
            "I0517 09:44:28.173259 139851376510848 learning.py:507] global step 6348: loss = 2.8612 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6349: loss = 2.3608 (0.576 sec/step)\n",
            "I0517 09:44:28.750598 139851376510848 learning.py:507] global step 6349: loss = 2.3608 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6350: loss = 1.7308 (0.542 sec/step)\n",
            "I0517 09:44:29.294164 139851376510848 learning.py:507] global step 6350: loss = 1.7308 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6351: loss = 2.6721 (0.551 sec/step)\n",
            "I0517 09:44:29.847229 139851376510848 learning.py:507] global step 6351: loss = 2.6721 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6352: loss = 1.7451 (0.549 sec/step)\n",
            "I0517 09:44:30.397614 139851376510848 learning.py:507] global step 6352: loss = 1.7451 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6353: loss = 2.4896 (0.587 sec/step)\n",
            "I0517 09:44:30.986108 139851376510848 learning.py:507] global step 6353: loss = 2.4896 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6354: loss = 1.6402 (0.550 sec/step)\n",
            "I0517 09:44:31.537722 139851376510848 learning.py:507] global step 6354: loss = 1.6402 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6355: loss = 2.2458 (0.570 sec/step)\n",
            "I0517 09:44:32.109817 139851376510848 learning.py:507] global step 6355: loss = 2.2458 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6356: loss = 1.8557 (0.558 sec/step)\n",
            "I0517 09:44:32.669269 139851376510848 learning.py:507] global step 6356: loss = 1.8557 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6357: loss = 2.2942 (0.554 sec/step)\n",
            "I0517 09:44:33.225446 139851376510848 learning.py:507] global step 6357: loss = 2.2942 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6358: loss = 1.3247 (0.576 sec/step)\n",
            "I0517 09:44:33.803046 139851376510848 learning.py:507] global step 6358: loss = 1.3247 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6359: loss = 2.6164 (0.561 sec/step)\n",
            "I0517 09:44:34.365428 139851376510848 learning.py:507] global step 6359: loss = 2.6164 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6360: loss = 1.9032 (0.549 sec/step)\n",
            "I0517 09:44:34.915665 139851376510848 learning.py:507] global step 6360: loss = 1.9032 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6361: loss = 1.6441 (0.585 sec/step)\n",
            "I0517 09:44:35.502985 139851376510848 learning.py:507] global step 6361: loss = 1.6441 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 6362: loss = 3.1629 (0.571 sec/step)\n",
            "I0517 09:44:36.075537 139851376510848 learning.py:507] global step 6362: loss = 3.1629 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6363: loss = 2.6775 (0.587 sec/step)\n",
            "I0517 09:44:36.664626 139851376510848 learning.py:507] global step 6363: loss = 2.6775 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6364: loss = 2.5703 (0.597 sec/step)\n",
            "I0517 09:44:37.263192 139851376510848 learning.py:507] global step 6364: loss = 2.5703 (0.597 sec/step)\n",
            "INFO:tensorflow:global step 6365: loss = 2.1720 (0.559 sec/step)\n",
            "I0517 09:44:37.823702 139851376510848 learning.py:507] global step 6365: loss = 2.1720 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6366: loss = 1.7186 (0.555 sec/step)\n",
            "I0517 09:44:38.380818 139851376510848 learning.py:507] global step 6366: loss = 1.7186 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6367: loss = 1.9322 (0.568 sec/step)\n",
            "I0517 09:44:38.950893 139851376510848 learning.py:507] global step 6367: loss = 1.9322 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6368: loss = 3.1006 (0.598 sec/step)\n",
            "I0517 09:44:39.550351 139851376510848 learning.py:507] global step 6368: loss = 3.1006 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6369: loss = 1.6579 (0.569 sec/step)\n",
            "I0517 09:44:40.121447 139851376510848 learning.py:507] global step 6369: loss = 1.6579 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6370: loss = 1.6742 (0.573 sec/step)\n",
            "I0517 09:44:40.696399 139851376510848 learning.py:507] global step 6370: loss = 1.6742 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6371: loss = 2.1285 (0.551 sec/step)\n",
            "I0517 09:44:41.248908 139851376510848 learning.py:507] global step 6371: loss = 2.1285 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6372: loss = 1.7966 (0.551 sec/step)\n",
            "I0517 09:44:41.801885 139851376510848 learning.py:507] global step 6372: loss = 1.7966 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6373: loss = 1.7048 (0.546 sec/step)\n",
            "I0517 09:44:42.349545 139851376510848 learning.py:507] global step 6373: loss = 1.7048 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6374: loss = 3.1681 (0.548 sec/step)\n",
            "I0517 09:44:42.899893 139851376510848 learning.py:507] global step 6374: loss = 3.1681 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6375: loss = 2.6242 (0.552 sec/step)\n",
            "I0517 09:44:43.453724 139851376510848 learning.py:507] global step 6375: loss = 2.6242 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6376: loss = 1.5598 (0.580 sec/step)\n",
            "I0517 09:44:44.035679 139851376510848 learning.py:507] global step 6376: loss = 1.5598 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6377: loss = 1.9266 (0.596 sec/step)\n",
            "I0517 09:44:44.633454 139851376510848 learning.py:507] global step 6377: loss = 1.9266 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 6378: loss = 2.6735 (0.552 sec/step)\n",
            "I0517 09:44:45.187075 139851376510848 learning.py:507] global step 6378: loss = 2.6735 (0.552 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "I0517 09:44:45.556688 139847658321664 supervisor.py:1117] Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "INFO:tensorflow:global step 6379: loss = 2.1418 (1.507 sec/step)\n",
            "I0517 09:44:46.931208 139851376510848 learning.py:507] global step 6379: loss = 2.1418 (1.507 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6379.\n",
            "I0517 09:44:47.773707 139847641536256 supervisor.py:1050] Recording summary at step 6379.\n",
            "INFO:tensorflow:global step 6380: loss = 2.2717 (0.940 sec/step)\n",
            "I0517 09:44:47.975850 139851376510848 learning.py:507] global step 6380: loss = 2.2717 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 6381: loss = 1.4740 (1.085 sec/step)\n",
            "I0517 09:44:49.081623 139851376510848 learning.py:507] global step 6381: loss = 1.4740 (1.085 sec/step)\n",
            "INFO:tensorflow:global step 6382: loss = 2.1970 (0.699 sec/step)\n",
            "I0517 09:44:49.782332 139851376510848 learning.py:507] global step 6382: loss = 2.1970 (0.699 sec/step)\n",
            "INFO:tensorflow:global step 6383: loss = 1.3468 (0.550 sec/step)\n",
            "I0517 09:44:50.334200 139851376510848 learning.py:507] global step 6383: loss = 1.3468 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6384: loss = 2.8558 (0.593 sec/step)\n",
            "I0517 09:44:50.929271 139851376510848 learning.py:507] global step 6384: loss = 2.8558 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6385: loss = 2.2712 (0.565 sec/step)\n",
            "I0517 09:44:51.496757 139851376510848 learning.py:507] global step 6385: loss = 2.2712 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6386: loss = 1.6282 (0.599 sec/step)\n",
            "I0517 09:44:52.097953 139851376510848 learning.py:507] global step 6386: loss = 1.6282 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6387: loss = 1.4810 (0.579 sec/step)\n",
            "I0517 09:44:52.679119 139851376510848 learning.py:507] global step 6387: loss = 1.4810 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6388: loss = 1.6499 (0.557 sec/step)\n",
            "I0517 09:44:53.238100 139851376510848 learning.py:507] global step 6388: loss = 1.6499 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6389: loss = 2.1045 (0.563 sec/step)\n",
            "I0517 09:44:53.803118 139851376510848 learning.py:507] global step 6389: loss = 2.1045 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6390: loss = 2.8670 (0.572 sec/step)\n",
            "I0517 09:44:54.376965 139851376510848 learning.py:507] global step 6390: loss = 2.8670 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6391: loss = 2.9636 (0.576 sec/step)\n",
            "I0517 09:44:54.956513 139851376510848 learning.py:507] global step 6391: loss = 2.9636 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6392: loss = 1.6176 (0.600 sec/step)\n",
            "I0517 09:44:55.558322 139851376510848 learning.py:507] global step 6392: loss = 1.6176 (0.600 sec/step)\n",
            "INFO:tensorflow:global step 6393: loss = 3.0260 (0.565 sec/step)\n",
            "I0517 09:44:56.125541 139851376510848 learning.py:507] global step 6393: loss = 3.0260 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6394: loss = 3.3271 (0.582 sec/step)\n",
            "I0517 09:44:56.708887 139851376510848 learning.py:507] global step 6394: loss = 3.3271 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6395: loss = 2.0218 (0.621 sec/step)\n",
            "I0517 09:44:57.332078 139851376510848 learning.py:507] global step 6395: loss = 2.0218 (0.621 sec/step)\n",
            "INFO:tensorflow:global step 6396: loss = 2.0341 (0.594 sec/step)\n",
            "I0517 09:44:57.928006 139851376510848 learning.py:507] global step 6396: loss = 2.0341 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 6397: loss = 1.8629 (0.572 sec/step)\n",
            "I0517 09:44:58.501521 139851376510848 learning.py:507] global step 6397: loss = 1.8629 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6398: loss = 1.8432 (0.574 sec/step)\n",
            "I0517 09:44:59.077068 139851376510848 learning.py:507] global step 6398: loss = 1.8432 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6399: loss = 1.9742 (0.565 sec/step)\n",
            "I0517 09:44:59.643839 139851376510848 learning.py:507] global step 6399: loss = 1.9742 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6400: loss = 1.5750 (0.578 sec/step)\n",
            "I0517 09:45:00.224080 139851376510848 learning.py:507] global step 6400: loss = 1.5750 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6401: loss = 3.4556 (0.538 sec/step)\n",
            "I0517 09:45:00.763810 139851376510848 learning.py:507] global step 6401: loss = 3.4556 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6402: loss = 2.0235 (0.550 sec/step)\n",
            "I0517 09:45:01.315298 139851376510848 learning.py:507] global step 6402: loss = 2.0235 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6403: loss = 2.2815 (0.560 sec/step)\n",
            "I0517 09:45:01.877151 139851376510848 learning.py:507] global step 6403: loss = 2.2815 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6404: loss = 2.0005 (0.566 sec/step)\n",
            "I0517 09:45:02.444851 139851376510848 learning.py:507] global step 6404: loss = 2.0005 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6405: loss = 2.6630 (0.557 sec/step)\n",
            "I0517 09:45:03.003554 139851376510848 learning.py:507] global step 6405: loss = 2.6630 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6406: loss = 2.2894 (0.574 sec/step)\n",
            "I0517 09:45:03.579866 139851376510848 learning.py:507] global step 6406: loss = 2.2894 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6407: loss = 1.2334 (0.563 sec/step)\n",
            "I0517 09:45:04.144886 139851376510848 learning.py:507] global step 6407: loss = 1.2334 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6408: loss = 2.6726 (0.556 sec/step)\n",
            "I0517 09:45:04.703076 139851376510848 learning.py:507] global step 6408: loss = 2.6726 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6409: loss = 1.8481 (0.564 sec/step)\n",
            "I0517 09:45:05.269103 139851376510848 learning.py:507] global step 6409: loss = 1.8481 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6410: loss = 1.8683 (0.556 sec/step)\n",
            "I0517 09:45:05.826386 139851376510848 learning.py:507] global step 6410: loss = 1.8683 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6411: loss = 1.5850 (0.548 sec/step)\n",
            "I0517 09:45:06.376075 139851376510848 learning.py:507] global step 6411: loss = 1.5850 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6412: loss = 2.1135 (0.544 sec/step)\n",
            "I0517 09:45:06.921574 139851376510848 learning.py:507] global step 6412: loss = 2.1135 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6413: loss = 2.5233 (0.553 sec/step)\n",
            "I0517 09:45:07.476859 139851376510848 learning.py:507] global step 6413: loss = 2.5233 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6414: loss = 1.9063 (0.569 sec/step)\n",
            "I0517 09:45:08.047346 139851376510848 learning.py:507] global step 6414: loss = 1.9063 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6415: loss = 2.0467 (0.599 sec/step)\n",
            "I0517 09:45:08.648124 139851376510848 learning.py:507] global step 6415: loss = 2.0467 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6416: loss = 2.5126 (0.573 sec/step)\n",
            "I0517 09:45:09.223252 139851376510848 learning.py:507] global step 6416: loss = 2.5126 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6417: loss = 2.0025 (0.559 sec/step)\n",
            "I0517 09:45:09.784281 139851376510848 learning.py:507] global step 6417: loss = 2.0025 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6418: loss = 1.8108 (0.580 sec/step)\n",
            "I0517 09:45:10.366284 139851376510848 learning.py:507] global step 6418: loss = 1.8108 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6419: loss = 1.7196 (0.596 sec/step)\n",
            "I0517 09:45:10.964377 139851376510848 learning.py:507] global step 6419: loss = 1.7196 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 6420: loss = 2.1143 (0.588 sec/step)\n",
            "I0517 09:45:11.554553 139851376510848 learning.py:507] global step 6420: loss = 2.1143 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6421: loss = 2.2169 (0.599 sec/step)\n",
            "I0517 09:45:12.154994 139851376510848 learning.py:507] global step 6421: loss = 2.2169 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6422: loss = 2.2121 (0.605 sec/step)\n",
            "I0517 09:45:12.762329 139851376510848 learning.py:507] global step 6422: loss = 2.2121 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 6423: loss = 2.0255 (0.584 sec/step)\n",
            "I0517 09:45:13.349302 139851376510848 learning.py:507] global step 6423: loss = 2.0255 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6424: loss = 2.7514 (0.568 sec/step)\n",
            "I0517 09:45:13.922082 139851376510848 learning.py:507] global step 6424: loss = 2.7514 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6425: loss = 2.0135 (0.572 sec/step)\n",
            "I0517 09:45:14.496178 139851376510848 learning.py:507] global step 6425: loss = 2.0135 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6426: loss = 2.0257 (0.531 sec/step)\n",
            "I0517 09:45:15.029055 139851376510848 learning.py:507] global step 6426: loss = 2.0257 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 6427: loss = 2.2766 (0.587 sec/step)\n",
            "I0517 09:45:15.617863 139851376510848 learning.py:507] global step 6427: loss = 2.2766 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6428: loss = 2.1838 (0.542 sec/step)\n",
            "I0517 09:45:16.161867 139851376510848 learning.py:507] global step 6428: loss = 2.1838 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6429: loss = 3.5100 (0.591 sec/step)\n",
            "I0517 09:45:16.755025 139851376510848 learning.py:507] global step 6429: loss = 3.5100 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6430: loss = 2.4285 (0.553 sec/step)\n",
            "I0517 09:45:17.309517 139851376510848 learning.py:507] global step 6430: loss = 2.4285 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6431: loss = 2.9850 (0.554 sec/step)\n",
            "I0517 09:45:17.864900 139851376510848 learning.py:507] global step 6431: loss = 2.9850 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6432: loss = 1.2995 (0.602 sec/step)\n",
            "I0517 09:45:18.468890 139851376510848 learning.py:507] global step 6432: loss = 1.2995 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6433: loss = 1.7261 (0.569 sec/step)\n",
            "I0517 09:45:19.040576 139851376510848 learning.py:507] global step 6433: loss = 1.7261 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6434: loss = 2.2827 (0.574 sec/step)\n",
            "I0517 09:45:19.616437 139851376510848 learning.py:507] global step 6434: loss = 2.2827 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6435: loss = 1.6705 (0.561 sec/step)\n",
            "I0517 09:45:20.179600 139851376510848 learning.py:507] global step 6435: loss = 1.6705 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6436: loss = 1.6547 (0.577 sec/step)\n",
            "I0517 09:45:20.758548 139851376510848 learning.py:507] global step 6436: loss = 1.6547 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 6437: loss = 2.2484 (0.543 sec/step)\n",
            "I0517 09:45:21.303637 139851376510848 learning.py:507] global step 6437: loss = 2.2484 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6438: loss = 1.8564 (0.572 sec/step)\n",
            "I0517 09:45:21.877832 139851376510848 learning.py:507] global step 6438: loss = 1.8564 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6439: loss = 2.7436 (0.590 sec/step)\n",
            "I0517 09:45:22.470197 139851376510848 learning.py:507] global step 6439: loss = 2.7436 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6440: loss = 1.9879 (0.572 sec/step)\n",
            "I0517 09:45:23.044578 139851376510848 learning.py:507] global step 6440: loss = 1.9879 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6441: loss = 1.6920 (0.596 sec/step)\n",
            "I0517 09:45:23.642851 139851376510848 learning.py:507] global step 6441: loss = 1.6920 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 6442: loss = 2.3005 (0.544 sec/step)\n",
            "I0517 09:45:24.188707 139851376510848 learning.py:507] global step 6442: loss = 2.3005 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6443: loss = 2.1832 (0.573 sec/step)\n",
            "I0517 09:45:24.763492 139851376510848 learning.py:507] global step 6443: loss = 2.1832 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6444: loss = 2.9505 (0.547 sec/step)\n",
            "I0517 09:45:25.312613 139851376510848 learning.py:507] global step 6444: loss = 2.9505 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6445: loss = 1.8496 (0.573 sec/step)\n",
            "I0517 09:45:25.887781 139851376510848 learning.py:507] global step 6445: loss = 1.8496 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6446: loss = 1.8873 (0.557 sec/step)\n",
            "I0517 09:45:26.446941 139851376510848 learning.py:507] global step 6446: loss = 1.8873 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6447: loss = 1.7521 (0.589 sec/step)\n",
            "I0517 09:45:27.037448 139851376510848 learning.py:507] global step 6447: loss = 1.7521 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6448: loss = 1.5217 (0.582 sec/step)\n",
            "I0517 09:45:27.621417 139851376510848 learning.py:507] global step 6448: loss = 1.5217 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6449: loss = 2.2230 (0.587 sec/step)\n",
            "I0517 09:45:28.210561 139851376510848 learning.py:507] global step 6449: loss = 2.2230 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6450: loss = 1.7663 (0.579 sec/step)\n",
            "I0517 09:45:28.791569 139851376510848 learning.py:507] global step 6450: loss = 1.7663 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6451: loss = 1.6929 (0.591 sec/step)\n",
            "I0517 09:45:29.384268 139851376510848 learning.py:507] global step 6451: loss = 1.6929 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6452: loss = 1.7378 (0.585 sec/step)\n",
            "I0517 09:45:29.971248 139851376510848 learning.py:507] global step 6452: loss = 1.7378 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 6453: loss = 2.1896 (0.543 sec/step)\n",
            "I0517 09:45:30.515858 139851376510848 learning.py:507] global step 6453: loss = 2.1896 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6454: loss = 2.5186 (0.585 sec/step)\n",
            "I0517 09:45:31.102959 139851376510848 learning.py:507] global step 6454: loss = 2.5186 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 6455: loss = 1.9956 (0.562 sec/step)\n",
            "I0517 09:45:31.666662 139851376510848 learning.py:507] global step 6455: loss = 1.9956 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6456: loss = 2.1666 (0.587 sec/step)\n",
            "I0517 09:45:32.255866 139851376510848 learning.py:507] global step 6456: loss = 2.1666 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6457: loss = 2.0006 (0.602 sec/step)\n",
            "I0517 09:45:32.859483 139851376510848 learning.py:507] global step 6457: loss = 2.0006 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6458: loss = 1.2632 (0.553 sec/step)\n",
            "I0517 09:45:33.414645 139851376510848 learning.py:507] global step 6458: loss = 1.2632 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6459: loss = 1.7137 (0.583 sec/step)\n",
            "I0517 09:45:33.999313 139851376510848 learning.py:507] global step 6459: loss = 1.7137 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6460: loss = 3.2092 (0.560 sec/step)\n",
            "I0517 09:45:34.561175 139851376510848 learning.py:507] global step 6460: loss = 3.2092 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6461: loss = 1.7878 (0.566 sec/step)\n",
            "I0517 09:45:35.128959 139851376510848 learning.py:507] global step 6461: loss = 1.7878 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6462: loss = 2.3526 (0.537 sec/step)\n",
            "I0517 09:45:35.667846 139851376510848 learning.py:507] global step 6462: loss = 2.3526 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6463: loss = 2.0734 (0.583 sec/step)\n",
            "I0517 09:45:36.252330 139851376510848 learning.py:507] global step 6463: loss = 2.0734 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6464: loss = 2.6223 (0.558 sec/step)\n",
            "I0517 09:45:36.811958 139851376510848 learning.py:507] global step 6464: loss = 2.6223 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6465: loss = 1.7071 (0.546 sec/step)\n",
            "I0517 09:45:37.359730 139851376510848 learning.py:507] global step 6465: loss = 1.7071 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6466: loss = 1.7654 (0.581 sec/step)\n",
            "I0517 09:45:37.941993 139851376510848 learning.py:507] global step 6466: loss = 1.7654 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 6467: loss = 3.2754 (0.552 sec/step)\n",
            "I0517 09:45:38.495432 139851376510848 learning.py:507] global step 6467: loss = 3.2754 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6468: loss = 2.1665 (0.546 sec/step)\n",
            "I0517 09:45:39.042877 139851376510848 learning.py:507] global step 6468: loss = 2.1665 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6469: loss = 2.0867 (0.516 sec/step)\n",
            "I0517 09:45:39.561565 139851376510848 learning.py:507] global step 6469: loss = 2.0867 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 6470: loss = 1.3995 (0.582 sec/step)\n",
            "I0517 09:45:40.145107 139851376510848 learning.py:507] global step 6470: loss = 1.3995 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6471: loss = 2.2616 (0.566 sec/step)\n",
            "I0517 09:45:40.713146 139851376510848 learning.py:507] global step 6471: loss = 2.2616 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6472: loss = 2.2427 (0.584 sec/step)\n",
            "I0517 09:45:41.299200 139851376510848 learning.py:507] global step 6472: loss = 2.2427 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6473: loss = 2.0272 (0.548 sec/step)\n",
            "I0517 09:45:41.849447 139851376510848 learning.py:507] global step 6473: loss = 2.0272 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6474: loss = 2.1309 (0.555 sec/step)\n",
            "I0517 09:45:42.406105 139851376510848 learning.py:507] global step 6474: loss = 2.1309 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6475: loss = 1.6419 (0.562 sec/step)\n",
            "I0517 09:45:42.972754 139851376510848 learning.py:507] global step 6475: loss = 1.6419 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6476: loss = 1.7718 (0.557 sec/step)\n",
            "I0517 09:45:43.531754 139851376510848 learning.py:507] global step 6476: loss = 1.7718 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6477: loss = 2.6457 (0.573 sec/step)\n",
            "I0517 09:45:44.106788 139851376510848 learning.py:507] global step 6477: loss = 2.6457 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6478: loss = 2.4438 (0.536 sec/step)\n",
            "I0517 09:45:44.645699 139851376510848 learning.py:507] global step 6478: loss = 2.4438 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6479: loss = 1.9993 (0.591 sec/step)\n",
            "I0517 09:45:45.238092 139851376510848 learning.py:507] global step 6479: loss = 1.9993 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6480: loss = 2.0931 (0.570 sec/step)\n",
            "I0517 09:45:45.810989 139851376510848 learning.py:507] global step 6480: loss = 2.0931 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6481: loss = 1.7632 (0.584 sec/step)\n",
            "I0517 09:45:46.397200 139851376510848 learning.py:507] global step 6481: loss = 1.7632 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6482: loss = 1.9025 (0.576 sec/step)\n",
            "I0517 09:45:46.975599 139851376510848 learning.py:507] global step 6482: loss = 1.9025 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6483: loss = 1.9394 (0.557 sec/step)\n",
            "I0517 09:45:47.534433 139851376510848 learning.py:507] global step 6483: loss = 1.9394 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6484: loss = 1.7363 (0.563 sec/step)\n",
            "I0517 09:45:48.103428 139851376510848 learning.py:507] global step 6484: loss = 1.7363 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6485: loss = 1.9521 (0.572 sec/step)\n",
            "I0517 09:45:48.682721 139851376510848 learning.py:507] global step 6485: loss = 1.9521 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6486: loss = 2.7934 (0.574 sec/step)\n",
            "I0517 09:45:49.258420 139851376510848 learning.py:507] global step 6486: loss = 2.7934 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6487: loss = 1.7922 (0.568 sec/step)\n",
            "I0517 09:45:49.828519 139851376510848 learning.py:507] global step 6487: loss = 1.7922 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6488: loss = 2.8517 (0.598 sec/step)\n",
            "I0517 09:45:50.428280 139851376510848 learning.py:507] global step 6488: loss = 2.8517 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6489: loss = 3.2247 (0.540 sec/step)\n",
            "I0517 09:45:50.970450 139851376510848 learning.py:507] global step 6489: loss = 3.2247 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6490: loss = 2.6662 (0.599 sec/step)\n",
            "I0517 09:45:51.571208 139851376510848 learning.py:507] global step 6490: loss = 2.6662 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6491: loss = 1.7629 (0.567 sec/step)\n",
            "I0517 09:45:52.140581 139851376510848 learning.py:507] global step 6491: loss = 1.7629 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6492: loss = 2.5784 (0.604 sec/step)\n",
            "I0517 09:45:52.746331 139851376510848 learning.py:507] global step 6492: loss = 2.5784 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 6493: loss = 3.6135 (0.568 sec/step)\n",
            "I0517 09:45:53.316273 139851376510848 learning.py:507] global step 6493: loss = 3.6135 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6494: loss = 1.7544 (0.550 sec/step)\n",
            "I0517 09:45:53.867997 139851376510848 learning.py:507] global step 6494: loss = 1.7544 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6495: loss = 2.1310 (0.551 sec/step)\n",
            "I0517 09:45:54.420894 139851376510848 learning.py:507] global step 6495: loss = 2.1310 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6496: loss = 2.1370 (0.552 sec/step)\n",
            "I0517 09:45:54.974374 139851376510848 learning.py:507] global step 6496: loss = 2.1370 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6497: loss = 1.7750 (0.567 sec/step)\n",
            "I0517 09:45:55.543208 139851376510848 learning.py:507] global step 6497: loss = 1.7750 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6498: loss = 2.0671 (0.557 sec/step)\n",
            "I0517 09:45:56.102051 139851376510848 learning.py:507] global step 6498: loss = 2.0671 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6499: loss = 1.5045 (0.611 sec/step)\n",
            "I0517 09:45:56.714928 139851376510848 learning.py:507] global step 6499: loss = 1.5045 (0.611 sec/step)\n",
            "INFO:tensorflow:global step 6500: loss = 1.9416 (0.560 sec/step)\n",
            "I0517 09:45:57.277121 139851376510848 learning.py:507] global step 6500: loss = 1.9416 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6501: loss = 1.7996 (0.554 sec/step)\n",
            "I0517 09:45:57.833378 139851376510848 learning.py:507] global step 6501: loss = 1.7996 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6502: loss = 2.5761 (0.569 sec/step)\n",
            "I0517 09:45:58.406488 139851376510848 learning.py:507] global step 6502: loss = 2.5761 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6503: loss = 2.0945 (0.548 sec/step)\n",
            "I0517 09:45:58.956410 139851376510848 learning.py:507] global step 6503: loss = 2.0945 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6504: loss = 3.8361 (0.599 sec/step)\n",
            "I0517 09:45:59.557396 139851376510848 learning.py:507] global step 6504: loss = 3.8361 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6505: loss = 1.6168 (0.557 sec/step)\n",
            "I0517 09:46:00.115922 139851376510848 learning.py:507] global step 6505: loss = 1.6168 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6506: loss = 2.0423 (0.595 sec/step)\n",
            "I0517 09:46:00.712942 139851376510848 learning.py:507] global step 6506: loss = 2.0423 (0.595 sec/step)\n",
            "INFO:tensorflow:global step 6507: loss = 2.2381 (0.564 sec/step)\n",
            "I0517 09:46:01.278732 139851376510848 learning.py:507] global step 6507: loss = 2.2381 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6508: loss = 2.1198 (0.566 sec/step)\n",
            "I0517 09:46:01.845990 139851376510848 learning.py:507] global step 6508: loss = 2.1198 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6509: loss = 2.5934 (0.569 sec/step)\n",
            "I0517 09:46:02.417107 139851376510848 learning.py:507] global step 6509: loss = 2.5934 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6510: loss = 2.3386 (0.543 sec/step)\n",
            "I0517 09:46:02.962686 139851376510848 learning.py:507] global step 6510: loss = 2.3386 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6511: loss = 1.8602 (0.578 sec/step)\n",
            "I0517 09:46:03.548211 139851376510848 learning.py:507] global step 6511: loss = 1.8602 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6512: loss = 2.1479 (0.574 sec/step)\n",
            "I0517 09:46:04.123805 139851376510848 learning.py:507] global step 6512: loss = 2.1479 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6513: loss = 2.6893 (0.567 sec/step)\n",
            "I0517 09:46:04.692631 139851376510848 learning.py:507] global step 6513: loss = 2.6893 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6514: loss = 2.0363 (0.572 sec/step)\n",
            "I0517 09:46:05.266433 139851376510848 learning.py:507] global step 6514: loss = 2.0363 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6515: loss = 2.5622 (0.608 sec/step)\n",
            "I0517 09:46:05.876302 139851376510848 learning.py:507] global step 6515: loss = 2.5622 (0.608 sec/step)\n",
            "INFO:tensorflow:global step 6516: loss = 2.0241 (0.565 sec/step)\n",
            "I0517 09:46:06.443342 139851376510848 learning.py:507] global step 6516: loss = 2.0241 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6517: loss = 2.0292 (0.581 sec/step)\n",
            "I0517 09:46:07.027498 139851376510848 learning.py:507] global step 6517: loss = 2.0292 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 6518: loss = 2.7342 (0.542 sec/step)\n",
            "I0517 09:46:07.570721 139851376510848 learning.py:507] global step 6518: loss = 2.7342 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6519: loss = 1.5603 (0.578 sec/step)\n",
            "I0517 09:46:08.151424 139851376510848 learning.py:507] global step 6519: loss = 1.5603 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6520: loss = 1.4264 (0.541 sec/step)\n",
            "I0517 09:46:08.695026 139851376510848 learning.py:507] global step 6520: loss = 1.4264 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6521: loss = 2.2825 (0.541 sec/step)\n",
            "I0517 09:46:09.238720 139851376510848 learning.py:507] global step 6521: loss = 2.2825 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6522: loss = 1.6059 (0.574 sec/step)\n",
            "I0517 09:46:09.814126 139851376510848 learning.py:507] global step 6522: loss = 1.6059 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6523: loss = 2.0716 (0.548 sec/step)\n",
            "I0517 09:46:10.363997 139851376510848 learning.py:507] global step 6523: loss = 2.0716 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6524: loss = 1.9467 (0.590 sec/step)\n",
            "I0517 09:46:10.956192 139851376510848 learning.py:507] global step 6524: loss = 1.9467 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6525: loss = 1.7967 (0.583 sec/step)\n",
            "I0517 09:46:11.540443 139851376510848 learning.py:507] global step 6525: loss = 1.7967 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6526: loss = 1.8937 (0.548 sec/step)\n",
            "I0517 09:46:12.090266 139851376510848 learning.py:507] global step 6526: loss = 1.8937 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6527: loss = 1.8046 (0.556 sec/step)\n",
            "I0517 09:46:12.648015 139851376510848 learning.py:507] global step 6527: loss = 1.8046 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6528: loss = 2.1285 (0.557 sec/step)\n",
            "I0517 09:46:13.207025 139851376510848 learning.py:507] global step 6528: loss = 2.1285 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6529: loss = 1.6686 (0.589 sec/step)\n",
            "I0517 09:46:13.798072 139851376510848 learning.py:507] global step 6529: loss = 1.6686 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6530: loss = 1.4030 (0.573 sec/step)\n",
            "I0517 09:46:14.374066 139851376510848 learning.py:507] global step 6530: loss = 1.4030 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6531: loss = 2.2803 (0.565 sec/step)\n",
            "I0517 09:46:14.941445 139851376510848 learning.py:507] global step 6531: loss = 2.2803 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6532: loss = 1.7111 (0.556 sec/step)\n",
            "I0517 09:46:15.499628 139851376510848 learning.py:507] global step 6532: loss = 1.7111 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6533: loss = 1.7063 (0.555 sec/step)\n",
            "I0517 09:46:16.056052 139851376510848 learning.py:507] global step 6533: loss = 1.7063 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6534: loss = 1.7757 (0.552 sec/step)\n",
            "I0517 09:46:16.611172 139851376510848 learning.py:507] global step 6534: loss = 1.7757 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6535: loss = 2.4661 (0.598 sec/step)\n",
            "I0517 09:46:17.211025 139851376510848 learning.py:507] global step 6535: loss = 2.4661 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6536: loss = 1.8311 (0.599 sec/step)\n",
            "I0517 09:46:17.812114 139851376510848 learning.py:507] global step 6536: loss = 1.8311 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6537: loss = 1.7050 (0.580 sec/step)\n",
            "I0517 09:46:18.393981 139851376510848 learning.py:507] global step 6537: loss = 1.7050 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6538: loss = 1.7535 (0.550 sec/step)\n",
            "I0517 09:46:18.945757 139851376510848 learning.py:507] global step 6538: loss = 1.7535 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6539: loss = 1.5213 (0.571 sec/step)\n",
            "I0517 09:46:19.518410 139851376510848 learning.py:507] global step 6539: loss = 1.5213 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6540: loss = 2.0024 (0.551 sec/step)\n",
            "I0517 09:46:20.071278 139851376510848 learning.py:507] global step 6540: loss = 2.0024 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6541: loss = 2.0148 (0.531 sec/step)\n",
            "I0517 09:46:20.604591 139851376510848 learning.py:507] global step 6541: loss = 2.0148 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 6542: loss = 1.4568 (0.566 sec/step)\n",
            "I0517 09:46:21.172264 139851376510848 learning.py:507] global step 6542: loss = 1.4568 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6543: loss = 2.0616 (0.560 sec/step)\n",
            "I0517 09:46:21.734122 139851376510848 learning.py:507] global step 6543: loss = 2.0616 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6544: loss = 1.4726 (0.570 sec/step)\n",
            "I0517 09:46:22.305754 139851376510848 learning.py:507] global step 6544: loss = 1.4726 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6545: loss = 1.6974 (0.585 sec/step)\n",
            "I0517 09:46:22.892803 139851376510848 learning.py:507] global step 6545: loss = 1.6974 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 6546: loss = 1.6542 (0.576 sec/step)\n",
            "I0517 09:46:23.470998 139851376510848 learning.py:507] global step 6546: loss = 1.6542 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6547: loss = 3.2341 (0.567 sec/step)\n",
            "I0517 09:46:24.039493 139851376510848 learning.py:507] global step 6547: loss = 3.2341 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6548: loss = 3.4618 (0.550 sec/step)\n",
            "I0517 09:46:24.591342 139851376510848 learning.py:507] global step 6548: loss = 3.4618 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6549: loss = 2.4790 (0.576 sec/step)\n",
            "I0517 09:46:25.169174 139851376510848 learning.py:507] global step 6549: loss = 2.4790 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6550: loss = 2.2325 (0.574 sec/step)\n",
            "I0517 09:46:25.745583 139851376510848 learning.py:507] global step 6550: loss = 2.2325 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6551: loss = 2.2492 (0.578 sec/step)\n",
            "I0517 09:46:26.325857 139851376510848 learning.py:507] global step 6551: loss = 2.2492 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6552: loss = 1.9140 (0.601 sec/step)\n",
            "I0517 09:46:26.928625 139851376510848 learning.py:507] global step 6552: loss = 1.9140 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 6553: loss = 2.4184 (0.571 sec/step)\n",
            "I0517 09:46:27.501995 139851376510848 learning.py:507] global step 6553: loss = 2.4184 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6554: loss = 2.1324 (0.541 sec/step)\n",
            "I0517 09:46:28.044605 139851376510848 learning.py:507] global step 6554: loss = 2.1324 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6555: loss = 2.0464 (0.568 sec/step)\n",
            "I0517 09:46:28.614173 139851376510848 learning.py:507] global step 6555: loss = 2.0464 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6556: loss = 3.1763 (0.541 sec/step)\n",
            "I0517 09:46:29.157115 139851376510848 learning.py:507] global step 6556: loss = 3.1763 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6557: loss = 2.3498 (0.574 sec/step)\n",
            "I0517 09:46:29.734126 139851376510848 learning.py:507] global step 6557: loss = 2.3498 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6558: loss = 3.7914 (0.590 sec/step)\n",
            "I0517 09:46:30.326199 139851376510848 learning.py:507] global step 6558: loss = 3.7914 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6559: loss = 2.4422 (0.559 sec/step)\n",
            "I0517 09:46:30.886883 139851376510848 learning.py:507] global step 6559: loss = 2.4422 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6560: loss = 1.7697 (0.557 sec/step)\n",
            "I0517 09:46:31.445958 139851376510848 learning.py:507] global step 6560: loss = 1.7697 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6561: loss = 2.3082 (0.583 sec/step)\n",
            "I0517 09:46:32.030452 139851376510848 learning.py:507] global step 6561: loss = 2.3082 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6562: loss = 2.3574 (0.575 sec/step)\n",
            "I0517 09:46:32.607196 139851376510848 learning.py:507] global step 6562: loss = 2.3574 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6563: loss = 1.5096 (0.565 sec/step)\n",
            "I0517 09:46:33.173952 139851376510848 learning.py:507] global step 6563: loss = 1.5096 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6564: loss = 1.7499 (0.573 sec/step)\n",
            "I0517 09:46:33.749137 139851376510848 learning.py:507] global step 6564: loss = 1.7499 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6565: loss = 1.5475 (0.557 sec/step)\n",
            "I0517 09:46:34.307856 139851376510848 learning.py:507] global step 6565: loss = 1.5475 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6566: loss = 1.8493 (0.570 sec/step)\n",
            "I0517 09:46:34.879177 139851376510848 learning.py:507] global step 6566: loss = 1.8493 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6567: loss = 2.1290 (0.544 sec/step)\n",
            "I0517 09:46:35.425008 139851376510848 learning.py:507] global step 6567: loss = 2.1290 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6568: loss = 2.6709 (0.558 sec/step)\n",
            "I0517 09:46:35.984718 139851376510848 learning.py:507] global step 6568: loss = 2.6709 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6569: loss = 2.1452 (0.570 sec/step)\n",
            "I0517 09:46:36.556044 139851376510848 learning.py:507] global step 6569: loss = 2.1452 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6570: loss = 2.3322 (0.566 sec/step)\n",
            "I0517 09:46:37.125392 139851376510848 learning.py:507] global step 6570: loss = 2.3322 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6571: loss = 1.7596 (0.575 sec/step)\n",
            "I0517 09:46:37.702330 139851376510848 learning.py:507] global step 6571: loss = 1.7596 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6572: loss = 1.6271 (0.565 sec/step)\n",
            "I0517 09:46:38.269461 139851376510848 learning.py:507] global step 6572: loss = 1.6271 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6573: loss = 2.0539 (0.564 sec/step)\n",
            "I0517 09:46:38.835386 139851376510848 learning.py:507] global step 6573: loss = 2.0539 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6574: loss = 1.5529 (0.578 sec/step)\n",
            "I0517 09:46:39.415529 139851376510848 learning.py:507] global step 6574: loss = 1.5529 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6575: loss = 2.1476 (0.603 sec/step)\n",
            "I0517 09:46:40.020537 139851376510848 learning.py:507] global step 6575: loss = 2.1476 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 6576: loss = 2.2414 (0.565 sec/step)\n",
            "I0517 09:46:40.587063 139851376510848 learning.py:507] global step 6576: loss = 2.2414 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6577: loss = 2.4914 (0.565 sec/step)\n",
            "I0517 09:46:41.153562 139851376510848 learning.py:507] global step 6577: loss = 2.4914 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6578: loss = 2.3091 (0.586 sec/step)\n",
            "I0517 09:46:41.740902 139851376510848 learning.py:507] global step 6578: loss = 2.3091 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 6579: loss = 2.3048 (0.567 sec/step)\n",
            "I0517 09:46:42.310291 139851376510848 learning.py:507] global step 6579: loss = 2.3048 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6580: loss = 2.1597 (0.580 sec/step)\n",
            "I0517 09:46:42.891793 139851376510848 learning.py:507] global step 6580: loss = 2.1597 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6581: loss = 1.7505 (0.598 sec/step)\n",
            "I0517 09:46:43.491921 139851376510848 learning.py:507] global step 6581: loss = 1.7505 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6582: loss = 2.5644 (0.566 sec/step)\n",
            "I0517 09:46:44.059724 139851376510848 learning.py:507] global step 6582: loss = 2.5644 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6583: loss = 4.5365 (0.560 sec/step)\n",
            "I0517 09:46:44.621400 139851376510848 learning.py:507] global step 6583: loss = 4.5365 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6584: loss = 2.1069 (0.607 sec/step)\n",
            "I0517 09:46:45.229907 139851376510848 learning.py:507] global step 6584: loss = 2.1069 (0.607 sec/step)\n",
            "INFO:tensorflow:global step 6585: loss = 2.4992 (0.742 sec/step)\n",
            "I0517 09:46:45.991517 139851376510848 learning.py:507] global step 6585: loss = 2.4992 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 6586: loss = 1.9904 (1.139 sec/step)\n",
            "I0517 09:46:47.163669 139851376510848 learning.py:507] global step 6586: loss = 1.9904 (1.139 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6586.\n",
            "I0517 09:46:47.366129 139847641536256 supervisor.py:1050] Recording summary at step 6586.\n",
            "INFO:tensorflow:global step 6587: loss = 1.9426 (0.599 sec/step)\n",
            "I0517 09:46:47.764818 139851376510848 learning.py:507] global step 6587: loss = 1.9426 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 6588: loss = 2.3763 (0.583 sec/step)\n",
            "I0517 09:46:48.349505 139851376510848 learning.py:507] global step 6588: loss = 2.3763 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6589: loss = 2.1038 (0.544 sec/step)\n",
            "I0517 09:46:48.894959 139851376510848 learning.py:507] global step 6589: loss = 2.1038 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6590: loss = 1.7157 (0.576 sec/step)\n",
            "I0517 09:46:49.472597 139851376510848 learning.py:507] global step 6590: loss = 1.7157 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6591: loss = 1.8206 (0.569 sec/step)\n",
            "I0517 09:46:50.043233 139851376510848 learning.py:507] global step 6591: loss = 1.8206 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6592: loss = 1.9763 (0.550 sec/step)\n",
            "I0517 09:46:50.594558 139851376510848 learning.py:507] global step 6592: loss = 1.9763 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6593: loss = 2.6190 (0.553 sec/step)\n",
            "I0517 09:46:51.150011 139851376510848 learning.py:507] global step 6593: loss = 2.6190 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6594: loss = 1.9182 (0.571 sec/step)\n",
            "I0517 09:46:51.723092 139851376510848 learning.py:507] global step 6594: loss = 1.9182 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6595: loss = 1.5087 (0.619 sec/step)\n",
            "I0517 09:46:52.344216 139851376510848 learning.py:507] global step 6595: loss = 1.5087 (0.619 sec/step)\n",
            "INFO:tensorflow:global step 6596: loss = 1.3953 (0.623 sec/step)\n",
            "I0517 09:46:52.970560 139851376510848 learning.py:507] global step 6596: loss = 1.3953 (0.623 sec/step)\n",
            "INFO:tensorflow:global step 6597: loss = 2.1170 (0.593 sec/step)\n",
            "I0517 09:46:53.565824 139851376510848 learning.py:507] global step 6597: loss = 2.1170 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6598: loss = 1.7760 (0.539 sec/step)\n",
            "I0517 09:46:54.107102 139851376510848 learning.py:507] global step 6598: loss = 1.7760 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 6599: loss = 1.9117 (0.593 sec/step)\n",
            "I0517 09:46:54.702020 139851376510848 learning.py:507] global step 6599: loss = 1.9117 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6600: loss = 1.5827 (0.579 sec/step)\n",
            "I0517 09:46:55.283470 139851376510848 learning.py:507] global step 6600: loss = 1.5827 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6601: loss = 2.1980 (0.560 sec/step)\n",
            "I0517 09:46:55.845284 139851376510848 learning.py:507] global step 6601: loss = 2.1980 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6602: loss = 2.3483 (0.590 sec/step)\n",
            "I0517 09:46:56.436936 139851376510848 learning.py:507] global step 6602: loss = 2.3483 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6603: loss = 3.1000 (0.577 sec/step)\n",
            "I0517 09:46:57.016144 139851376510848 learning.py:507] global step 6603: loss = 3.1000 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 6604: loss = 2.5280 (0.549 sec/step)\n",
            "I0517 09:46:57.566679 139851376510848 learning.py:507] global step 6604: loss = 2.5280 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6605: loss = 1.8022 (0.571 sec/step)\n",
            "I0517 09:46:58.140281 139851376510848 learning.py:507] global step 6605: loss = 1.8022 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6606: loss = 2.2612 (0.554 sec/step)\n",
            "I0517 09:46:58.696653 139851376510848 learning.py:507] global step 6606: loss = 2.2612 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6607: loss = 3.2983 (0.574 sec/step)\n",
            "I0517 09:46:59.272992 139851376510848 learning.py:507] global step 6607: loss = 3.2983 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6608: loss = 1.3389 (0.528 sec/step)\n",
            "I0517 09:46:59.802619 139851376510848 learning.py:507] global step 6608: loss = 1.3389 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 6609: loss = 2.3323 (0.567 sec/step)\n",
            "I0517 09:47:00.371661 139851376510848 learning.py:507] global step 6609: loss = 2.3323 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6610: loss = 1.9481 (0.536 sec/step)\n",
            "I0517 09:47:00.909845 139851376510848 learning.py:507] global step 6610: loss = 1.9481 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6611: loss = 2.1700 (0.576 sec/step)\n",
            "I0517 09:47:01.487509 139851376510848 learning.py:507] global step 6611: loss = 2.1700 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6612: loss = 1.6947 (0.535 sec/step)\n",
            "I0517 09:47:02.024554 139851376510848 learning.py:507] global step 6612: loss = 1.6947 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6613: loss = 2.3615 (0.580 sec/step)\n",
            "I0517 09:47:02.606587 139851376510848 learning.py:507] global step 6613: loss = 2.3615 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6614: loss = 1.8389 (0.549 sec/step)\n",
            "I0517 09:47:03.157064 139851376510848 learning.py:507] global step 6614: loss = 1.8389 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6615: loss = 1.5757 (0.620 sec/step)\n",
            "I0517 09:47:03.778599 139851376510848 learning.py:507] global step 6615: loss = 1.5757 (0.620 sec/step)\n",
            "INFO:tensorflow:global step 6616: loss = 1.8035 (0.524 sec/step)\n",
            "I0517 09:47:04.303954 139851376510848 learning.py:507] global step 6616: loss = 1.8035 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 6617: loss = 2.0741 (0.543 sec/step)\n",
            "I0517 09:47:04.848697 139851376510848 learning.py:507] global step 6617: loss = 2.0741 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6618: loss = 1.8663 (0.546 sec/step)\n",
            "I0517 09:47:05.396582 139851376510848 learning.py:507] global step 6618: loss = 1.8663 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6619: loss = 1.6761 (0.554 sec/step)\n",
            "I0517 09:47:05.951979 139851376510848 learning.py:507] global step 6619: loss = 1.6761 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6620: loss = 1.7541 (0.589 sec/step)\n",
            "I0517 09:47:06.543192 139851376510848 learning.py:507] global step 6620: loss = 1.7541 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6621: loss = 3.2612 (0.570 sec/step)\n",
            "I0517 09:47:07.114729 139851376510848 learning.py:507] global step 6621: loss = 3.2612 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6622: loss = 1.9000 (0.568 sec/step)\n",
            "I0517 09:47:07.684666 139851376510848 learning.py:507] global step 6622: loss = 1.9000 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6623: loss = 2.0940 (0.568 sec/step)\n",
            "I0517 09:47:08.254404 139851376510848 learning.py:507] global step 6623: loss = 2.0940 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6624: loss = 2.0207 (0.554 sec/step)\n",
            "I0517 09:47:08.810187 139851376510848 learning.py:507] global step 6624: loss = 2.0207 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6625: loss = 1.6436 (0.548 sec/step)\n",
            "I0517 09:47:09.359888 139851376510848 learning.py:507] global step 6625: loss = 1.6436 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6626: loss = 2.4607 (0.560 sec/step)\n",
            "I0517 09:47:09.921385 139851376510848 learning.py:507] global step 6626: loss = 2.4607 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6627: loss = 2.0092 (0.546 sec/step)\n",
            "I0517 09:47:10.468955 139851376510848 learning.py:507] global step 6627: loss = 2.0092 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6628: loss = 1.8994 (0.554 sec/step)\n",
            "I0517 09:47:11.025158 139851376510848 learning.py:507] global step 6628: loss = 1.8994 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6629: loss = 2.9055 (0.571 sec/step)\n",
            "I0517 09:47:11.599062 139851376510848 learning.py:507] global step 6629: loss = 2.9055 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6630: loss = 1.7368 (0.551 sec/step)\n",
            "I0517 09:47:12.156013 139851376510848 learning.py:507] global step 6630: loss = 1.7368 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6631: loss = 1.9975 (0.546 sec/step)\n",
            "I0517 09:47:12.703655 139851376510848 learning.py:507] global step 6631: loss = 1.9975 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6632: loss = 1.8652 (0.560 sec/step)\n",
            "I0517 09:47:13.264869 139851376510848 learning.py:507] global step 6632: loss = 1.8652 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6633: loss = 1.5335 (0.589 sec/step)\n",
            "I0517 09:47:13.855481 139851376510848 learning.py:507] global step 6633: loss = 1.5335 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6634: loss = 1.7486 (0.591 sec/step)\n",
            "I0517 09:47:14.448367 139851376510848 learning.py:507] global step 6634: loss = 1.7486 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6635: loss = 2.4668 (0.561 sec/step)\n",
            "I0517 09:47:15.010630 139851376510848 learning.py:507] global step 6635: loss = 2.4668 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6636: loss = 1.6079 (0.540 sec/step)\n",
            "I0517 09:47:15.552604 139851376510848 learning.py:507] global step 6636: loss = 1.6079 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6637: loss = 2.5883 (0.568 sec/step)\n",
            "I0517 09:47:16.122356 139851376510848 learning.py:507] global step 6637: loss = 2.5883 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6638: loss = 2.0679 (0.540 sec/step)\n",
            "I0517 09:47:16.664144 139851376510848 learning.py:507] global step 6638: loss = 2.0679 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6639: loss = 2.4395 (0.573 sec/step)\n",
            "I0517 09:47:17.239084 139851376510848 learning.py:507] global step 6639: loss = 2.4395 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6640: loss = 2.9784 (0.561 sec/step)\n",
            "I0517 09:47:17.801377 139851376510848 learning.py:507] global step 6640: loss = 2.9784 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6641: loss = 2.1643 (0.573 sec/step)\n",
            "I0517 09:47:18.376120 139851376510848 learning.py:507] global step 6641: loss = 2.1643 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6642: loss = 2.1468 (0.548 sec/step)\n",
            "I0517 09:47:18.925655 139851376510848 learning.py:507] global step 6642: loss = 2.1468 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6643: loss = 2.0011 (0.535 sec/step)\n",
            "I0517 09:47:19.462532 139851376510848 learning.py:507] global step 6643: loss = 2.0011 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6644: loss = 2.2810 (0.561 sec/step)\n",
            "I0517 09:47:20.025012 139851376510848 learning.py:507] global step 6644: loss = 2.2810 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6645: loss = 1.7190 (0.557 sec/step)\n",
            "I0517 09:47:20.583322 139851376510848 learning.py:507] global step 6645: loss = 1.7190 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6646: loss = 1.5426 (0.580 sec/step)\n",
            "I0517 09:47:21.165102 139851376510848 learning.py:507] global step 6646: loss = 1.5426 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6647: loss = 1.6460 (0.541 sec/step)\n",
            "I0517 09:47:21.708331 139851376510848 learning.py:507] global step 6647: loss = 1.6460 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6648: loss = 1.9009 (0.560 sec/step)\n",
            "I0517 09:47:22.269626 139851376510848 learning.py:507] global step 6648: loss = 1.9009 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6649: loss = 2.1530 (0.559 sec/step)\n",
            "I0517 09:47:22.829810 139851376510848 learning.py:507] global step 6649: loss = 2.1530 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6650: loss = 1.5717 (0.547 sec/step)\n",
            "I0517 09:47:23.378961 139851376510848 learning.py:507] global step 6650: loss = 1.5717 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6651: loss = 2.7058 (0.549 sec/step)\n",
            "I0517 09:47:23.930153 139851376510848 learning.py:507] global step 6651: loss = 2.7058 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6652: loss = 1.8390 (0.569 sec/step)\n",
            "I0517 09:47:24.501121 139851376510848 learning.py:507] global step 6652: loss = 1.8390 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6653: loss = 2.3527 (0.630 sec/step)\n",
            "I0517 09:47:25.133153 139851376510848 learning.py:507] global step 6653: loss = 2.3527 (0.630 sec/step)\n",
            "INFO:tensorflow:global step 6654: loss = 2.1606 (0.547 sec/step)\n",
            "I0517 09:47:25.681781 139851376510848 learning.py:507] global step 6654: loss = 2.1606 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6655: loss = 1.4553 (0.590 sec/step)\n",
            "I0517 09:47:26.273996 139851376510848 learning.py:507] global step 6655: loss = 1.4553 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6656: loss = 2.9332 (0.561 sec/step)\n",
            "I0517 09:47:26.837347 139851376510848 learning.py:507] global step 6656: loss = 2.9332 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6657: loss = 1.8074 (0.545 sec/step)\n",
            "I0517 09:47:27.384101 139851376510848 learning.py:507] global step 6657: loss = 1.8074 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6658: loss = 2.0752 (0.547 sec/step)\n",
            "I0517 09:47:27.933181 139851376510848 learning.py:507] global step 6658: loss = 2.0752 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6659: loss = 2.0784 (0.542 sec/step)\n",
            "I0517 09:47:28.478234 139851376510848 learning.py:507] global step 6659: loss = 2.0784 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6660: loss = 2.3075 (0.551 sec/step)\n",
            "I0517 09:47:29.031288 139851376510848 learning.py:507] global step 6660: loss = 2.3075 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6661: loss = 1.3050 (0.571 sec/step)\n",
            "I0517 09:47:29.603839 139851376510848 learning.py:507] global step 6661: loss = 1.3050 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6662: loss = 1.8435 (0.561 sec/step)\n",
            "I0517 09:47:30.166434 139851376510848 learning.py:507] global step 6662: loss = 1.8435 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6663: loss = 1.9907 (0.558 sec/step)\n",
            "I0517 09:47:30.726355 139851376510848 learning.py:507] global step 6663: loss = 1.9907 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6664: loss = 1.4145 (0.554 sec/step)\n",
            "I0517 09:47:31.283176 139851376510848 learning.py:507] global step 6664: loss = 1.4145 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6665: loss = 2.6361 (0.555 sec/step)\n",
            "I0517 09:47:31.840073 139851376510848 learning.py:507] global step 6665: loss = 2.6361 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6666: loss = 1.9291 (0.556 sec/step)\n",
            "I0517 09:47:32.398523 139851376510848 learning.py:507] global step 6666: loss = 1.9291 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6667: loss = 3.3728 (0.555 sec/step)\n",
            "I0517 09:47:32.955470 139851376510848 learning.py:507] global step 6667: loss = 3.3728 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6668: loss = 2.0114 (0.557 sec/step)\n",
            "I0517 09:47:33.514501 139851376510848 learning.py:507] global step 6668: loss = 2.0114 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6669: loss = 2.0567 (0.549 sec/step)\n",
            "I0517 09:47:34.065305 139851376510848 learning.py:507] global step 6669: loss = 2.0567 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6670: loss = 2.8012 (0.569 sec/step)\n",
            "I0517 09:47:34.637464 139851376510848 learning.py:507] global step 6670: loss = 2.8012 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6671: loss = 2.7498 (0.583 sec/step)\n",
            "I0517 09:47:35.224623 139851376510848 learning.py:507] global step 6671: loss = 2.7498 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6672: loss = 2.2719 (0.588 sec/step)\n",
            "I0517 09:47:35.815600 139851376510848 learning.py:507] global step 6672: loss = 2.2719 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6673: loss = 1.7738 (0.549 sec/step)\n",
            "I0517 09:47:36.366226 139851376510848 learning.py:507] global step 6673: loss = 1.7738 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6674: loss = 2.0465 (0.566 sec/step)\n",
            "I0517 09:47:36.933928 139851376510848 learning.py:507] global step 6674: loss = 2.0465 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6675: loss = 1.6293 (0.562 sec/step)\n",
            "I0517 09:47:37.497672 139851376510848 learning.py:507] global step 6675: loss = 1.6293 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6676: loss = 1.5625 (0.555 sec/step)\n",
            "I0517 09:47:38.054003 139851376510848 learning.py:507] global step 6676: loss = 1.5625 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6677: loss = 1.8725 (0.543 sec/step)\n",
            "I0517 09:47:38.598359 139851376510848 learning.py:507] global step 6677: loss = 1.8725 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6678: loss = 2.3218 (0.564 sec/step)\n",
            "I0517 09:47:39.164501 139851376510848 learning.py:507] global step 6678: loss = 2.3218 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6679: loss = 1.8668 (0.564 sec/step)\n",
            "I0517 09:47:39.730688 139851376510848 learning.py:507] global step 6679: loss = 1.8668 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6680: loss = 2.4101 (0.543 sec/step)\n",
            "I0517 09:47:40.276337 139851376510848 learning.py:507] global step 6680: loss = 2.4101 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6681: loss = 1.8667 (0.552 sec/step)\n",
            "I0517 09:47:40.830412 139851376510848 learning.py:507] global step 6681: loss = 1.8667 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6682: loss = 1.6815 (0.553 sec/step)\n",
            "I0517 09:47:41.384856 139851376510848 learning.py:507] global step 6682: loss = 1.6815 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6683: loss = 2.9179 (0.558 sec/step)\n",
            "I0517 09:47:41.946013 139851376510848 learning.py:507] global step 6683: loss = 2.9179 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6684: loss = 1.6854 (0.537 sec/step)\n",
            "I0517 09:47:42.484862 139851376510848 learning.py:507] global step 6684: loss = 1.6854 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6685: loss = 1.4419 (0.536 sec/step)\n",
            "I0517 09:47:43.022721 139851376510848 learning.py:507] global step 6685: loss = 1.4419 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6686: loss = 4.5669 (0.543 sec/step)\n",
            "I0517 09:47:43.567995 139851376510848 learning.py:507] global step 6686: loss = 4.5669 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6687: loss = 2.0216 (0.590 sec/step)\n",
            "I0517 09:47:44.159538 139851376510848 learning.py:507] global step 6687: loss = 2.0216 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6688: loss = 1.9081 (0.568 sec/step)\n",
            "I0517 09:47:44.729806 139851376510848 learning.py:507] global step 6688: loss = 1.9081 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6689: loss = 1.9862 (0.586 sec/step)\n",
            "I0517 09:47:45.317672 139851376510848 learning.py:507] global step 6689: loss = 1.9862 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 6690: loss = 2.5460 (0.562 sec/step)\n",
            "I0517 09:47:45.881821 139851376510848 learning.py:507] global step 6690: loss = 2.5460 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6691: loss = 3.0134 (0.571 sec/step)\n",
            "I0517 09:47:46.454151 139851376510848 learning.py:507] global step 6691: loss = 3.0134 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6692: loss = 1.9486 (0.537 sec/step)\n",
            "I0517 09:47:46.992762 139851376510848 learning.py:507] global step 6692: loss = 1.9486 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6693: loss = 1.7925 (0.559 sec/step)\n",
            "I0517 09:47:47.553453 139851376510848 learning.py:507] global step 6693: loss = 1.7925 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6694: loss = 2.4698 (0.594 sec/step)\n",
            "I0517 09:47:48.149101 139851376510848 learning.py:507] global step 6694: loss = 2.4698 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 6695: loss = 1.9919 (0.537 sec/step)\n",
            "I0517 09:47:48.688625 139851376510848 learning.py:507] global step 6695: loss = 1.9919 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6696: loss = 2.0440 (0.567 sec/step)\n",
            "I0517 09:47:49.257401 139851376510848 learning.py:507] global step 6696: loss = 2.0440 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6697: loss = 2.8504 (0.563 sec/step)\n",
            "I0517 09:47:49.822394 139851376510848 learning.py:507] global step 6697: loss = 2.8504 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6698: loss = 3.3523 (0.573 sec/step)\n",
            "I0517 09:47:50.397426 139851376510848 learning.py:507] global step 6698: loss = 3.3523 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6699: loss = 1.6427 (0.575 sec/step)\n",
            "I0517 09:47:50.982779 139851376510848 learning.py:507] global step 6699: loss = 1.6427 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 6700: loss = 2.4271 (0.562 sec/step)\n",
            "I0517 09:47:51.546093 139851376510848 learning.py:507] global step 6700: loss = 2.4271 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6701: loss = 2.6506 (0.550 sec/step)\n",
            "I0517 09:47:52.097836 139851376510848 learning.py:507] global step 6701: loss = 2.6506 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6702: loss = 2.1901 (0.557 sec/step)\n",
            "I0517 09:47:52.656326 139851376510848 learning.py:507] global step 6702: loss = 2.1901 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 6703: loss = 2.7143 (0.579 sec/step)\n",
            "I0517 09:47:53.236890 139851376510848 learning.py:507] global step 6703: loss = 2.7143 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6704: loss = 2.2572 (0.534 sec/step)\n",
            "I0517 09:47:53.773120 139851376510848 learning.py:507] global step 6704: loss = 2.2572 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 6705: loss = 2.6076 (0.547 sec/step)\n",
            "I0517 09:47:54.322175 139851376510848 learning.py:507] global step 6705: loss = 2.6076 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6706: loss = 3.4751 (0.544 sec/step)\n",
            "I0517 09:47:54.868074 139851376510848 learning.py:507] global step 6706: loss = 3.4751 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6707: loss = 1.5970 (0.593 sec/step)\n",
            "I0517 09:47:55.462699 139851376510848 learning.py:507] global step 6707: loss = 1.5970 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6708: loss = 1.8188 (0.589 sec/step)\n",
            "I0517 09:47:56.053389 139851376510848 learning.py:507] global step 6708: loss = 1.8188 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6709: loss = 1.7465 (0.598 sec/step)\n",
            "I0517 09:47:56.653311 139851376510848 learning.py:507] global step 6709: loss = 1.7465 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6710: loss = 1.7509 (0.589 sec/step)\n",
            "I0517 09:47:57.243958 139851376510848 learning.py:507] global step 6710: loss = 1.7509 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 6711: loss = 2.9882 (0.548 sec/step)\n",
            "I0517 09:47:57.793993 139851376510848 learning.py:507] global step 6711: loss = 2.9882 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6712: loss = 2.6310 (0.533 sec/step)\n",
            "I0517 09:47:58.328348 139851376510848 learning.py:507] global step 6712: loss = 2.6310 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6713: loss = 2.2221 (0.537 sec/step)\n",
            "I0517 09:47:58.866746 139851376510848 learning.py:507] global step 6713: loss = 2.2221 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6714: loss = 1.8913 (0.549 sec/step)\n",
            "I0517 09:47:59.417176 139851376510848 learning.py:507] global step 6714: loss = 1.8913 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6715: loss = 2.3314 (0.569 sec/step)\n",
            "I0517 09:47:59.988132 139851376510848 learning.py:507] global step 6715: loss = 2.3314 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6716: loss = 2.0312 (0.562 sec/step)\n",
            "I0517 09:48:00.551852 139851376510848 learning.py:507] global step 6716: loss = 2.0312 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6717: loss = 2.1112 (0.566 sec/step)\n",
            "I0517 09:48:01.120081 139851376510848 learning.py:507] global step 6717: loss = 2.1112 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6718: loss = 2.0014 (0.551 sec/step)\n",
            "I0517 09:48:01.673157 139851376510848 learning.py:507] global step 6718: loss = 2.0014 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6719: loss = 1.5892 (0.543 sec/step)\n",
            "I0517 09:48:02.218146 139851376510848 learning.py:507] global step 6719: loss = 1.5892 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6720: loss = 1.8982 (0.558 sec/step)\n",
            "I0517 09:48:02.777943 139851376510848 learning.py:507] global step 6720: loss = 1.8982 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6721: loss = 1.4397 (0.553 sec/step)\n",
            "I0517 09:48:03.333013 139851376510848 learning.py:507] global step 6721: loss = 1.4397 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6722: loss = 2.2511 (0.549 sec/step)\n",
            "I0517 09:48:03.883680 139851376510848 learning.py:507] global step 6722: loss = 2.2511 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6723: loss = 1.6774 (0.576 sec/step)\n",
            "I0517 09:48:04.461268 139851376510848 learning.py:507] global step 6723: loss = 1.6774 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6724: loss = 1.9349 (0.570 sec/step)\n",
            "I0517 09:48:05.033007 139851376510848 learning.py:507] global step 6724: loss = 1.9349 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 6725: loss = 2.0823 (0.555 sec/step)\n",
            "I0517 09:48:05.590508 139851376510848 learning.py:507] global step 6725: loss = 2.0823 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6726: loss = 1.7121 (0.548 sec/step)\n",
            "I0517 09:48:06.140799 139851376510848 learning.py:507] global step 6726: loss = 1.7121 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6727: loss = 1.8508 (0.556 sec/step)\n",
            "I0517 09:48:06.699151 139851376510848 learning.py:507] global step 6727: loss = 1.8508 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6728: loss = 1.3492 (0.597 sec/step)\n",
            "I0517 09:48:07.298421 139851376510848 learning.py:507] global step 6728: loss = 1.3492 (0.597 sec/step)\n",
            "INFO:tensorflow:global step 6729: loss = 1.8902 (0.555 sec/step)\n",
            "I0517 09:48:07.855328 139851376510848 learning.py:507] global step 6729: loss = 1.8902 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6730: loss = 3.3108 (0.551 sec/step)\n",
            "I0517 09:48:08.408895 139851376510848 learning.py:507] global step 6730: loss = 3.3108 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6731: loss = 3.1899 (0.552 sec/step)\n",
            "I0517 09:48:08.963063 139851376510848 learning.py:507] global step 6731: loss = 3.1899 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6732: loss = 1.9204 (0.582 sec/step)\n",
            "I0517 09:48:09.547409 139851376510848 learning.py:507] global step 6732: loss = 1.9204 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6733: loss = 1.9671 (0.583 sec/step)\n",
            "I0517 09:48:10.132493 139851376510848 learning.py:507] global step 6733: loss = 1.9671 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 6734: loss = 1.3960 (0.597 sec/step)\n",
            "I0517 09:48:10.731260 139851376510848 learning.py:507] global step 6734: loss = 1.3960 (0.597 sec/step)\n",
            "INFO:tensorflow:global step 6735: loss = 2.1096 (0.560 sec/step)\n",
            "I0517 09:48:11.293261 139851376510848 learning.py:507] global step 6735: loss = 2.1096 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6736: loss = 2.4236 (0.558 sec/step)\n",
            "I0517 09:48:11.853588 139851376510848 learning.py:507] global step 6736: loss = 2.4236 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6737: loss = 1.4785 (0.593 sec/step)\n",
            "I0517 09:48:12.448344 139851376510848 learning.py:507] global step 6737: loss = 1.4785 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6738: loss = 2.1590 (0.544 sec/step)\n",
            "I0517 09:48:12.995577 139851376510848 learning.py:507] global step 6738: loss = 2.1590 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6739: loss = 2.3779 (0.573 sec/step)\n",
            "I0517 09:48:13.570008 139851376510848 learning.py:507] global step 6739: loss = 2.3779 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6740: loss = 1.9710 (0.533 sec/step)\n",
            "I0517 09:48:14.104424 139851376510848 learning.py:507] global step 6740: loss = 1.9710 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6741: loss = 1.5538 (0.545 sec/step)\n",
            "I0517 09:48:14.651277 139851376510848 learning.py:507] global step 6741: loss = 1.5538 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6742: loss = 1.7616 (0.539 sec/step)\n",
            "I0517 09:48:15.191838 139851376510848 learning.py:507] global step 6742: loss = 1.7616 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 6743: loss = 1.9328 (0.554 sec/step)\n",
            "I0517 09:48:15.747344 139851376510848 learning.py:507] global step 6743: loss = 1.9328 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6744: loss = 4.5645 (0.537 sec/step)\n",
            "I0517 09:48:16.286400 139851376510848 learning.py:507] global step 6744: loss = 4.5645 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6745: loss = 1.3404 (0.563 sec/step)\n",
            "I0517 09:48:16.851148 139851376510848 learning.py:507] global step 6745: loss = 1.3404 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6746: loss = 2.7541 (0.554 sec/step)\n",
            "I0517 09:48:17.407711 139851376510848 learning.py:507] global step 6746: loss = 2.7541 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6747: loss = 3.0966 (0.554 sec/step)\n",
            "I0517 09:48:17.963506 139851376510848 learning.py:507] global step 6747: loss = 3.0966 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6748: loss = 2.9598 (0.537 sec/step)\n",
            "I0517 09:48:18.502080 139851376510848 learning.py:507] global step 6748: loss = 2.9598 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6749: loss = 1.8226 (0.563 sec/step)\n",
            "I0517 09:48:19.067345 139851376510848 learning.py:507] global step 6749: loss = 1.8226 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6750: loss = 2.0940 (0.561 sec/step)\n",
            "I0517 09:48:19.630105 139851376510848 learning.py:507] global step 6750: loss = 2.0940 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6751: loss = 1.7288 (0.560 sec/step)\n",
            "I0517 09:48:20.192192 139851376510848 learning.py:507] global step 6751: loss = 1.7288 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6752: loss = 1.7759 (0.579 sec/step)\n",
            "I0517 09:48:20.772796 139851376510848 learning.py:507] global step 6752: loss = 1.7759 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6753: loss = 2.0168 (0.580 sec/step)\n",
            "I0517 09:48:21.354838 139851376510848 learning.py:507] global step 6753: loss = 2.0168 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6754: loss = 2.3708 (0.550 sec/step)\n",
            "I0517 09:48:21.906332 139851376510848 learning.py:507] global step 6754: loss = 2.3708 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6755: loss = 2.7953 (0.554 sec/step)\n",
            "I0517 09:48:22.462400 139851376510848 learning.py:507] global step 6755: loss = 2.7953 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6756: loss = 1.5539 (0.554 sec/step)\n",
            "I0517 09:48:23.018685 139851376510848 learning.py:507] global step 6756: loss = 1.5539 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6757: loss = 2.4896 (0.579 sec/step)\n",
            "I0517 09:48:23.599862 139851376510848 learning.py:507] global step 6757: loss = 2.4896 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6758: loss = 2.0180 (0.559 sec/step)\n",
            "I0517 09:48:24.163177 139851376510848 learning.py:507] global step 6758: loss = 2.0180 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6759: loss = 1.4750 (0.571 sec/step)\n",
            "I0517 09:48:24.735488 139851376510848 learning.py:507] global step 6759: loss = 1.4750 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6760: loss = 2.1109 (0.582 sec/step)\n",
            "I0517 09:48:25.319509 139851376510848 learning.py:507] global step 6760: loss = 2.1109 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 6761: loss = 3.4381 (0.587 sec/step)\n",
            "I0517 09:48:25.907855 139851376510848 learning.py:507] global step 6761: loss = 3.4381 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6762: loss = 1.7521 (0.548 sec/step)\n",
            "I0517 09:48:26.459000 139851376510848 learning.py:507] global step 6762: loss = 1.7521 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6763: loss = 1.9984 (0.555 sec/step)\n",
            "I0517 09:48:27.016208 139851376510848 learning.py:507] global step 6763: loss = 1.9984 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6764: loss = 1.7257 (0.545 sec/step)\n",
            "I0517 09:48:27.562725 139851376510848 learning.py:507] global step 6764: loss = 1.7257 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6765: loss = 1.5693 (0.592 sec/step)\n",
            "I0517 09:48:28.155987 139851376510848 learning.py:507] global step 6765: loss = 1.5693 (0.592 sec/step)\n",
            "INFO:tensorflow:global step 6766: loss = 1.9587 (0.526 sec/step)\n",
            "I0517 09:48:28.683949 139851376510848 learning.py:507] global step 6766: loss = 1.9587 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 6767: loss = 1.5964 (0.544 sec/step)\n",
            "I0517 09:48:29.230118 139851376510848 learning.py:507] global step 6767: loss = 1.5964 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6768: loss = 1.4952 (0.564 sec/step)\n",
            "I0517 09:48:29.796358 139851376510848 learning.py:507] global step 6768: loss = 1.4952 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6769: loss = 1.8420 (0.547 sec/step)\n",
            "I0517 09:48:30.344883 139851376510848 learning.py:507] global step 6769: loss = 1.8420 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6770: loss = 2.3615 (0.532 sec/step)\n",
            "I0517 09:48:30.878946 139851376510848 learning.py:507] global step 6770: loss = 2.3615 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 6771: loss = 2.1951 (0.527 sec/step)\n",
            "I0517 09:48:31.407981 139851376510848 learning.py:507] global step 6771: loss = 2.1951 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 6772: loss = 1.4911 (0.527 sec/step)\n",
            "I0517 09:48:31.937211 139851376510848 learning.py:507] global step 6772: loss = 1.4911 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 6773: loss = 2.8924 (0.535 sec/step)\n",
            "I0517 09:48:32.474441 139851376510848 learning.py:507] global step 6773: loss = 2.8924 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6774: loss = 2.8721 (0.541 sec/step)\n",
            "I0517 09:48:33.018059 139851376510848 learning.py:507] global step 6774: loss = 2.8721 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6775: loss = 2.2268 (0.560 sec/step)\n",
            "I0517 09:48:33.579849 139851376510848 learning.py:507] global step 6775: loss = 2.2268 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6776: loss = 1.9187 (0.551 sec/step)\n",
            "I0517 09:48:34.132286 139851376510848 learning.py:507] global step 6776: loss = 1.9187 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6777: loss = 2.2622 (0.563 sec/step)\n",
            "I0517 09:48:34.697400 139851376510848 learning.py:507] global step 6777: loss = 2.2622 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6778: loss = 1.6299 (0.571 sec/step)\n",
            "I0517 09:48:35.270113 139851376510848 learning.py:507] global step 6778: loss = 1.6299 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6779: loss = 1.8193 (0.556 sec/step)\n",
            "I0517 09:48:35.827926 139851376510848 learning.py:507] global step 6779: loss = 1.8193 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6780: loss = 1.6886 (0.544 sec/step)\n",
            "I0517 09:48:36.374732 139851376510848 learning.py:507] global step 6780: loss = 1.6886 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6781: loss = 1.8256 (0.538 sec/step)\n",
            "I0517 09:48:36.915578 139851376510848 learning.py:507] global step 6781: loss = 1.8256 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6782: loss = 3.0955 (0.584 sec/step)\n",
            "I0517 09:48:37.501654 139851376510848 learning.py:507] global step 6782: loss = 3.0955 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6783: loss = 1.8409 (0.606 sec/step)\n",
            "I0517 09:48:38.108977 139851376510848 learning.py:507] global step 6783: loss = 1.8409 (0.606 sec/step)\n",
            "INFO:tensorflow:global step 6784: loss = 2.6283 (0.549 sec/step)\n",
            "I0517 09:48:38.659775 139851376510848 learning.py:507] global step 6784: loss = 2.6283 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6785: loss = 2.0021 (0.569 sec/step)\n",
            "I0517 09:48:39.230300 139851376510848 learning.py:507] global step 6785: loss = 2.0021 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6786: loss = 2.4283 (0.564 sec/step)\n",
            "I0517 09:48:39.795868 139851376510848 learning.py:507] global step 6786: loss = 2.4283 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6787: loss = 2.1592 (0.538 sec/step)\n",
            "I0517 09:48:40.335589 139851376510848 learning.py:507] global step 6787: loss = 2.1592 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6788: loss = 1.5143 (0.533 sec/step)\n",
            "I0517 09:48:40.870881 139851376510848 learning.py:507] global step 6788: loss = 1.5143 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6789: loss = 2.2019 (0.577 sec/step)\n",
            "I0517 09:48:41.450162 139851376510848 learning.py:507] global step 6789: loss = 2.2019 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 6790: loss = 1.6633 (0.559 sec/step)\n",
            "I0517 09:48:42.011461 139851376510848 learning.py:507] global step 6790: loss = 1.6633 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6791: loss = 1.9566 (0.560 sec/step)\n",
            "I0517 09:48:42.573663 139851376510848 learning.py:507] global step 6791: loss = 1.9566 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6792: loss = 2.1872 (0.580 sec/step)\n",
            "I0517 09:48:43.155851 139851376510848 learning.py:507] global step 6792: loss = 2.1872 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6793: loss = 2.5487 (0.552 sec/step)\n",
            "I0517 09:48:43.711317 139851376510848 learning.py:507] global step 6793: loss = 2.5487 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6794: loss = 2.3077 (0.538 sec/step)\n",
            "I0517 09:48:44.250916 139851376510848 learning.py:507] global step 6794: loss = 2.3077 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6795: loss = 2.0902 (0.545 sec/step)\n",
            "I0517 09:48:44.797574 139851376510848 learning.py:507] global step 6795: loss = 2.0902 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6796: loss = 2.1269 (0.545 sec/step)\n",
            "I0517 09:48:45.344423 139851376510848 learning.py:507] global step 6796: loss = 2.1269 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6797: loss = 2.5871 (0.876 sec/step)\n",
            "I0517 09:48:46.223313 139851376510848 learning.py:507] global step 6797: loss = 2.5871 (0.876 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6798.\n",
            "I0517 09:48:47.157231 139847641536256 supervisor.py:1050] Recording summary at step 6798.\n",
            "INFO:tensorflow:global step 6798: loss = 2.0035 (0.963 sec/step)\n",
            "I0517 09:48:47.191176 139851376510848 learning.py:507] global step 6798: loss = 2.0035 (0.963 sec/step)\n",
            "INFO:tensorflow:global step 6799: loss = 3.0418 (0.554 sec/step)\n",
            "I0517 09:48:47.748095 139851376510848 learning.py:507] global step 6799: loss = 3.0418 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6800: loss = 2.1931 (0.548 sec/step)\n",
            "I0517 09:48:48.298271 139851376510848 learning.py:507] global step 6800: loss = 2.1931 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6801: loss = 1.9525 (0.565 sec/step)\n",
            "I0517 09:48:48.864942 139851376510848 learning.py:507] global step 6801: loss = 1.9525 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6802: loss = 1.5194 (0.580 sec/step)\n",
            "I0517 09:48:49.446467 139851376510848 learning.py:507] global step 6802: loss = 1.5194 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6803: loss = 1.8025 (0.530 sec/step)\n",
            "I0517 09:48:49.978013 139851376510848 learning.py:507] global step 6803: loss = 1.8025 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 6804: loss = 1.7420 (0.587 sec/step)\n",
            "I0517 09:48:50.566668 139851376510848 learning.py:507] global step 6804: loss = 1.7420 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6805: loss = 1.7733 (0.578 sec/step)\n",
            "I0517 09:48:51.146413 139851376510848 learning.py:507] global step 6805: loss = 1.7733 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6806: loss = 2.8404 (0.552 sec/step)\n",
            "I0517 09:48:51.699902 139851376510848 learning.py:507] global step 6806: loss = 2.8404 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6807: loss = 2.4440 (0.550 sec/step)\n",
            "I0517 09:48:52.251926 139851376510848 learning.py:507] global step 6807: loss = 2.4440 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6808: loss = 1.8540 (0.548 sec/step)\n",
            "I0517 09:48:52.801418 139851376510848 learning.py:507] global step 6808: loss = 1.8540 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6809: loss = 1.7233 (0.542 sec/step)\n",
            "I0517 09:48:53.345520 139851376510848 learning.py:507] global step 6809: loss = 1.7233 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6810: loss = 1.6524 (0.546 sec/step)\n",
            "I0517 09:48:53.893600 139851376510848 learning.py:507] global step 6810: loss = 1.6524 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6811: loss = 1.9220 (0.562 sec/step)\n",
            "I0517 09:48:54.457282 139851376510848 learning.py:507] global step 6811: loss = 1.9220 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 6812: loss = 2.0333 (0.534 sec/step)\n",
            "I0517 09:48:54.992948 139851376510848 learning.py:507] global step 6812: loss = 2.0333 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 6813: loss = 2.0023 (0.568 sec/step)\n",
            "I0517 09:48:55.563613 139851376510848 learning.py:507] global step 6813: loss = 2.0023 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6814: loss = 2.3954 (0.531 sec/step)\n",
            "I0517 09:48:56.095972 139851376510848 learning.py:507] global step 6814: loss = 2.3954 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 6815: loss = 2.1864 (0.598 sec/step)\n",
            "I0517 09:48:56.696190 139851376510848 learning.py:507] global step 6815: loss = 2.1864 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 6816: loss = 1.5461 (0.572 sec/step)\n",
            "I0517 09:48:57.269783 139851376510848 learning.py:507] global step 6816: loss = 1.5461 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6817: loss = 2.2452 (0.538 sec/step)\n",
            "I0517 09:48:57.809237 139851376510848 learning.py:507] global step 6817: loss = 2.2452 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6818: loss = 1.9561 (0.541 sec/step)\n",
            "I0517 09:48:58.351879 139851376510848 learning.py:507] global step 6818: loss = 1.9561 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6819: loss = 1.9074 (0.543 sec/step)\n",
            "I0517 09:48:58.897189 139851376510848 learning.py:507] global step 6819: loss = 1.9074 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6820: loss = 2.4167 (0.543 sec/step)\n",
            "I0517 09:48:59.442439 139851376510848 learning.py:507] global step 6820: loss = 2.4167 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6821: loss = 2.3928 (0.569 sec/step)\n",
            "I0517 09:49:00.013373 139851376510848 learning.py:507] global step 6821: loss = 2.3928 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6822: loss = 1.6669 (0.544 sec/step)\n",
            "I0517 09:49:00.558904 139851376510848 learning.py:507] global step 6822: loss = 1.6669 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6823: loss = 2.0379 (0.552 sec/step)\n",
            "I0517 09:49:01.113760 139851376510848 learning.py:507] global step 6823: loss = 2.0379 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6824: loss = 1.6166 (0.535 sec/step)\n",
            "I0517 09:49:01.650626 139851376510848 learning.py:507] global step 6824: loss = 1.6166 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6825: loss = 2.0976 (0.535 sec/step)\n",
            "I0517 09:49:02.187866 139851376510848 learning.py:507] global step 6825: loss = 2.0976 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6826: loss = 1.7125 (0.541 sec/step)\n",
            "I0517 09:49:02.730937 139851376510848 learning.py:507] global step 6826: loss = 1.7125 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6827: loss = 1.8069 (0.561 sec/step)\n",
            "I0517 09:49:03.294852 139851376510848 learning.py:507] global step 6827: loss = 1.8069 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6828: loss = 1.6198 (0.547 sec/step)\n",
            "I0517 09:49:03.844126 139851376510848 learning.py:507] global step 6828: loss = 1.6198 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6829: loss = 2.0286 (0.540 sec/step)\n",
            "I0517 09:49:04.385546 139851376510848 learning.py:507] global step 6829: loss = 2.0286 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6830: loss = 1.3797 (0.542 sec/step)\n",
            "I0517 09:49:04.929622 139851376510848 learning.py:507] global step 6830: loss = 1.3797 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6831: loss = 2.2547 (0.554 sec/step)\n",
            "I0517 09:49:05.485354 139851376510848 learning.py:507] global step 6831: loss = 2.2547 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6832: loss = 4.0406 (0.541 sec/step)\n",
            "I0517 09:49:06.028455 139851376510848 learning.py:507] global step 6832: loss = 4.0406 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6833: loss = 2.2184 (0.539 sec/step)\n",
            "I0517 09:49:06.569241 139851376510848 learning.py:507] global step 6833: loss = 2.2184 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 6834: loss = 2.7789 (0.536 sec/step)\n",
            "I0517 09:49:07.106569 139851376510848 learning.py:507] global step 6834: loss = 2.7789 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6835: loss = 2.0734 (0.547 sec/step)\n",
            "I0517 09:49:07.655272 139851376510848 learning.py:507] global step 6835: loss = 2.0734 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6836: loss = 2.4808 (0.580 sec/step)\n",
            "I0517 09:49:08.236715 139851376510848 learning.py:507] global step 6836: loss = 2.4808 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 6837: loss = 1.9460 (0.573 sec/step)\n",
            "I0517 09:49:08.810992 139851376510848 learning.py:507] global step 6837: loss = 1.9460 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6838: loss = 2.1493 (0.559 sec/step)\n",
            "I0517 09:49:09.372077 139851376510848 learning.py:507] global step 6838: loss = 2.1493 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6839: loss = 1.7665 (0.587 sec/step)\n",
            "I0517 09:49:09.960654 139851376510848 learning.py:507] global step 6839: loss = 1.7665 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 6840: loss = 2.5006 (0.571 sec/step)\n",
            "I0517 09:49:10.533518 139851376510848 learning.py:507] global step 6840: loss = 2.5006 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6841: loss = 2.1040 (0.532 sec/step)\n",
            "I0517 09:49:11.066861 139851376510848 learning.py:507] global step 6841: loss = 2.1040 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 6842: loss = 1.8581 (0.549 sec/step)\n",
            "I0517 09:49:11.617964 139851376510848 learning.py:507] global step 6842: loss = 1.8581 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6843: loss = 2.5945 (0.549 sec/step)\n",
            "I0517 09:49:12.169125 139851376510848 learning.py:507] global step 6843: loss = 2.5945 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6844: loss = 1.6124 (0.558 sec/step)\n",
            "I0517 09:49:12.729408 139851376510848 learning.py:507] global step 6844: loss = 1.6124 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 6845: loss = 1.9660 (0.576 sec/step)\n",
            "I0517 09:49:13.308424 139851376510848 learning.py:507] global step 6845: loss = 1.9660 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 6846: loss = 2.1119 (0.559 sec/step)\n",
            "I0517 09:49:13.869717 139851376510848 learning.py:507] global step 6846: loss = 2.1119 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6847: loss = 2.7430 (0.547 sec/step)\n",
            "I0517 09:49:14.418868 139851376510848 learning.py:507] global step 6847: loss = 2.7430 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6848: loss = 1.7324 (0.546 sec/step)\n",
            "I0517 09:49:14.966518 139851376510848 learning.py:507] global step 6848: loss = 1.7324 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6849: loss = 2.3721 (0.549 sec/step)\n",
            "I0517 09:49:15.517763 139851376510848 learning.py:507] global step 6849: loss = 2.3721 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6850: loss = 2.5338 (0.550 sec/step)\n",
            "I0517 09:49:16.070048 139851376510848 learning.py:507] global step 6850: loss = 2.5338 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6851: loss = 1.9180 (0.538 sec/step)\n",
            "I0517 09:49:16.609781 139851376510848 learning.py:507] global step 6851: loss = 1.9180 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6852: loss = 2.1894 (0.538 sec/step)\n",
            "I0517 09:49:17.150104 139851376510848 learning.py:507] global step 6852: loss = 2.1894 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6853: loss = 2.1894 (0.553 sec/step)\n",
            "I0517 09:49:17.704807 139851376510848 learning.py:507] global step 6853: loss = 2.1894 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6854: loss = 1.6822 (0.548 sec/step)\n",
            "I0517 09:49:18.254912 139851376510848 learning.py:507] global step 6854: loss = 1.6822 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6855: loss = 2.6858 (0.559 sec/step)\n",
            "I0517 09:49:18.816270 139851376510848 learning.py:507] global step 6855: loss = 2.6858 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6856: loss = 1.6475 (0.542 sec/step)\n",
            "I0517 09:49:19.361018 139851376510848 learning.py:507] global step 6856: loss = 1.6475 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6857: loss = 1.7090 (0.564 sec/step)\n",
            "I0517 09:49:19.926374 139851376510848 learning.py:507] global step 6857: loss = 1.7090 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6858: loss = 1.5965 (0.556 sec/step)\n",
            "I0517 09:49:20.483661 139851376510848 learning.py:507] global step 6858: loss = 1.5965 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6859: loss = 1.4778 (0.550 sec/step)\n",
            "I0517 09:49:21.035988 139851376510848 learning.py:507] global step 6859: loss = 1.4778 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6860: loss = 2.2125 (0.573 sec/step)\n",
            "I0517 09:49:21.610768 139851376510848 learning.py:507] global step 6860: loss = 2.2125 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6861: loss = 1.4065 (0.523 sec/step)\n",
            "I0517 09:49:22.135999 139851376510848 learning.py:507] global step 6861: loss = 1.4065 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 6862: loss = 4.5179 (0.588 sec/step)\n",
            "I0517 09:49:22.726449 139851376510848 learning.py:507] global step 6862: loss = 4.5179 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 6863: loss = 1.2085 (0.596 sec/step)\n",
            "I0517 09:49:23.324523 139851376510848 learning.py:507] global step 6863: loss = 1.2085 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 6864: loss = 1.7988 (0.563 sec/step)\n",
            "I0517 09:49:23.888914 139851376510848 learning.py:507] global step 6864: loss = 1.7988 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6865: loss = 1.4268 (0.564 sec/step)\n",
            "I0517 09:49:24.454967 139851376510848 learning.py:507] global step 6865: loss = 1.4268 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6866: loss = 2.2999 (0.546 sec/step)\n",
            "I0517 09:49:25.003090 139851376510848 learning.py:507] global step 6866: loss = 2.2999 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6867: loss = 2.9234 (0.567 sec/step)\n",
            "I0517 09:49:25.572091 139851376510848 learning.py:507] global step 6867: loss = 2.9234 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 6868: loss = 1.7667 (0.544 sec/step)\n",
            "I0517 09:49:26.118089 139851376510848 learning.py:507] global step 6868: loss = 1.7667 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6869: loss = 3.3403 (0.548 sec/step)\n",
            "I0517 09:49:26.667765 139851376510848 learning.py:507] global step 6869: loss = 3.3403 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 6870: loss = 1.6721 (0.536 sec/step)\n",
            "I0517 09:49:27.205790 139851376510848 learning.py:507] global step 6870: loss = 1.6721 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6871: loss = 1.7403 (0.593 sec/step)\n",
            "I0517 09:49:27.800381 139851376510848 learning.py:507] global step 6871: loss = 1.7403 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 6872: loss = 1.6935 (0.547 sec/step)\n",
            "I0517 09:49:28.349423 139851376510848 learning.py:507] global step 6872: loss = 1.6935 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6873: loss = 2.2809 (0.561 sec/step)\n",
            "I0517 09:49:28.912020 139851376510848 learning.py:507] global step 6873: loss = 2.2809 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6874: loss = 1.7072 (0.546 sec/step)\n",
            "I0517 09:49:29.459596 139851376510848 learning.py:507] global step 6874: loss = 1.7072 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6875: loss = 2.4106 (0.564 sec/step)\n",
            "I0517 09:49:30.025046 139851376510848 learning.py:507] global step 6875: loss = 2.4106 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 6876: loss = 3.4387 (0.561 sec/step)\n",
            "I0517 09:49:30.587627 139851376510848 learning.py:507] global step 6876: loss = 3.4387 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6877: loss = 2.4267 (0.565 sec/step)\n",
            "I0517 09:49:31.154763 139851376510848 learning.py:507] global step 6877: loss = 2.4267 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6878: loss = 1.6761 (0.550 sec/step)\n",
            "I0517 09:49:31.706335 139851376510848 learning.py:507] global step 6878: loss = 1.6761 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6879: loss = 1.6931 (0.535 sec/step)\n",
            "I0517 09:49:32.242955 139851376510848 learning.py:507] global step 6879: loss = 1.6931 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6880: loss = 4.2701 (0.544 sec/step)\n",
            "I0517 09:49:32.789240 139851376510848 learning.py:507] global step 6880: loss = 4.2701 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6881: loss = 2.3917 (0.556 sec/step)\n",
            "I0517 09:49:33.346796 139851376510848 learning.py:507] global step 6881: loss = 2.3917 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6882: loss = 1.8997 (0.572 sec/step)\n",
            "I0517 09:49:33.920675 139851376510848 learning.py:507] global step 6882: loss = 1.8997 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6883: loss = 2.2034 (0.560 sec/step)\n",
            "I0517 09:49:34.482336 139851376510848 learning.py:507] global step 6883: loss = 2.2034 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6884: loss = 1.9942 (0.550 sec/step)\n",
            "I0517 09:49:35.034536 139851376510848 learning.py:507] global step 6884: loss = 1.9942 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6885: loss = 2.0063 (0.537 sec/step)\n",
            "I0517 09:49:35.573738 139851376510848 learning.py:507] global step 6885: loss = 2.0063 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6886: loss = 2.3658 (0.540 sec/step)\n",
            "I0517 09:49:36.115656 139851376510848 learning.py:507] global step 6886: loss = 2.3658 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6887: loss = 2.8413 (0.550 sec/step)\n",
            "I0517 09:49:36.667362 139851376510848 learning.py:507] global step 6887: loss = 2.8413 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6888: loss = 2.2150 (0.533 sec/step)\n",
            "I0517 09:49:37.202070 139851376510848 learning.py:507] global step 6888: loss = 2.2150 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6889: loss = 2.4964 (0.544 sec/step)\n",
            "I0517 09:49:37.747400 139851376510848 learning.py:507] global step 6889: loss = 2.4964 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6890: loss = 1.4780 (0.541 sec/step)\n",
            "I0517 09:49:38.289978 139851376510848 learning.py:507] global step 6890: loss = 1.4780 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6891: loss = 2.8042 (0.574 sec/step)\n",
            "I0517 09:49:38.865781 139851376510848 learning.py:507] global step 6891: loss = 2.8042 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 6892: loss = 2.1601 (0.569 sec/step)\n",
            "I0517 09:49:39.436904 139851376510848 learning.py:507] global step 6892: loss = 2.1601 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6893: loss = 2.4513 (0.568 sec/step)\n",
            "I0517 09:49:40.006845 139851376510848 learning.py:507] global step 6893: loss = 2.4513 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6894: loss = 2.0378 (0.554 sec/step)\n",
            "I0517 09:49:40.562396 139851376510848 learning.py:507] global step 6894: loss = 2.0378 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6895: loss = 2.5561 (0.591 sec/step)\n",
            "I0517 09:49:41.155511 139851376510848 learning.py:507] global step 6895: loss = 2.5561 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 6896: loss = 3.2903 (0.559 sec/step)\n",
            "I0517 09:49:41.716385 139851376510848 learning.py:507] global step 6896: loss = 3.2903 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6897: loss = 1.6610 (0.553 sec/step)\n",
            "I0517 09:49:42.271013 139851376510848 learning.py:507] global step 6897: loss = 1.6610 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6898: loss = 1.6260 (0.551 sec/step)\n",
            "I0517 09:49:42.824379 139851376510848 learning.py:507] global step 6898: loss = 1.6260 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6899: loss = 1.7146 (0.577 sec/step)\n",
            "I0517 09:49:43.402812 139851376510848 learning.py:507] global step 6899: loss = 1.7146 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 6900: loss = 2.2304 (0.555 sec/step)\n",
            "I0517 09:49:43.959700 139851376510848 learning.py:507] global step 6900: loss = 2.2304 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6901: loss = 2.6857 (0.563 sec/step)\n",
            "I0517 09:49:44.524335 139851376510848 learning.py:507] global step 6901: loss = 2.6857 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6902: loss = 2.7830 (0.553 sec/step)\n",
            "I0517 09:49:45.079004 139851376510848 learning.py:507] global step 6902: loss = 2.7830 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6903: loss = 3.2271 (0.537 sec/step)\n",
            "I0517 09:49:45.618218 139851376510848 learning.py:507] global step 6903: loss = 3.2271 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6904: loss = 2.2949 (0.565 sec/step)\n",
            "I0517 09:49:46.185072 139851376510848 learning.py:507] global step 6904: loss = 2.2949 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6905: loss = 1.6958 (0.535 sec/step)\n",
            "I0517 09:49:46.722008 139851376510848 learning.py:507] global step 6905: loss = 1.6958 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6906: loss = 2.1398 (0.571 sec/step)\n",
            "I0517 09:49:47.294895 139851376510848 learning.py:507] global step 6906: loss = 2.1398 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6907: loss = 3.3989 (0.524 sec/step)\n",
            "I0517 09:49:47.821106 139851376510848 learning.py:507] global step 6907: loss = 3.3989 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 6908: loss = 2.5583 (0.590 sec/step)\n",
            "I0517 09:49:48.412721 139851376510848 learning.py:507] global step 6908: loss = 2.5583 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 6909: loss = 1.8679 (0.553 sec/step)\n",
            "I0517 09:49:48.968267 139851376510848 learning.py:507] global step 6909: loss = 1.8679 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6910: loss = 2.6514 (0.554 sec/step)\n",
            "I0517 09:49:49.524470 139851376510848 learning.py:507] global step 6910: loss = 2.6514 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6911: loss = 1.5712 (0.573 sec/step)\n",
            "I0517 09:49:50.099594 139851376510848 learning.py:507] global step 6911: loss = 1.5712 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6912: loss = 3.0733 (0.554 sec/step)\n",
            "I0517 09:49:50.656148 139851376510848 learning.py:507] global step 6912: loss = 3.0733 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 6913: loss = 1.8062 (0.578 sec/step)\n",
            "I0517 09:49:51.236461 139851376510848 learning.py:507] global step 6913: loss = 1.8062 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6914: loss = 1.9926 (0.543 sec/step)\n",
            "I0517 09:49:51.781104 139851376510848 learning.py:507] global step 6914: loss = 1.9926 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6915: loss = 1.5894 (0.566 sec/step)\n",
            "I0517 09:49:52.348479 139851376510848 learning.py:507] global step 6915: loss = 1.5894 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6916: loss = 3.6707 (0.542 sec/step)\n",
            "I0517 09:49:52.892288 139851376510848 learning.py:507] global step 6916: loss = 3.6707 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6917: loss = 1.7355 (0.547 sec/step)\n",
            "I0517 09:49:53.440809 139851376510848 learning.py:507] global step 6917: loss = 1.7355 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6918: loss = 2.9946 (0.546 sec/step)\n",
            "I0517 09:49:53.988821 139851376510848 learning.py:507] global step 6918: loss = 2.9946 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6919: loss = 1.9734 (0.546 sec/step)\n",
            "I0517 09:49:54.536510 139851376510848 learning.py:507] global step 6919: loss = 1.9734 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6920: loss = 2.0071 (0.533 sec/step)\n",
            "I0517 09:49:55.071855 139851376510848 learning.py:507] global step 6920: loss = 2.0071 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6921: loss = 2.0510 (0.543 sec/step)\n",
            "I0517 09:49:55.617093 139851376510848 learning.py:507] global step 6921: loss = 2.0510 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6922: loss = 2.0198 (0.541 sec/step)\n",
            "I0517 09:49:56.159781 139851376510848 learning.py:507] global step 6922: loss = 2.0198 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6923: loss = 2.0366 (0.585 sec/step)\n",
            "I0517 09:49:56.746708 139851376510848 learning.py:507] global step 6923: loss = 2.0366 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 6924: loss = 1.7195 (0.537 sec/step)\n",
            "I0517 09:49:57.285614 139851376510848 learning.py:507] global step 6924: loss = 1.7195 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6925: loss = 1.7938 (0.535 sec/step)\n",
            "I0517 09:49:57.822646 139851376510848 learning.py:507] global step 6925: loss = 1.7938 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6926: loss = 1.5016 (0.566 sec/step)\n",
            "I0517 09:49:58.390378 139851376510848 learning.py:507] global step 6926: loss = 1.5016 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6927: loss = 4.0545 (0.515 sec/step)\n",
            "I0517 09:49:58.907342 139851376510848 learning.py:507] global step 6927: loss = 4.0545 (0.515 sec/step)\n",
            "INFO:tensorflow:global step 6928: loss = 1.7196 (0.560 sec/step)\n",
            "I0517 09:49:59.469457 139851376510848 learning.py:507] global step 6928: loss = 1.7196 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6929: loss = 2.2414 (0.556 sec/step)\n",
            "I0517 09:50:00.026586 139851376510848 learning.py:507] global step 6929: loss = 2.2414 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6930: loss = 2.3510 (0.545 sec/step)\n",
            "I0517 09:50:00.573536 139851376510848 learning.py:507] global step 6930: loss = 2.3510 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6931: loss = 2.1475 (0.528 sec/step)\n",
            "I0517 09:50:01.103120 139851376510848 learning.py:507] global step 6931: loss = 2.1475 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 6932: loss = 1.7411 (0.566 sec/step)\n",
            "I0517 09:50:01.670398 139851376510848 learning.py:507] global step 6932: loss = 1.7411 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6933: loss = 2.1379 (0.535 sec/step)\n",
            "I0517 09:50:02.206926 139851376510848 learning.py:507] global step 6933: loss = 2.1379 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6934: loss = 1.9132 (0.602 sec/step)\n",
            "I0517 09:50:02.810973 139851376510848 learning.py:507] global step 6934: loss = 1.9132 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 6935: loss = 2.2328 (0.536 sec/step)\n",
            "I0517 09:50:03.348403 139851376510848 learning.py:507] global step 6935: loss = 2.2328 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 6936: loss = 1.6852 (0.565 sec/step)\n",
            "I0517 09:50:03.915129 139851376510848 learning.py:507] global step 6936: loss = 1.6852 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6937: loss = 1.8266 (0.540 sec/step)\n",
            "I0517 09:50:04.456639 139851376510848 learning.py:507] global step 6937: loss = 1.8266 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6938: loss = 1.3032 (0.527 sec/step)\n",
            "I0517 09:50:04.985625 139851376510848 learning.py:507] global step 6938: loss = 1.3032 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 6939: loss = 2.2426 (0.559 sec/step)\n",
            "I0517 09:50:05.546185 139851376510848 learning.py:507] global step 6939: loss = 2.2426 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6940: loss = 2.2794 (0.545 sec/step)\n",
            "I0517 09:50:06.093364 139851376510848 learning.py:507] global step 6940: loss = 2.2794 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6941: loss = 2.2710 (0.556 sec/step)\n",
            "I0517 09:50:06.651359 139851376510848 learning.py:507] global step 6941: loss = 2.2710 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6942: loss = 1.9983 (0.535 sec/step)\n",
            "I0517 09:50:07.188466 139851376510848 learning.py:507] global step 6942: loss = 1.9983 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6943: loss = 1.6930 (0.568 sec/step)\n",
            "I0517 09:50:07.758490 139851376510848 learning.py:507] global step 6943: loss = 1.6930 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 6944: loss = 1.6357 (0.553 sec/step)\n",
            "I0517 09:50:08.313680 139851376510848 learning.py:507] global step 6944: loss = 1.6357 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6945: loss = 1.7772 (0.561 sec/step)\n",
            "I0517 09:50:08.876916 139851376510848 learning.py:507] global step 6945: loss = 1.7772 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 6946: loss = 2.2823 (0.544 sec/step)\n",
            "I0517 09:50:09.422451 139851376510848 learning.py:507] global step 6946: loss = 2.2823 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 6947: loss = 1.8045 (0.542 sec/step)\n",
            "I0517 09:50:09.966516 139851376510848 learning.py:507] global step 6947: loss = 1.8045 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6948: loss = 1.3324 (0.540 sec/step)\n",
            "I0517 09:50:10.508471 139851376510848 learning.py:507] global step 6948: loss = 1.3324 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6949: loss = 2.0204 (0.596 sec/step)\n",
            "I0517 09:50:11.106713 139851376510848 learning.py:507] global step 6949: loss = 2.0204 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 6950: loss = 1.4734 (0.551 sec/step)\n",
            "I0517 09:50:11.659369 139851376510848 learning.py:507] global step 6950: loss = 1.4734 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 6951: loss = 2.1918 (0.529 sec/step)\n",
            "I0517 09:50:12.189934 139851376510848 learning.py:507] global step 6951: loss = 2.1918 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 6952: loss = 1.7811 (0.547 sec/step)\n",
            "I0517 09:50:12.738278 139851376510848 learning.py:507] global step 6952: loss = 1.7811 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6953: loss = 1.7684 (0.552 sec/step)\n",
            "I0517 09:50:13.291659 139851376510848 learning.py:507] global step 6953: loss = 1.7684 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6954: loss = 1.8386 (0.545 sec/step)\n",
            "I0517 09:50:13.838391 139851376510848 learning.py:507] global step 6954: loss = 1.8386 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6955: loss = 1.6767 (0.571 sec/step)\n",
            "I0517 09:50:14.410903 139851376510848 learning.py:507] global step 6955: loss = 1.6767 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6956: loss = 1.9328 (0.532 sec/step)\n",
            "I0517 09:50:14.944391 139851376510848 learning.py:507] global step 6956: loss = 1.9328 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 6957: loss = 1.3871 (0.571 sec/step)\n",
            "I0517 09:50:15.518153 139851376510848 learning.py:507] global step 6957: loss = 1.3871 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 6958: loss = 1.5030 (0.569 sec/step)\n",
            "I0517 09:50:16.088400 139851376510848 learning.py:507] global step 6958: loss = 1.5030 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 6959: loss = 2.1127 (0.537 sec/step)\n",
            "I0517 09:50:16.627496 139851376510848 learning.py:507] global step 6959: loss = 2.1127 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6960: loss = 1.9010 (0.540 sec/step)\n",
            "I0517 09:50:17.169783 139851376510848 learning.py:507] global step 6960: loss = 1.9010 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6961: loss = 2.0672 (0.529 sec/step)\n",
            "I0517 09:50:17.701237 139851376510848 learning.py:507] global step 6961: loss = 2.0672 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 6962: loss = 3.8611 (0.550 sec/step)\n",
            "I0517 09:50:18.253155 139851376510848 learning.py:507] global step 6962: loss = 3.8611 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 6963: loss = 1.5516 (0.572 sec/step)\n",
            "I0517 09:50:18.826725 139851376510848 learning.py:507] global step 6963: loss = 1.5516 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6964: loss = 1.8722 (0.537 sec/step)\n",
            "I0517 09:50:19.365298 139851376510848 learning.py:507] global step 6964: loss = 1.8722 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6965: loss = 1.5150 (0.552 sec/step)\n",
            "I0517 09:50:19.919637 139851376510848 learning.py:507] global step 6965: loss = 1.5150 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6966: loss = 1.6530 (0.538 sec/step)\n",
            "I0517 09:50:20.459470 139851376510848 learning.py:507] global step 6966: loss = 1.6530 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 6967: loss = 1.5667 (0.573 sec/step)\n",
            "I0517 09:50:21.034141 139851376510848 learning.py:507] global step 6967: loss = 1.5667 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 6968: loss = 1.7658 (0.543 sec/step)\n",
            "I0517 09:50:21.578648 139851376510848 learning.py:507] global step 6968: loss = 1.7658 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 6969: loss = 2.2945 (0.553 sec/step)\n",
            "I0517 09:50:22.133939 139851376510848 learning.py:507] global step 6969: loss = 2.2945 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 6970: loss = 2.2829 (0.545 sec/step)\n",
            "I0517 09:50:22.680482 139851376510848 learning.py:507] global step 6970: loss = 2.2829 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 6971: loss = 2.3610 (0.566 sec/step)\n",
            "I0517 09:50:23.248126 139851376510848 learning.py:507] global step 6971: loss = 2.3610 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 6972: loss = 1.6374 (0.572 sec/step)\n",
            "I0517 09:50:23.823221 139851376510848 learning.py:507] global step 6972: loss = 1.6374 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 6973: loss = 2.4269 (0.552 sec/step)\n",
            "I0517 09:50:24.376755 139851376510848 learning.py:507] global step 6973: loss = 2.4269 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6974: loss = 2.2872 (0.559 sec/step)\n",
            "I0517 09:50:24.937510 139851376510848 learning.py:507] global step 6974: loss = 2.2872 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 6975: loss = 1.8490 (0.535 sec/step)\n",
            "I0517 09:50:25.474541 139851376510848 learning.py:507] global step 6975: loss = 1.8490 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 6976: loss = 3.6379 (0.547 sec/step)\n",
            "I0517 09:50:26.023011 139851376510848 learning.py:507] global step 6976: loss = 3.6379 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6977: loss = 1.8491 (0.520 sec/step)\n",
            "I0517 09:50:26.545233 139851376510848 learning.py:507] global step 6977: loss = 1.8491 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 6978: loss = 1.4993 (0.546 sec/step)\n",
            "I0517 09:50:27.092667 139851376510848 learning.py:507] global step 6978: loss = 1.4993 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6979: loss = 2.7375 (0.540 sec/step)\n",
            "I0517 09:50:27.634073 139851376510848 learning.py:507] global step 6979: loss = 2.7375 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6980: loss = 2.1204 (0.560 sec/step)\n",
            "I0517 09:50:28.195378 139851376510848 learning.py:507] global step 6980: loss = 2.1204 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 6981: loss = 1.7753 (0.540 sec/step)\n",
            "I0517 09:50:28.737222 139851376510848 learning.py:507] global step 6981: loss = 1.7753 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 6982: loss = 1.6297 (0.556 sec/step)\n",
            "I0517 09:50:29.295856 139851376510848 learning.py:507] global step 6982: loss = 1.6297 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 6983: loss = 2.2370 (0.546 sec/step)\n",
            "I0517 09:50:29.843822 139851376510848 learning.py:507] global step 6983: loss = 2.2370 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 6984: loss = 1.8604 (0.555 sec/step)\n",
            "I0517 09:50:30.400669 139851376510848 learning.py:507] global step 6984: loss = 1.8604 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6985: loss = 2.2211 (0.552 sec/step)\n",
            "I0517 09:50:30.954217 139851376510848 learning.py:507] global step 6985: loss = 2.2211 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 6986: loss = 1.4875 (0.579 sec/step)\n",
            "I0517 09:50:31.534778 139851376510848 learning.py:507] global step 6986: loss = 1.4875 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6987: loss = 1.5721 (0.537 sec/step)\n",
            "I0517 09:50:32.073015 139851376510848 learning.py:507] global step 6987: loss = 1.5721 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 6988: loss = 2.9654 (0.578 sec/step)\n",
            "I0517 09:50:32.652602 139851376510848 learning.py:507] global step 6988: loss = 2.9654 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 6989: loss = 2.1349 (0.565 sec/step)\n",
            "I0517 09:50:33.218869 139851376510848 learning.py:507] global step 6989: loss = 2.1349 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 6990: loss = 1.8772 (0.542 sec/step)\n",
            "I0517 09:50:33.762223 139851376510848 learning.py:507] global step 6990: loss = 1.8772 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 6991: loss = 1.7588 (0.563 sec/step)\n",
            "I0517 09:50:34.326965 139851376510848 learning.py:507] global step 6991: loss = 1.7588 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 6992: loss = 1.9532 (0.549 sec/step)\n",
            "I0517 09:50:34.878169 139851376510848 learning.py:507] global step 6992: loss = 1.9532 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 6993: loss = 1.7028 (0.547 sec/step)\n",
            "I0517 09:50:35.427147 139851376510848 learning.py:507] global step 6993: loss = 1.7028 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 6994: loss = 1.6153 (0.533 sec/step)\n",
            "I0517 09:50:35.962388 139851376510848 learning.py:507] global step 6994: loss = 1.6153 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 6995: loss = 1.6574 (0.555 sec/step)\n",
            "I0517 09:50:36.519182 139851376510848 learning.py:507] global step 6995: loss = 1.6574 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 6996: loss = 1.5037 (0.541 sec/step)\n",
            "I0517 09:50:37.061534 139851376510848 learning.py:507] global step 6996: loss = 1.5037 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 6997: loss = 3.0249 (0.584 sec/step)\n",
            "I0517 09:50:37.646988 139851376510848 learning.py:507] global step 6997: loss = 3.0249 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 6998: loss = 1.6605 (0.530 sec/step)\n",
            "I0517 09:50:38.178723 139851376510848 learning.py:507] global step 6998: loss = 1.6605 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 6999: loss = 1.9776 (0.533 sec/step)\n",
            "I0517 09:50:38.713397 139851376510848 learning.py:507] global step 6999: loss = 1.9776 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7000: loss = 1.7685 (0.520 sec/step)\n",
            "I0517 09:50:39.234813 139851376510848 learning.py:507] global step 7000: loss = 1.7685 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 7001: loss = 1.6688 (0.560 sec/step)\n",
            "I0517 09:50:39.796990 139851376510848 learning.py:507] global step 7001: loss = 1.6688 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7002: loss = 2.0096 (0.529 sec/step)\n",
            "I0517 09:50:40.328296 139851376510848 learning.py:507] global step 7002: loss = 2.0096 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7003: loss = 1.9386 (0.524 sec/step)\n",
            "I0517 09:50:40.853971 139851376510848 learning.py:507] global step 7003: loss = 1.9386 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7004: loss = 2.3473 (0.519 sec/step)\n",
            "I0517 09:50:41.374970 139851376510848 learning.py:507] global step 7004: loss = 2.3473 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7005: loss = 1.4466 (0.551 sec/step)\n",
            "I0517 09:50:41.927589 139851376510848 learning.py:507] global step 7005: loss = 1.4466 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7006: loss = 1.8163 (0.552 sec/step)\n",
            "I0517 09:50:42.480958 139851376510848 learning.py:507] global step 7006: loss = 1.8163 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7007: loss = 1.3033 (0.543 sec/step)\n",
            "I0517 09:50:43.026123 139851376510848 learning.py:507] global step 7007: loss = 1.3033 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7008: loss = 1.6196 (0.532 sec/step)\n",
            "I0517 09:50:43.560191 139851376510848 learning.py:507] global step 7008: loss = 1.6196 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7009: loss = 1.6235 (0.608 sec/step)\n",
            "I0517 09:50:44.170375 139851376510848 learning.py:507] global step 7009: loss = 1.6235 (0.608 sec/step)\n",
            "INFO:tensorflow:global step 7010: loss = 1.9061 (0.570 sec/step)\n",
            "I0517 09:50:44.741587 139851376510848 learning.py:507] global step 7010: loss = 1.9061 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7011: loss = 2.9001 (0.571 sec/step)\n",
            "I0517 09:50:45.314242 139851376510848 learning.py:507] global step 7011: loss = 2.9001 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7012: loss = 2.0245 (0.671 sec/step)\n",
            "I0517 09:50:46.167463 139851376510848 learning.py:507] global step 7012: loss = 2.0245 (0.671 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7012.\n",
            "I0517 09:50:47.076796 139847641536256 supervisor.py:1050] Recording summary at step 7012.\n",
            "INFO:tensorflow:global step 7013: loss = 1.6832 (1.038 sec/step)\n",
            "I0517 09:50:47.207623 139851376510848 learning.py:507] global step 7013: loss = 1.6832 (1.038 sec/step)\n",
            "INFO:tensorflow:global step 7014: loss = 1.5116 (0.544 sec/step)\n",
            "I0517 09:50:47.753195 139851376510848 learning.py:507] global step 7014: loss = 1.5116 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7015: loss = 2.6313 (0.561 sec/step)\n",
            "I0517 09:50:48.316500 139851376510848 learning.py:507] global step 7015: loss = 2.6313 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7016: loss = 2.2727 (0.571 sec/step)\n",
            "I0517 09:50:48.889790 139851376510848 learning.py:507] global step 7016: loss = 2.2727 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7017: loss = 1.6555 (0.558 sec/step)\n",
            "I0517 09:50:49.449268 139851376510848 learning.py:507] global step 7017: loss = 1.6555 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7018: loss = 1.7383 (0.549 sec/step)\n",
            "I0517 09:50:50.000396 139851376510848 learning.py:507] global step 7018: loss = 1.7383 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7019: loss = 2.2762 (0.544 sec/step)\n",
            "I0517 09:50:50.546075 139851376510848 learning.py:507] global step 7019: loss = 2.2762 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7020: loss = 2.8978 (0.598 sec/step)\n",
            "I0517 09:50:51.146781 139851376510848 learning.py:507] global step 7020: loss = 2.8978 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 7021: loss = 1.9187 (0.542 sec/step)\n",
            "I0517 09:50:51.691855 139851376510848 learning.py:507] global step 7021: loss = 1.9187 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7022: loss = 2.3336 (0.540 sec/step)\n",
            "I0517 09:50:52.233365 139851376510848 learning.py:507] global step 7022: loss = 2.3336 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7023: loss = 1.8651 (0.532 sec/step)\n",
            "I0517 09:50:52.766827 139851376510848 learning.py:507] global step 7023: loss = 1.8651 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7024: loss = 1.4353 (0.554 sec/step)\n",
            "I0517 09:50:53.322366 139851376510848 learning.py:507] global step 7024: loss = 1.4353 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7025: loss = 1.9864 (0.564 sec/step)\n",
            "I0517 09:50:53.888453 139851376510848 learning.py:507] global step 7025: loss = 1.9864 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7026: loss = 2.0349 (0.565 sec/step)\n",
            "I0517 09:50:54.455026 139851376510848 learning.py:507] global step 7026: loss = 2.0349 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7027: loss = 1.8127 (0.551 sec/step)\n",
            "I0517 09:50:55.010140 139851376510848 learning.py:507] global step 7027: loss = 1.8127 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7028: loss = 1.7463 (0.554 sec/step)\n",
            "I0517 09:50:55.566441 139851376510848 learning.py:507] global step 7028: loss = 1.7463 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7029: loss = 1.6534 (0.531 sec/step)\n",
            "I0517 09:50:56.099548 139851376510848 learning.py:507] global step 7029: loss = 1.6534 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7030: loss = 1.8802 (0.543 sec/step)\n",
            "I0517 09:50:56.643927 139851376510848 learning.py:507] global step 7030: loss = 1.8802 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7031: loss = 2.0032 (0.586 sec/step)\n",
            "I0517 09:50:57.232008 139851376510848 learning.py:507] global step 7031: loss = 2.0032 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 7032: loss = 2.0684 (0.529 sec/step)\n",
            "I0517 09:50:57.763218 139851376510848 learning.py:507] global step 7032: loss = 2.0684 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7033: loss = 2.3894 (0.558 sec/step)\n",
            "I0517 09:50:58.323363 139851376510848 learning.py:507] global step 7033: loss = 2.3894 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7034: loss = 1.7167 (0.529 sec/step)\n",
            "I0517 09:50:58.854309 139851376510848 learning.py:507] global step 7034: loss = 1.7167 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7035: loss = 1.6217 (0.556 sec/step)\n",
            "I0517 09:50:59.412057 139851376510848 learning.py:507] global step 7035: loss = 1.6217 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7036: loss = 3.4817 (0.543 sec/step)\n",
            "I0517 09:50:59.959076 139851376510848 learning.py:507] global step 7036: loss = 3.4817 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7037: loss = 3.1050 (0.543 sec/step)\n",
            "I0517 09:51:00.504132 139851376510848 learning.py:507] global step 7037: loss = 3.1050 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7038: loss = 1.6415 (0.523 sec/step)\n",
            "I0517 09:51:01.028991 139851376510848 learning.py:507] global step 7038: loss = 1.6415 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7039: loss = 3.1921 (0.550 sec/step)\n",
            "I0517 09:51:01.581247 139851376510848 learning.py:507] global step 7039: loss = 3.1921 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7040: loss = 2.0234 (0.544 sec/step)\n",
            "I0517 09:51:02.127093 139851376510848 learning.py:507] global step 7040: loss = 2.0234 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7041: loss = 1.7141 (0.556 sec/step)\n",
            "I0517 09:51:02.685669 139851376510848 learning.py:507] global step 7041: loss = 1.7141 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7042: loss = 1.5324 (0.544 sec/step)\n",
            "I0517 09:51:03.231793 139851376510848 learning.py:507] global step 7042: loss = 1.5324 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7043: loss = 1.9221 (0.521 sec/step)\n",
            "I0517 09:51:03.754120 139851376510848 learning.py:507] global step 7043: loss = 1.9221 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7044: loss = 2.0358 (0.549 sec/step)\n",
            "I0517 09:51:04.304703 139851376510848 learning.py:507] global step 7044: loss = 2.0358 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7045: loss = 1.7736 (0.534 sec/step)\n",
            "I0517 09:51:04.840498 139851376510848 learning.py:507] global step 7045: loss = 1.7736 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7046: loss = 2.0986 (0.564 sec/step)\n",
            "I0517 09:51:05.405836 139851376510848 learning.py:507] global step 7046: loss = 2.0986 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7047: loss = 2.1686 (0.516 sec/step)\n",
            "I0517 09:51:05.923936 139851376510848 learning.py:507] global step 7047: loss = 2.1686 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7048: loss = 1.8230 (0.547 sec/step)\n",
            "I0517 09:51:06.472744 139851376510848 learning.py:507] global step 7048: loss = 1.8230 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7049: loss = 1.9881 (0.567 sec/step)\n",
            "I0517 09:51:07.041995 139851376510848 learning.py:507] global step 7049: loss = 1.9881 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7050: loss = 2.1872 (0.560 sec/step)\n",
            "I0517 09:51:07.604278 139851376510848 learning.py:507] global step 7050: loss = 2.1872 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7051: loss = 1.9948 (0.560 sec/step)\n",
            "I0517 09:51:08.166686 139851376510848 learning.py:507] global step 7051: loss = 1.9948 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7052: loss = 1.7044 (0.545 sec/step)\n",
            "I0517 09:51:08.715466 139851376510848 learning.py:507] global step 7052: loss = 1.7044 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7053: loss = 1.6826 (0.552 sec/step)\n",
            "I0517 09:51:09.269434 139851376510848 learning.py:507] global step 7053: loss = 1.6826 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7054: loss = 1.9999 (0.519 sec/step)\n",
            "I0517 09:51:09.790410 139851376510848 learning.py:507] global step 7054: loss = 1.9999 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7055: loss = 2.1545 (0.544 sec/step)\n",
            "I0517 09:51:10.335969 139851376510848 learning.py:507] global step 7055: loss = 2.1545 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7056: loss = 2.6544 (0.535 sec/step)\n",
            "I0517 09:51:10.873394 139851376510848 learning.py:507] global step 7056: loss = 2.6544 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7057: loss = 1.8853 (0.532 sec/step)\n",
            "I0517 09:51:11.407177 139851376510848 learning.py:507] global step 7057: loss = 1.8853 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7058: loss = 1.5206 (0.537 sec/step)\n",
            "I0517 09:51:11.945951 139851376510848 learning.py:507] global step 7058: loss = 1.5206 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7059: loss = 1.1963 (0.545 sec/step)\n",
            "I0517 09:51:12.492478 139851376510848 learning.py:507] global step 7059: loss = 1.1963 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7060: loss = 2.2667 (0.569 sec/step)\n",
            "I0517 09:51:13.063407 139851376510848 learning.py:507] global step 7060: loss = 2.2667 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7061: loss = 3.3550 (0.544 sec/step)\n",
            "I0517 09:51:13.609537 139851376510848 learning.py:507] global step 7061: loss = 3.3550 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7062: loss = 1.3407 (0.539 sec/step)\n",
            "I0517 09:51:14.149945 139851376510848 learning.py:507] global step 7062: loss = 1.3407 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7063: loss = 1.9051 (0.543 sec/step)\n",
            "I0517 09:51:14.694457 139851376510848 learning.py:507] global step 7063: loss = 1.9051 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7064: loss = 2.4234 (0.526 sec/step)\n",
            "I0517 09:51:15.221816 139851376510848 learning.py:507] global step 7064: loss = 2.4234 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7065: loss = 2.1819 (0.552 sec/step)\n",
            "I0517 09:51:15.775762 139851376510848 learning.py:507] global step 7065: loss = 2.1819 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7066: loss = 1.8691 (0.534 sec/step)\n",
            "I0517 09:51:16.311776 139851376510848 learning.py:507] global step 7066: loss = 1.8691 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7067: loss = 2.0401 (0.524 sec/step)\n",
            "I0517 09:51:16.838016 139851376510848 learning.py:507] global step 7067: loss = 2.0401 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7068: loss = 2.2459 (0.552 sec/step)\n",
            "I0517 09:51:17.391794 139851376510848 learning.py:507] global step 7068: loss = 2.2459 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7069: loss = 1.8346 (0.543 sec/step)\n",
            "I0517 09:51:17.936770 139851376510848 learning.py:507] global step 7069: loss = 1.8346 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7070: loss = 1.8432 (0.547 sec/step)\n",
            "I0517 09:51:18.485406 139851376510848 learning.py:507] global step 7070: loss = 1.8432 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7071: loss = 1.6454 (0.548 sec/step)\n",
            "I0517 09:51:19.035023 139851376510848 learning.py:507] global step 7071: loss = 1.6454 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7072: loss = 2.2276 (0.549 sec/step)\n",
            "I0517 09:51:19.586019 139851376510848 learning.py:507] global step 7072: loss = 2.2276 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7073: loss = 1.8930 (0.558 sec/step)\n",
            "I0517 09:51:20.146217 139851376510848 learning.py:507] global step 7073: loss = 1.8930 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7074: loss = 1.5657 (0.561 sec/step)\n",
            "I0517 09:51:20.708897 139851376510848 learning.py:507] global step 7074: loss = 1.5657 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7075: loss = 2.5171 (0.535 sec/step)\n",
            "I0517 09:51:21.245615 139851376510848 learning.py:507] global step 7075: loss = 2.5171 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7076: loss = 1.5874 (0.567 sec/step)\n",
            "I0517 09:51:21.813866 139851376510848 learning.py:507] global step 7076: loss = 1.5874 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7077: loss = 2.0845 (0.539 sec/step)\n",
            "I0517 09:51:22.354964 139851376510848 learning.py:507] global step 7077: loss = 2.0845 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7078: loss = 2.2860 (0.555 sec/step)\n",
            "I0517 09:51:22.912343 139851376510848 learning.py:507] global step 7078: loss = 2.2860 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7079: loss = 2.9804 (0.529 sec/step)\n",
            "I0517 09:51:23.443580 139851376510848 learning.py:507] global step 7079: loss = 2.9804 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7080: loss = 2.1616 (0.538 sec/step)\n",
            "I0517 09:51:23.982965 139851376510848 learning.py:507] global step 7080: loss = 2.1616 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7081: loss = 2.2866 (0.544 sec/step)\n",
            "I0517 09:51:24.528698 139851376510848 learning.py:507] global step 7081: loss = 2.2866 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7082: loss = 2.7498 (0.542 sec/step)\n",
            "I0517 09:51:25.072447 139851376510848 learning.py:507] global step 7082: loss = 2.7498 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7083: loss = 1.9003 (0.551 sec/step)\n",
            "I0517 09:51:25.625098 139851376510848 learning.py:507] global step 7083: loss = 1.9003 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7084: loss = 2.8101 (0.547 sec/step)\n",
            "I0517 09:51:26.173721 139851376510848 learning.py:507] global step 7084: loss = 2.8101 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7085: loss = 1.7746 (0.561 sec/step)\n",
            "I0517 09:51:26.736947 139851376510848 learning.py:507] global step 7085: loss = 1.7746 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7086: loss = 1.6002 (0.557 sec/step)\n",
            "I0517 09:51:27.296157 139851376510848 learning.py:507] global step 7086: loss = 1.6002 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7087: loss = 2.8171 (0.568 sec/step)\n",
            "I0517 09:51:27.866013 139851376510848 learning.py:507] global step 7087: loss = 2.8171 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7088: loss = 2.1589 (0.526 sec/step)\n",
            "I0517 09:51:28.394229 139851376510848 learning.py:507] global step 7088: loss = 2.1589 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7089: loss = 1.9801 (0.539 sec/step)\n",
            "I0517 09:51:28.935467 139851376510848 learning.py:507] global step 7089: loss = 1.9801 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7090: loss = 1.5045 (0.524 sec/step)\n",
            "I0517 09:51:29.460673 139851376510848 learning.py:507] global step 7090: loss = 1.5045 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7091: loss = 3.7930 (0.573 sec/step)\n",
            "I0517 09:51:30.035021 139851376510848 learning.py:507] global step 7091: loss = 3.7930 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 7092: loss = 1.6637 (0.521 sec/step)\n",
            "I0517 09:51:30.558729 139851376510848 learning.py:507] global step 7092: loss = 1.6637 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7093: loss = 1.6411 (0.553 sec/step)\n",
            "I0517 09:51:31.113783 139851376510848 learning.py:507] global step 7093: loss = 1.6411 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7094: loss = 1.7857 (0.562 sec/step)\n",
            "I0517 09:51:31.677826 139851376510848 learning.py:507] global step 7094: loss = 1.7857 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7095: loss = 1.8331 (0.558 sec/step)\n",
            "I0517 09:51:32.237952 139851376510848 learning.py:507] global step 7095: loss = 1.8331 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7096: loss = 1.8252 (0.539 sec/step)\n",
            "I0517 09:51:32.778991 139851376510848 learning.py:507] global step 7096: loss = 1.8252 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7097: loss = 1.8871 (0.554 sec/step)\n",
            "I0517 09:51:33.335272 139851376510848 learning.py:507] global step 7097: loss = 1.8871 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7098: loss = 1.7297 (0.561 sec/step)\n",
            "I0517 09:51:33.898385 139851376510848 learning.py:507] global step 7098: loss = 1.7297 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7099: loss = 2.1310 (0.578 sec/step)\n",
            "I0517 09:51:34.478477 139851376510848 learning.py:507] global step 7099: loss = 2.1310 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7100: loss = 2.0978 (0.546 sec/step)\n",
            "I0517 09:51:35.026396 139851376510848 learning.py:507] global step 7100: loss = 2.0978 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7101: loss = 2.2859 (0.545 sec/step)\n",
            "I0517 09:51:35.573687 139851376510848 learning.py:507] global step 7101: loss = 2.2859 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7102: loss = 1.5828 (0.570 sec/step)\n",
            "I0517 09:51:36.145201 139851376510848 learning.py:507] global step 7102: loss = 1.5828 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7103: loss = 1.3912 (0.545 sec/step)\n",
            "I0517 09:51:36.692188 139851376510848 learning.py:507] global step 7103: loss = 1.3912 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7104: loss = 2.0495 (0.569 sec/step)\n",
            "I0517 09:51:37.263579 139851376510848 learning.py:507] global step 7104: loss = 2.0495 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7105: loss = 1.7052 (0.542 sec/step)\n",
            "I0517 09:51:37.807533 139851376510848 learning.py:507] global step 7105: loss = 1.7052 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7106: loss = 1.7409 (0.574 sec/step)\n",
            "I0517 09:51:38.383695 139851376510848 learning.py:507] global step 7106: loss = 1.7409 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7107: loss = 2.2502 (0.565 sec/step)\n",
            "I0517 09:51:38.950525 139851376510848 learning.py:507] global step 7107: loss = 2.2502 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7108: loss = 1.7843 (0.533 sec/step)\n",
            "I0517 09:51:39.485557 139851376510848 learning.py:507] global step 7108: loss = 1.7843 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7109: loss = 2.4497 (0.530 sec/step)\n",
            "I0517 09:51:40.017403 139851376510848 learning.py:507] global step 7109: loss = 2.4497 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7110: loss = 2.7354 (0.556 sec/step)\n",
            "I0517 09:51:40.575059 139851376510848 learning.py:507] global step 7110: loss = 2.7354 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7111: loss = 1.8207 (0.556 sec/step)\n",
            "I0517 09:51:41.133341 139851376510848 learning.py:507] global step 7111: loss = 1.8207 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7112: loss = 1.3506 (0.523 sec/step)\n",
            "I0517 09:51:41.657821 139851376510848 learning.py:507] global step 7112: loss = 1.3506 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7113: loss = 2.3181 (0.552 sec/step)\n",
            "I0517 09:51:42.211782 139851376510848 learning.py:507] global step 7113: loss = 2.3181 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7114: loss = 1.4334 (0.538 sec/step)\n",
            "I0517 09:51:42.751727 139851376510848 learning.py:507] global step 7114: loss = 1.4334 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7115: loss = 2.1310 (0.574 sec/step)\n",
            "I0517 09:51:43.327417 139851376510848 learning.py:507] global step 7115: loss = 2.1310 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7116: loss = 2.0002 (0.539 sec/step)\n",
            "I0517 09:51:43.868300 139851376510848 learning.py:507] global step 7116: loss = 2.0002 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7117: loss = 1.8833 (0.552 sec/step)\n",
            "I0517 09:51:44.422364 139851376510848 learning.py:507] global step 7117: loss = 1.8833 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7118: loss = 1.9636 (0.551 sec/step)\n",
            "I0517 09:51:44.975678 139851376510848 learning.py:507] global step 7118: loss = 1.9636 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7119: loss = 2.3147 (0.554 sec/step)\n",
            "I0517 09:51:45.531517 139851376510848 learning.py:507] global step 7119: loss = 2.3147 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7120: loss = 2.1159 (0.543 sec/step)\n",
            "I0517 09:51:46.076825 139851376510848 learning.py:507] global step 7120: loss = 2.1159 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7121: loss = 1.5901 (0.524 sec/step)\n",
            "I0517 09:51:46.602581 139851376510848 learning.py:507] global step 7121: loss = 1.5901 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7122: loss = 1.6943 (0.582 sec/step)\n",
            "I0517 09:51:47.186431 139851376510848 learning.py:507] global step 7122: loss = 1.6943 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 7123: loss = 2.4401 (0.573 sec/step)\n",
            "I0517 09:51:47.761013 139851376510848 learning.py:507] global step 7123: loss = 2.4401 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 7124: loss = 1.7953 (0.550 sec/step)\n",
            "I0517 09:51:48.313459 139851376510848 learning.py:507] global step 7124: loss = 1.7953 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7125: loss = 1.9483 (0.545 sec/step)\n",
            "I0517 09:51:48.859897 139851376510848 learning.py:507] global step 7125: loss = 1.9483 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7126: loss = 2.2746 (0.531 sec/step)\n",
            "I0517 09:51:49.394008 139851376510848 learning.py:507] global step 7126: loss = 2.2746 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7127: loss = 1.9653 (0.575 sec/step)\n",
            "I0517 09:51:49.970471 139851376510848 learning.py:507] global step 7127: loss = 1.9653 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7128: loss = 2.0986 (0.537 sec/step)\n",
            "I0517 09:51:50.508922 139851376510848 learning.py:507] global step 7128: loss = 2.0986 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7129: loss = 1.7632 (0.524 sec/step)\n",
            "I0517 09:51:51.034863 139851376510848 learning.py:507] global step 7129: loss = 1.7632 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7130: loss = 1.8819 (0.555 sec/step)\n",
            "I0517 09:51:51.591137 139851376510848 learning.py:507] global step 7130: loss = 1.8819 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7131: loss = 2.2165 (0.550 sec/step)\n",
            "I0517 09:51:52.142606 139851376510848 learning.py:507] global step 7131: loss = 2.2165 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7132: loss = 2.1758 (0.566 sec/step)\n",
            "I0517 09:51:52.710108 139851376510848 learning.py:507] global step 7132: loss = 2.1758 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7133: loss = 1.7639 (0.637 sec/step)\n",
            "I0517 09:51:53.349331 139851376510848 learning.py:507] global step 7133: loss = 1.7639 (0.637 sec/step)\n",
            "INFO:tensorflow:global step 7134: loss = 1.6565 (0.622 sec/step)\n",
            "I0517 09:51:53.975427 139851376510848 learning.py:507] global step 7134: loss = 1.6565 (0.622 sec/step)\n",
            "INFO:tensorflow:global step 7135: loss = 2.1173 (0.553 sec/step)\n",
            "I0517 09:51:54.530311 139851376510848 learning.py:507] global step 7135: loss = 2.1173 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7136: loss = 2.0305 (0.545 sec/step)\n",
            "I0517 09:51:55.078443 139851376510848 learning.py:507] global step 7136: loss = 2.0305 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7137: loss = 1.8774 (0.574 sec/step)\n",
            "I0517 09:51:55.654104 139851376510848 learning.py:507] global step 7137: loss = 1.8774 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7138: loss = 2.4103 (0.550 sec/step)\n",
            "I0517 09:51:56.205701 139851376510848 learning.py:507] global step 7138: loss = 2.4103 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7139: loss = 1.5783 (0.615 sec/step)\n",
            "I0517 09:51:56.822288 139851376510848 learning.py:507] global step 7139: loss = 1.5783 (0.615 sec/step)\n",
            "INFO:tensorflow:global step 7140: loss = 2.1243 (0.550 sec/step)\n",
            "I0517 09:51:57.373967 139851376510848 learning.py:507] global step 7140: loss = 2.1243 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7141: loss = 3.2241 (0.576 sec/step)\n",
            "I0517 09:51:57.951688 139851376510848 learning.py:507] global step 7141: loss = 3.2241 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 7142: loss = 1.8623 (0.570 sec/step)\n",
            "I0517 09:51:58.523189 139851376510848 learning.py:507] global step 7142: loss = 1.8623 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7143: loss = 2.1263 (0.559 sec/step)\n",
            "I0517 09:51:59.083506 139851376510848 learning.py:507] global step 7143: loss = 2.1263 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7144: loss = 1.5802 (0.557 sec/step)\n",
            "I0517 09:51:59.642586 139851376510848 learning.py:507] global step 7144: loss = 1.5802 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7145: loss = 2.0169 (0.556 sec/step)\n",
            "I0517 09:52:00.200021 139851376510848 learning.py:507] global step 7145: loss = 2.0169 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7146: loss = 2.0381 (0.542 sec/step)\n",
            "I0517 09:52:00.744530 139851376510848 learning.py:507] global step 7146: loss = 2.0381 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7147: loss = 2.7400 (0.543 sec/step)\n",
            "I0517 09:52:01.289245 139851376510848 learning.py:507] global step 7147: loss = 2.7400 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7148: loss = 2.0188 (0.546 sec/step)\n",
            "I0517 09:52:01.837129 139851376510848 learning.py:507] global step 7148: loss = 2.0188 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7149: loss = 1.6223 (0.534 sec/step)\n",
            "I0517 09:52:02.373998 139851376510848 learning.py:507] global step 7149: loss = 1.6223 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7150: loss = 1.9638 (0.541 sec/step)\n",
            "I0517 09:52:02.916729 139851376510848 learning.py:507] global step 7150: loss = 1.9638 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7151: loss = 2.0812 (0.552 sec/step)\n",
            "I0517 09:52:03.470920 139851376510848 learning.py:507] global step 7151: loss = 2.0812 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7152: loss = 2.6248 (0.541 sec/step)\n",
            "I0517 09:52:04.013518 139851376510848 learning.py:507] global step 7152: loss = 2.6248 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7153: loss = 2.0737 (0.545 sec/step)\n",
            "I0517 09:52:04.560373 139851376510848 learning.py:507] global step 7153: loss = 2.0737 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7154: loss = 1.9194 (0.558 sec/step)\n",
            "I0517 09:52:05.120397 139851376510848 learning.py:507] global step 7154: loss = 1.9194 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7155: loss = 2.0766 (0.555 sec/step)\n",
            "I0517 09:52:05.678564 139851376510848 learning.py:507] global step 7155: loss = 2.0766 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7156: loss = 1.6249 (0.558 sec/step)\n",
            "I0517 09:52:06.239506 139851376510848 learning.py:507] global step 7156: loss = 1.6249 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7157: loss = 1.4465 (0.541 sec/step)\n",
            "I0517 09:52:06.781967 139851376510848 learning.py:507] global step 7157: loss = 1.4465 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7158: loss = 1.7155 (0.553 sec/step)\n",
            "I0517 09:52:07.336432 139851376510848 learning.py:507] global step 7158: loss = 1.7155 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7159: loss = 1.8047 (0.552 sec/step)\n",
            "I0517 09:52:07.890637 139851376510848 learning.py:507] global step 7159: loss = 1.8047 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7160: loss = 1.9452 (0.567 sec/step)\n",
            "I0517 09:52:08.459966 139851376510848 learning.py:507] global step 7160: loss = 1.9452 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7161: loss = 2.0762 (0.550 sec/step)\n",
            "I0517 09:52:09.011472 139851376510848 learning.py:507] global step 7161: loss = 2.0762 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7162: loss = 1.5437 (0.550 sec/step)\n",
            "I0517 09:52:09.564779 139851376510848 learning.py:507] global step 7162: loss = 1.5437 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7163: loss = 2.9491 (0.581 sec/step)\n",
            "I0517 09:52:10.147266 139851376510848 learning.py:507] global step 7163: loss = 2.9491 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 7164: loss = 2.2990 (0.562 sec/step)\n",
            "I0517 09:52:10.711019 139851376510848 learning.py:507] global step 7164: loss = 2.2990 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7165: loss = 1.6551 (0.562 sec/step)\n",
            "I0517 09:52:11.274640 139851376510848 learning.py:507] global step 7165: loss = 1.6551 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7166: loss = 1.7625 (0.538 sec/step)\n",
            "I0517 09:52:11.814548 139851376510848 learning.py:507] global step 7166: loss = 1.7625 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7167: loss = 2.1086 (0.558 sec/step)\n",
            "I0517 09:52:12.374083 139851376510848 learning.py:507] global step 7167: loss = 2.1086 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7168: loss = 1.7330 (0.543 sec/step)\n",
            "I0517 09:52:12.918762 139851376510848 learning.py:507] global step 7168: loss = 1.7330 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7169: loss = 1.7875 (0.564 sec/step)\n",
            "I0517 09:52:13.484863 139851376510848 learning.py:507] global step 7169: loss = 1.7875 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7170: loss = 3.2072 (0.542 sec/step)\n",
            "I0517 09:52:14.034418 139851376510848 learning.py:507] global step 7170: loss = 3.2072 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7171: loss = 2.3144 (0.577 sec/step)\n",
            "I0517 09:52:14.612891 139851376510848 learning.py:507] global step 7171: loss = 2.3144 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 7172: loss = 2.8926 (0.530 sec/step)\n",
            "I0517 09:52:15.144683 139851376510848 learning.py:507] global step 7172: loss = 2.8926 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7173: loss = 1.7154 (0.563 sec/step)\n",
            "I0517 09:52:15.709729 139851376510848 learning.py:507] global step 7173: loss = 1.7154 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7174: loss = 2.4447 (0.548 sec/step)\n",
            "I0517 09:52:16.258798 139851376510848 learning.py:507] global step 7174: loss = 2.4447 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7175: loss = 1.4050 (0.545 sec/step)\n",
            "I0517 09:52:16.805838 139851376510848 learning.py:507] global step 7175: loss = 1.4050 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7176: loss = 1.5565 (0.563 sec/step)\n",
            "I0517 09:52:17.370648 139851376510848 learning.py:507] global step 7176: loss = 1.5565 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7177: loss = 1.9291 (0.527 sec/step)\n",
            "I0517 09:52:17.899432 139851376510848 learning.py:507] global step 7177: loss = 1.9291 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7178: loss = 1.8678 (0.575 sec/step)\n",
            "I0517 09:52:18.477240 139851376510848 learning.py:507] global step 7178: loss = 1.8678 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7179: loss = 1.4992 (0.524 sec/step)\n",
            "I0517 09:52:19.003285 139851376510848 learning.py:507] global step 7179: loss = 1.4992 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7180: loss = 1.6999 (0.537 sec/step)\n",
            "I0517 09:52:19.542447 139851376510848 learning.py:507] global step 7180: loss = 1.6999 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7181: loss = 1.8485 (0.546 sec/step)\n",
            "I0517 09:52:20.089914 139851376510848 learning.py:507] global step 7181: loss = 1.8485 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7182: loss = 1.5542 (0.550 sec/step)\n",
            "I0517 09:52:20.641477 139851376510848 learning.py:507] global step 7182: loss = 1.5542 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7183: loss = 2.4541 (0.524 sec/step)\n",
            "I0517 09:52:21.167208 139851376510848 learning.py:507] global step 7183: loss = 2.4541 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7184: loss = 1.9138 (0.554 sec/step)\n",
            "I0517 09:52:21.723227 139851376510848 learning.py:507] global step 7184: loss = 1.9138 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7185: loss = 2.3181 (0.531 sec/step)\n",
            "I0517 09:52:22.255927 139851376510848 learning.py:507] global step 7185: loss = 2.3181 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7186: loss = 1.9017 (0.549 sec/step)\n",
            "I0517 09:52:22.806280 139851376510848 learning.py:507] global step 7186: loss = 1.9017 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7187: loss = 2.3062 (0.539 sec/step)\n",
            "I0517 09:52:23.346987 139851376510848 learning.py:507] global step 7187: loss = 2.3062 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7188: loss = 2.0201 (0.535 sec/step)\n",
            "I0517 09:52:23.883233 139851376510848 learning.py:507] global step 7188: loss = 2.0201 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7189: loss = 1.7892 (0.543 sec/step)\n",
            "I0517 09:52:24.428295 139851376510848 learning.py:507] global step 7189: loss = 1.7892 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7190: loss = 2.0462 (0.544 sec/step)\n",
            "I0517 09:52:24.974184 139851376510848 learning.py:507] global step 7190: loss = 2.0462 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7191: loss = 2.2296 (0.566 sec/step)\n",
            "I0517 09:52:25.541564 139851376510848 learning.py:507] global step 7191: loss = 2.2296 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7192: loss = 1.9471 (0.537 sec/step)\n",
            "I0517 09:52:26.080560 139851376510848 learning.py:507] global step 7192: loss = 1.9471 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7193: loss = 2.7200 (0.564 sec/step)\n",
            "I0517 09:52:26.645919 139851376510848 learning.py:507] global step 7193: loss = 2.7200 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7194: loss = 2.3378 (0.531 sec/step)\n",
            "I0517 09:52:27.178425 139851376510848 learning.py:507] global step 7194: loss = 2.3378 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7195: loss = 2.8650 (0.544 sec/step)\n",
            "I0517 09:52:27.723808 139851376510848 learning.py:507] global step 7195: loss = 2.8650 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7196: loss = 1.7456 (0.568 sec/step)\n",
            "I0517 09:52:28.293602 139851376510848 learning.py:507] global step 7196: loss = 1.7456 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7197: loss = 2.1863 (0.561 sec/step)\n",
            "I0517 09:52:28.856394 139851376510848 learning.py:507] global step 7197: loss = 2.1863 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7198: loss = 1.2986 (0.546 sec/step)\n",
            "I0517 09:52:29.404187 139851376510848 learning.py:507] global step 7198: loss = 1.2986 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7199: loss = 1.4760 (0.554 sec/step)\n",
            "I0517 09:52:29.959821 139851376510848 learning.py:507] global step 7199: loss = 1.4760 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7200: loss = 1.7083 (0.540 sec/step)\n",
            "I0517 09:52:30.501610 139851376510848 learning.py:507] global step 7200: loss = 1.7083 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7201: loss = 2.2706 (0.539 sec/step)\n",
            "I0517 09:52:31.042443 139851376510848 learning.py:507] global step 7201: loss = 2.2706 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7202: loss = 2.6189 (0.537 sec/step)\n",
            "I0517 09:52:31.580704 139851376510848 learning.py:507] global step 7202: loss = 2.6189 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7203: loss = 3.7222 (0.561 sec/step)\n",
            "I0517 09:52:32.143201 139851376510848 learning.py:507] global step 7203: loss = 3.7222 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7204: loss = 1.9527 (0.564 sec/step)\n",
            "I0517 09:52:32.708977 139851376510848 learning.py:507] global step 7204: loss = 1.9527 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7205: loss = 1.6247 (0.516 sec/step)\n",
            "I0517 09:52:33.226997 139851376510848 learning.py:507] global step 7205: loss = 1.6247 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7206: loss = 1.7107 (0.546 sec/step)\n",
            "I0517 09:52:33.774908 139851376510848 learning.py:507] global step 7206: loss = 1.7107 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7207: loss = 1.6401 (0.532 sec/step)\n",
            "I0517 09:52:34.308896 139851376510848 learning.py:507] global step 7207: loss = 1.6401 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7208: loss = 1.9806 (0.555 sec/step)\n",
            "I0517 09:52:34.865076 139851376510848 learning.py:507] global step 7208: loss = 1.9806 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7209: loss = 2.1235 (0.569 sec/step)\n",
            "I0517 09:52:35.435403 139851376510848 learning.py:507] global step 7209: loss = 2.1235 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7210: loss = 1.5295 (0.562 sec/step)\n",
            "I0517 09:52:35.998847 139851376510848 learning.py:507] global step 7210: loss = 1.5295 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7211: loss = 1.7958 (0.591 sec/step)\n",
            "I0517 09:52:36.591335 139851376510848 learning.py:507] global step 7211: loss = 1.7958 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 7212: loss = 2.5680 (0.556 sec/step)\n",
            "I0517 09:52:37.149321 139851376510848 learning.py:507] global step 7212: loss = 2.5680 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7213: loss = 1.4448 (0.561 sec/step)\n",
            "I0517 09:52:37.713665 139851376510848 learning.py:507] global step 7213: loss = 1.4448 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7214: loss = 2.2650 (0.519 sec/step)\n",
            "I0517 09:52:38.236020 139851376510848 learning.py:507] global step 7214: loss = 2.2650 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7215: loss = 2.2513 (0.541 sec/step)\n",
            "I0517 09:52:38.779438 139851376510848 learning.py:507] global step 7215: loss = 2.2513 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7216: loss = 1.9586 (0.572 sec/step)\n",
            "I0517 09:52:39.353428 139851376510848 learning.py:507] global step 7216: loss = 1.9586 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7217: loss = 1.6773 (0.579 sec/step)\n",
            "I0517 09:52:39.934528 139851376510848 learning.py:507] global step 7217: loss = 1.6773 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 7218: loss = 2.4095 (0.546 sec/step)\n",
            "I0517 09:52:40.482658 139851376510848 learning.py:507] global step 7218: loss = 2.4095 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7219: loss = 2.3115 (0.542 sec/step)\n",
            "I0517 09:52:41.026833 139851376510848 learning.py:507] global step 7219: loss = 2.3115 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7220: loss = 1.9447 (0.516 sec/step)\n",
            "I0517 09:52:41.544269 139851376510848 learning.py:507] global step 7220: loss = 1.9447 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7221: loss = 1.5976 (0.533 sec/step)\n",
            "I0517 09:52:42.079708 139851376510848 learning.py:507] global step 7221: loss = 1.5976 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7222: loss = 2.2612 (0.539 sec/step)\n",
            "I0517 09:52:42.620174 139851376510848 learning.py:507] global step 7222: loss = 2.2612 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7223: loss = 1.6942 (0.556 sec/step)\n",
            "I0517 09:52:43.178244 139851376510848 learning.py:507] global step 7223: loss = 1.6942 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7224: loss = 2.2563 (0.530 sec/step)\n",
            "I0517 09:52:43.710095 139851376510848 learning.py:507] global step 7224: loss = 2.2563 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7225: loss = 1.5613 (0.560 sec/step)\n",
            "I0517 09:52:44.271923 139851376510848 learning.py:507] global step 7225: loss = 1.5613 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7226: loss = 1.7677 (0.546 sec/step)\n",
            "I0517 09:52:44.819940 139851376510848 learning.py:507] global step 7226: loss = 1.7677 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7227: loss = 2.3329 (0.539 sec/step)\n",
            "I0517 09:52:45.361148 139851376510848 learning.py:507] global step 7227: loss = 2.3329 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7228: loss = 1.3568 (0.670 sec/step)\n",
            "I0517 09:52:46.194607 139851376510848 learning.py:507] global step 7228: loss = 1.3568 (0.670 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7228.\n",
            "I0517 09:52:47.071804 139847641536256 supervisor.py:1050] Recording summary at step 7228.\n",
            "INFO:tensorflow:global step 7229: loss = 1.6232 (1.003 sec/step)\n",
            "I0517 09:52:47.199461 139851376510848 learning.py:507] global step 7229: loss = 1.6232 (1.003 sec/step)\n",
            "INFO:tensorflow:global step 7230: loss = 3.2912 (0.544 sec/step)\n",
            "I0517 09:52:47.745329 139851376510848 learning.py:507] global step 7230: loss = 3.2912 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7231: loss = 2.7387 (0.549 sec/step)\n",
            "I0517 09:52:48.296656 139851376510848 learning.py:507] global step 7231: loss = 2.7387 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7232: loss = 1.8486 (0.539 sec/step)\n",
            "I0517 09:52:48.837484 139851376510848 learning.py:507] global step 7232: loss = 1.8486 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7233: loss = 2.7185 (0.563 sec/step)\n",
            "I0517 09:52:49.402454 139851376510848 learning.py:507] global step 7233: loss = 2.7185 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7234: loss = 2.0777 (0.526 sec/step)\n",
            "I0517 09:52:49.930422 139851376510848 learning.py:507] global step 7234: loss = 2.0777 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7235: loss = 1.8790 (0.562 sec/step)\n",
            "I0517 09:52:50.494569 139851376510848 learning.py:507] global step 7235: loss = 1.8790 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7236: loss = 2.0479 (0.548 sec/step)\n",
            "I0517 09:52:51.044559 139851376510848 learning.py:507] global step 7236: loss = 2.0479 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7237: loss = 2.2916 (0.563 sec/step)\n",
            "I0517 09:52:51.609417 139851376510848 learning.py:507] global step 7237: loss = 2.2916 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7238: loss = 2.3212 (0.555 sec/step)\n",
            "I0517 09:52:52.167482 139851376510848 learning.py:507] global step 7238: loss = 2.3212 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7239: loss = 1.5984 (0.549 sec/step)\n",
            "I0517 09:52:52.718041 139851376510848 learning.py:507] global step 7239: loss = 1.5984 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7240: loss = 3.0404 (0.544 sec/step)\n",
            "I0517 09:52:53.263710 139851376510848 learning.py:507] global step 7240: loss = 3.0404 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7241: loss = 1.4716 (0.513 sec/step)\n",
            "I0517 09:52:53.777935 139851376510848 learning.py:507] global step 7241: loss = 1.4716 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 7242: loss = 1.5372 (0.537 sec/step)\n",
            "I0517 09:52:54.316243 139851376510848 learning.py:507] global step 7242: loss = 1.5372 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7243: loss = 1.4823 (0.535 sec/step)\n",
            "I0517 09:52:54.853850 139851376510848 learning.py:507] global step 7243: loss = 1.4823 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7244: loss = 1.5150 (0.552 sec/step)\n",
            "I0517 09:52:55.408157 139851376510848 learning.py:507] global step 7244: loss = 1.5150 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7245: loss = 1.9269 (0.531 sec/step)\n",
            "I0517 09:52:55.940655 139851376510848 learning.py:507] global step 7245: loss = 1.9269 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7246: loss = 2.2614 (0.548 sec/step)\n",
            "I0517 09:52:56.491070 139851376510848 learning.py:507] global step 7246: loss = 2.2614 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7247: loss = 4.3144 (0.552 sec/step)\n",
            "I0517 09:52:57.044477 139851376510848 learning.py:507] global step 7247: loss = 4.3144 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7248: loss = 1.8893 (0.537 sec/step)\n",
            "I0517 09:52:57.583215 139851376510848 learning.py:507] global step 7248: loss = 1.8893 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7249: loss = 1.4852 (0.529 sec/step)\n",
            "I0517 09:52:58.114109 139851376510848 learning.py:507] global step 7249: loss = 1.4852 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7250: loss = 1.4176 (0.542 sec/step)\n",
            "I0517 09:52:58.657837 139851376510848 learning.py:507] global step 7250: loss = 1.4176 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7251: loss = 2.3535 (0.525 sec/step)\n",
            "I0517 09:52:59.184506 139851376510848 learning.py:507] global step 7251: loss = 2.3535 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7252: loss = 1.5895 (0.542 sec/step)\n",
            "I0517 09:52:59.728431 139851376510848 learning.py:507] global step 7252: loss = 1.5895 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7253: loss = 1.8815 (0.516 sec/step)\n",
            "I0517 09:53:00.246453 139851376510848 learning.py:507] global step 7253: loss = 1.8815 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7254: loss = 1.5712 (0.552 sec/step)\n",
            "I0517 09:53:00.799784 139851376510848 learning.py:507] global step 7254: loss = 1.5712 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7255: loss = 2.8391 (0.531 sec/step)\n",
            "I0517 09:53:01.333154 139851376510848 learning.py:507] global step 7255: loss = 2.8391 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7256: loss = 2.5040 (0.559 sec/step)\n",
            "I0517 09:53:01.894313 139851376510848 learning.py:507] global step 7256: loss = 2.5040 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7257: loss = 2.6343 (0.546 sec/step)\n",
            "I0517 09:53:02.441962 139851376510848 learning.py:507] global step 7257: loss = 2.6343 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7258: loss = 1.5289 (0.519 sec/step)\n",
            "I0517 09:53:02.962804 139851376510848 learning.py:507] global step 7258: loss = 1.5289 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7259: loss = 2.0083 (0.562 sec/step)\n",
            "I0517 09:53:03.526715 139851376510848 learning.py:507] global step 7259: loss = 2.0083 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7260: loss = 1.9699 (0.547 sec/step)\n",
            "I0517 09:53:04.075504 139851376510848 learning.py:507] global step 7260: loss = 1.9699 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7261: loss = 2.4415 (0.556 sec/step)\n",
            "I0517 09:53:04.633504 139851376510848 learning.py:507] global step 7261: loss = 2.4415 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7262: loss = 2.3332 (0.528 sec/step)\n",
            "I0517 09:53:05.163265 139851376510848 learning.py:507] global step 7262: loss = 2.3332 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7263: loss = 2.0121 (0.537 sec/step)\n",
            "I0517 09:53:05.701859 139851376510848 learning.py:507] global step 7263: loss = 2.0121 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7264: loss = 1.9573 (0.528 sec/step)\n",
            "I0517 09:53:06.231834 139851376510848 learning.py:507] global step 7264: loss = 1.9573 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7265: loss = 2.2891 (0.539 sec/step)\n",
            "I0517 09:53:06.772446 139851376510848 learning.py:507] global step 7265: loss = 2.2891 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7266: loss = 2.0229 (0.539 sec/step)\n",
            "I0517 09:53:07.313082 139851376510848 learning.py:507] global step 7266: loss = 2.0229 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7267: loss = 2.0945 (0.554 sec/step)\n",
            "I0517 09:53:07.868988 139851376510848 learning.py:507] global step 7267: loss = 2.0945 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7268: loss = 1.9346 (0.554 sec/step)\n",
            "I0517 09:53:08.424426 139851376510848 learning.py:507] global step 7268: loss = 1.9346 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7269: loss = 2.8471 (0.539 sec/step)\n",
            "I0517 09:53:08.965558 139851376510848 learning.py:507] global step 7269: loss = 2.8471 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7270: loss = 3.0751 (0.559 sec/step)\n",
            "I0517 09:53:09.526229 139851376510848 learning.py:507] global step 7270: loss = 3.0751 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7271: loss = 2.4811 (0.539 sec/step)\n",
            "I0517 09:53:10.066676 139851376510848 learning.py:507] global step 7271: loss = 2.4811 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7272: loss = 3.1142 (0.555 sec/step)\n",
            "I0517 09:53:10.624160 139851376510848 learning.py:507] global step 7272: loss = 3.1142 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7273: loss = 1.7616 (0.558 sec/step)\n",
            "I0517 09:53:11.184403 139851376510848 learning.py:507] global step 7273: loss = 1.7616 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7274: loss = 2.6349 (0.562 sec/step)\n",
            "I0517 09:53:11.748415 139851376510848 learning.py:507] global step 7274: loss = 2.6349 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7275: loss = 1.6335 (0.549 sec/step)\n",
            "I0517 09:53:12.299261 139851376510848 learning.py:507] global step 7275: loss = 1.6335 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7276: loss = 1.6496 (0.539 sec/step)\n",
            "I0517 09:53:12.839832 139851376510848 learning.py:507] global step 7276: loss = 1.6496 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7277: loss = 2.4951 (0.540 sec/step)\n",
            "I0517 09:53:13.381534 139851376510848 learning.py:507] global step 7277: loss = 2.4951 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7278: loss = 1.9483 (0.530 sec/step)\n",
            "I0517 09:53:13.913721 139851376510848 learning.py:507] global step 7278: loss = 1.9483 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7279: loss = 1.9714 (0.566 sec/step)\n",
            "I0517 09:53:14.481981 139851376510848 learning.py:507] global step 7279: loss = 1.9714 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7280: loss = 2.4586 (0.540 sec/step)\n",
            "I0517 09:53:15.024203 139851376510848 learning.py:507] global step 7280: loss = 2.4586 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7281: loss = 1.5820 (0.535 sec/step)\n",
            "I0517 09:53:15.561260 139851376510848 learning.py:507] global step 7281: loss = 1.5820 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7282: loss = 2.0490 (0.554 sec/step)\n",
            "I0517 09:53:16.117232 139851376510848 learning.py:507] global step 7282: loss = 2.0490 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7283: loss = 2.8925 (0.551 sec/step)\n",
            "I0517 09:53:16.670320 139851376510848 learning.py:507] global step 7283: loss = 2.8925 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7284: loss = 1.7977 (0.535 sec/step)\n",
            "I0517 09:53:17.207633 139851376510848 learning.py:507] global step 7284: loss = 1.7977 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7285: loss = 1.5505 (0.546 sec/step)\n",
            "I0517 09:53:17.755018 139851376510848 learning.py:507] global step 7285: loss = 1.5505 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7286: loss = 1.8296 (0.540 sec/step)\n",
            "I0517 09:53:18.296364 139851376510848 learning.py:507] global step 7286: loss = 1.8296 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7287: loss = 2.6441 (0.565 sec/step)\n",
            "I0517 09:53:18.863243 139851376510848 learning.py:507] global step 7287: loss = 2.6441 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7288: loss = 2.2606 (0.518 sec/step)\n",
            "I0517 09:53:19.384062 139851376510848 learning.py:507] global step 7288: loss = 2.2606 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7289: loss = 2.9080 (0.541 sec/step)\n",
            "I0517 09:53:19.928110 139851376510848 learning.py:507] global step 7289: loss = 2.9080 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7290: loss = 1.9689 (0.540 sec/step)\n",
            "I0517 09:53:20.470117 139851376510848 learning.py:507] global step 7290: loss = 1.9689 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7291: loss = 1.9613 (0.555 sec/step)\n",
            "I0517 09:53:21.026905 139851376510848 learning.py:507] global step 7291: loss = 1.9613 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7292: loss = 1.6304 (0.567 sec/step)\n",
            "I0517 09:53:21.596443 139851376510848 learning.py:507] global step 7292: loss = 1.6304 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7293: loss = 3.4632 (0.538 sec/step)\n",
            "I0517 09:53:22.136411 139851376510848 learning.py:507] global step 7293: loss = 3.4632 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7294: loss = 1.5385 (0.586 sec/step)\n",
            "I0517 09:53:22.724694 139851376510848 learning.py:507] global step 7294: loss = 1.5385 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 7295: loss = 1.7803 (0.540 sec/step)\n",
            "I0517 09:53:23.266952 139851376510848 learning.py:507] global step 7295: loss = 1.7803 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7296: loss = 2.2423 (0.543 sec/step)\n",
            "I0517 09:53:23.811499 139851376510848 learning.py:507] global step 7296: loss = 2.2423 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7297: loss = 1.8563 (0.549 sec/step)\n",
            "I0517 09:53:24.362400 139851376510848 learning.py:507] global step 7297: loss = 1.8563 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7298: loss = 3.0619 (0.545 sec/step)\n",
            "I0517 09:53:24.909010 139851376510848 learning.py:507] global step 7298: loss = 3.0619 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7299: loss = 2.5780 (0.535 sec/step)\n",
            "I0517 09:53:25.445638 139851376510848 learning.py:507] global step 7299: loss = 2.5780 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7300: loss = 2.0836 (0.562 sec/step)\n",
            "I0517 09:53:26.010439 139851376510848 learning.py:507] global step 7300: loss = 2.0836 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7301: loss = 1.7423 (0.555 sec/step)\n",
            "I0517 09:53:26.568428 139851376510848 learning.py:507] global step 7301: loss = 1.7423 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7302: loss = 1.7586 (0.536 sec/step)\n",
            "I0517 09:53:27.105743 139851376510848 learning.py:507] global step 7302: loss = 1.7586 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7303: loss = 1.6519 (0.536 sec/step)\n",
            "I0517 09:53:27.643187 139851376510848 learning.py:507] global step 7303: loss = 1.6519 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7304: loss = 1.9158 (0.569 sec/step)\n",
            "I0517 09:53:28.213823 139851376510848 learning.py:507] global step 7304: loss = 1.9158 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7305: loss = 2.5008 (0.569 sec/step)\n",
            "I0517 09:53:28.784294 139851376510848 learning.py:507] global step 7305: loss = 2.5008 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7306: loss = 2.2135 (0.540 sec/step)\n",
            "I0517 09:53:29.325684 139851376510848 learning.py:507] global step 7306: loss = 2.2135 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7307: loss = 2.6914 (0.556 sec/step)\n",
            "I0517 09:53:29.884248 139851376510848 learning.py:507] global step 7307: loss = 2.6914 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7308: loss = 2.1420 (0.536 sec/step)\n",
            "I0517 09:53:30.421947 139851376510848 learning.py:507] global step 7308: loss = 2.1420 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7309: loss = 2.6366 (0.545 sec/step)\n",
            "I0517 09:53:30.969119 139851376510848 learning.py:507] global step 7309: loss = 2.6366 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7310: loss = 1.8197 (0.548 sec/step)\n",
            "I0517 09:53:31.518845 139851376510848 learning.py:507] global step 7310: loss = 1.8197 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7311: loss = 2.3192 (0.553 sec/step)\n",
            "I0517 09:53:32.073947 139851376510848 learning.py:507] global step 7311: loss = 2.3192 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7312: loss = 1.8322 (0.567 sec/step)\n",
            "I0517 09:53:32.643065 139851376510848 learning.py:507] global step 7312: loss = 1.8322 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7313: loss = 1.8847 (0.556 sec/step)\n",
            "I0517 09:53:33.200829 139851376510848 learning.py:507] global step 7313: loss = 1.8847 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7314: loss = 1.5338 (0.564 sec/step)\n",
            "I0517 09:53:33.771150 139851376510848 learning.py:507] global step 7314: loss = 1.5338 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7315: loss = 1.7804 (0.536 sec/step)\n",
            "I0517 09:53:34.309299 139851376510848 learning.py:507] global step 7315: loss = 1.7804 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7316: loss = 1.4946 (0.526 sec/step)\n",
            "I0517 09:53:34.837411 139851376510848 learning.py:507] global step 7316: loss = 1.4946 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7317: loss = 2.4824 (0.549 sec/step)\n",
            "I0517 09:53:35.388581 139851376510848 learning.py:507] global step 7317: loss = 2.4824 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7318: loss = 1.5196 (0.551 sec/step)\n",
            "I0517 09:53:35.941309 139851376510848 learning.py:507] global step 7318: loss = 1.5196 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7319: loss = 1.9547 (0.556 sec/step)\n",
            "I0517 09:53:36.499055 139851376510848 learning.py:507] global step 7319: loss = 1.9547 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7320: loss = 3.0776 (0.529 sec/step)\n",
            "I0517 09:53:37.029884 139851376510848 learning.py:507] global step 7320: loss = 3.0776 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7321: loss = 2.8753 (0.547 sec/step)\n",
            "I0517 09:53:37.578353 139851376510848 learning.py:507] global step 7321: loss = 2.8753 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7322: loss = 2.0067 (0.534 sec/step)\n",
            "I0517 09:53:38.114298 139851376510848 learning.py:507] global step 7322: loss = 2.0067 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7323: loss = 1.9867 (0.567 sec/step)\n",
            "I0517 09:53:38.682871 139851376510848 learning.py:507] global step 7323: loss = 1.9867 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7324: loss = 2.6199 (0.561 sec/step)\n",
            "I0517 09:53:39.246241 139851376510848 learning.py:507] global step 7324: loss = 2.6199 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7325: loss = 1.2454 (0.548 sec/step)\n",
            "I0517 09:53:39.795702 139851376510848 learning.py:507] global step 7325: loss = 1.2454 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7326: loss = 2.1112 (0.517 sec/step)\n",
            "I0517 09:53:40.314070 139851376510848 learning.py:507] global step 7326: loss = 2.1112 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 7327: loss = 1.6943 (0.568 sec/step)\n",
            "I0517 09:53:40.884181 139851376510848 learning.py:507] global step 7327: loss = 1.6943 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7328: loss = 2.3905 (0.554 sec/step)\n",
            "I0517 09:53:41.441670 139851376510848 learning.py:507] global step 7328: loss = 2.3905 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7329: loss = 3.3209 (0.584 sec/step)\n",
            "I0517 09:53:42.028501 139851376510848 learning.py:507] global step 7329: loss = 3.3209 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 7330: loss = 1.8152 (0.563 sec/step)\n",
            "I0517 09:53:42.593600 139851376510848 learning.py:507] global step 7330: loss = 1.8152 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7331: loss = 2.2283 (0.594 sec/step)\n",
            "I0517 09:53:43.189279 139851376510848 learning.py:507] global step 7331: loss = 2.2283 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 7332: loss = 3.0070 (0.547 sec/step)\n",
            "I0517 09:53:43.738211 139851376510848 learning.py:507] global step 7332: loss = 3.0070 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7333: loss = 2.2066 (0.562 sec/step)\n",
            "I0517 09:53:44.301726 139851376510848 learning.py:507] global step 7333: loss = 2.2066 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7334: loss = 2.0831 (0.539 sec/step)\n",
            "I0517 09:53:44.842992 139851376510848 learning.py:507] global step 7334: loss = 2.0831 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7335: loss = 2.3155 (0.527 sec/step)\n",
            "I0517 09:53:45.371504 139851376510848 learning.py:507] global step 7335: loss = 2.3155 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7336: loss = 1.8509 (0.555 sec/step)\n",
            "I0517 09:53:45.928345 139851376510848 learning.py:507] global step 7336: loss = 1.8509 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7337: loss = 1.9580 (0.564 sec/step)\n",
            "I0517 09:53:46.493642 139851376510848 learning.py:507] global step 7337: loss = 1.9580 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7338: loss = 1.4473 (0.566 sec/step)\n",
            "I0517 09:53:47.061422 139851376510848 learning.py:507] global step 7338: loss = 1.4473 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7339: loss = 1.6159 (0.546 sec/step)\n",
            "I0517 09:53:47.611350 139851376510848 learning.py:507] global step 7339: loss = 1.6159 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7340: loss = 3.5258 (0.572 sec/step)\n",
            "I0517 09:53:48.184773 139851376510848 learning.py:507] global step 7340: loss = 3.5258 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7341: loss = 2.4492 (0.553 sec/step)\n",
            "I0517 09:53:48.739043 139851376510848 learning.py:507] global step 7341: loss = 2.4492 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7342: loss = 1.5771 (0.537 sec/step)\n",
            "I0517 09:53:49.277631 139851376510848 learning.py:507] global step 7342: loss = 1.5771 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7343: loss = 1.6275 (0.559 sec/step)\n",
            "I0517 09:53:49.838006 139851376510848 learning.py:507] global step 7343: loss = 1.6275 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7344: loss = 2.2755 (0.516 sec/step)\n",
            "I0517 09:53:50.356202 139851376510848 learning.py:507] global step 7344: loss = 2.2755 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7345: loss = 2.1933 (0.530 sec/step)\n",
            "I0517 09:53:50.887811 139851376510848 learning.py:507] global step 7345: loss = 2.1933 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7346: loss = 1.9076 (0.538 sec/step)\n",
            "I0517 09:53:51.427407 139851376510848 learning.py:507] global step 7346: loss = 1.9076 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7347: loss = 2.4932 (0.532 sec/step)\n",
            "I0517 09:53:51.961676 139851376510848 learning.py:507] global step 7347: loss = 2.4932 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7348: loss = 2.2349 (0.528 sec/step)\n",
            "I0517 09:53:52.491724 139851376510848 learning.py:507] global step 7348: loss = 2.2349 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7349: loss = 1.5084 (0.560 sec/step)\n",
            "I0517 09:53:53.053903 139851376510848 learning.py:507] global step 7349: loss = 1.5084 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7350: loss = 1.7981 (0.523 sec/step)\n",
            "I0517 09:53:53.578819 139851376510848 learning.py:507] global step 7350: loss = 1.7981 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7351: loss = 1.8977 (0.551 sec/step)\n",
            "I0517 09:53:54.132114 139851376510848 learning.py:507] global step 7351: loss = 1.8977 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7352: loss = 2.0675 (0.524 sec/step)\n",
            "I0517 09:53:54.658199 139851376510848 learning.py:507] global step 7352: loss = 2.0675 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7353: loss = 1.9371 (0.561 sec/step)\n",
            "I0517 09:53:55.221522 139851376510848 learning.py:507] global step 7353: loss = 1.9371 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7354: loss = 1.9114 (0.530 sec/step)\n",
            "I0517 09:53:55.753025 139851376510848 learning.py:507] global step 7354: loss = 1.9114 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7355: loss = 1.5802 (0.538 sec/step)\n",
            "I0517 09:53:56.292583 139851376510848 learning.py:507] global step 7355: loss = 1.5802 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7356: loss = 1.8441 (0.572 sec/step)\n",
            "I0517 09:53:56.867777 139851376510848 learning.py:507] global step 7356: loss = 1.8441 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7357: loss = 1.7834 (0.546 sec/step)\n",
            "I0517 09:53:57.418241 139851376510848 learning.py:507] global step 7357: loss = 1.7834 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7358: loss = 1.8112 (0.544 sec/step)\n",
            "I0517 09:53:57.964115 139851376510848 learning.py:507] global step 7358: loss = 1.8112 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7359: loss = 1.5274 (0.556 sec/step)\n",
            "I0517 09:53:58.522217 139851376510848 learning.py:507] global step 7359: loss = 1.5274 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7360: loss = 1.5695 (0.566 sec/step)\n",
            "I0517 09:53:59.089653 139851376510848 learning.py:507] global step 7360: loss = 1.5695 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7361: loss = 2.5076 (0.539 sec/step)\n",
            "I0517 09:53:59.631252 139851376510848 learning.py:507] global step 7361: loss = 2.5076 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7362: loss = 1.3848 (0.548 sec/step)\n",
            "I0517 09:54:00.181312 139851376510848 learning.py:507] global step 7362: loss = 1.3848 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7363: loss = 2.6770 (0.552 sec/step)\n",
            "I0517 09:54:00.735348 139851376510848 learning.py:507] global step 7363: loss = 2.6770 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7364: loss = 2.6543 (0.557 sec/step)\n",
            "I0517 09:54:01.294123 139851376510848 learning.py:507] global step 7364: loss = 2.6543 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7365: loss = 1.4675 (0.545 sec/step)\n",
            "I0517 09:54:01.840754 139851376510848 learning.py:507] global step 7365: loss = 1.4675 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7366: loss = 2.0116 (0.551 sec/step)\n",
            "I0517 09:54:02.394272 139851376510848 learning.py:507] global step 7366: loss = 2.0116 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7367: loss = 2.0186 (0.524 sec/step)\n",
            "I0517 09:54:02.919576 139851376510848 learning.py:507] global step 7367: loss = 2.0186 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7368: loss = 2.1546 (0.537 sec/step)\n",
            "I0517 09:54:03.457869 139851376510848 learning.py:507] global step 7368: loss = 2.1546 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7369: loss = 1.9907 (0.525 sec/step)\n",
            "I0517 09:54:03.985302 139851376510848 learning.py:507] global step 7369: loss = 1.9907 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7370: loss = 1.6751 (0.563 sec/step)\n",
            "I0517 09:54:04.549634 139851376510848 learning.py:507] global step 7370: loss = 1.6751 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7371: loss = 2.0854 (0.535 sec/step)\n",
            "I0517 09:54:05.087418 139851376510848 learning.py:507] global step 7371: loss = 2.0854 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7372: loss = 1.7799 (0.525 sec/step)\n",
            "I0517 09:54:05.617588 139851376510848 learning.py:507] global step 7372: loss = 1.7799 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7373: loss = 2.1854 (0.526 sec/step)\n",
            "I0517 09:54:06.145324 139851376510848 learning.py:507] global step 7373: loss = 2.1854 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7374: loss = 2.1259 (0.535 sec/step)\n",
            "I0517 09:54:06.681756 139851376510848 learning.py:507] global step 7374: loss = 2.1259 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7375: loss = 1.6248 (0.537 sec/step)\n",
            "I0517 09:54:07.220746 139851376510848 learning.py:507] global step 7375: loss = 1.6248 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7376: loss = 1.6494 (0.522 sec/step)\n",
            "I0517 09:54:07.744265 139851376510848 learning.py:507] global step 7376: loss = 1.6494 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7377: loss = 1.8656 (0.557 sec/step)\n",
            "I0517 09:54:08.303639 139851376510848 learning.py:507] global step 7377: loss = 1.8656 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7378: loss = 2.2812 (0.562 sec/step)\n",
            "I0517 09:54:08.867081 139851376510848 learning.py:507] global step 7378: loss = 2.2812 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7379: loss = 1.9307 (0.555 sec/step)\n",
            "I0517 09:54:09.424177 139851376510848 learning.py:507] global step 7379: loss = 1.9307 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7380: loss = 1.5725 (0.525 sec/step)\n",
            "I0517 09:54:09.951563 139851376510848 learning.py:507] global step 7380: loss = 1.5725 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7381: loss = 1.8256 (0.565 sec/step)\n",
            "I0517 09:54:10.518379 139851376510848 learning.py:507] global step 7381: loss = 1.8256 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7382: loss = 1.7690 (0.538 sec/step)\n",
            "I0517 09:54:11.058144 139851376510848 learning.py:507] global step 7382: loss = 1.7690 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7383: loss = 2.0240 (0.568 sec/step)\n",
            "I0517 09:54:11.627634 139851376510848 learning.py:507] global step 7383: loss = 2.0240 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7384: loss = 1.7215 (0.540 sec/step)\n",
            "I0517 09:54:12.170403 139851376510848 learning.py:507] global step 7384: loss = 1.7215 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7385: loss = 1.7443 (0.558 sec/step)\n",
            "I0517 09:54:12.730115 139851376510848 learning.py:507] global step 7385: loss = 1.7443 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7386: loss = 1.5253 (0.545 sec/step)\n",
            "I0517 09:54:13.277420 139851376510848 learning.py:507] global step 7386: loss = 1.5253 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7387: loss = 1.4504 (0.562 sec/step)\n",
            "I0517 09:54:13.840976 139851376510848 learning.py:507] global step 7387: loss = 1.4504 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7388: loss = 1.9193 (0.558 sec/step)\n",
            "I0517 09:54:14.401840 139851376510848 learning.py:507] global step 7388: loss = 1.9193 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7389: loss = 1.6343 (0.561 sec/step)\n",
            "I0517 09:54:14.965444 139851376510848 learning.py:507] global step 7389: loss = 1.6343 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7390: loss = 1.7941 (0.599 sec/step)\n",
            "I0517 09:54:15.566826 139851376510848 learning.py:507] global step 7390: loss = 1.7941 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 7391: loss = 1.9709 (0.547 sec/step)\n",
            "I0517 09:54:16.116013 139851376510848 learning.py:507] global step 7391: loss = 1.9709 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7392: loss = 1.8995 (0.544 sec/step)\n",
            "I0517 09:54:16.662616 139851376510848 learning.py:507] global step 7392: loss = 1.8995 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7393: loss = 1.8685 (0.525 sec/step)\n",
            "I0517 09:54:17.189898 139851376510848 learning.py:507] global step 7393: loss = 1.8685 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7394: loss = 1.8268 (0.560 sec/step)\n",
            "I0517 09:54:17.751813 139851376510848 learning.py:507] global step 7394: loss = 1.8268 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7395: loss = 1.7488 (0.523 sec/step)\n",
            "I0517 09:54:18.276367 139851376510848 learning.py:507] global step 7395: loss = 1.7488 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7396: loss = 1.8241 (0.556 sec/step)\n",
            "I0517 09:54:18.833747 139851376510848 learning.py:507] global step 7396: loss = 1.8241 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7397: loss = 1.8197 (0.534 sec/step)\n",
            "I0517 09:54:19.369617 139851376510848 learning.py:507] global step 7397: loss = 1.8197 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7398: loss = 3.1603 (0.544 sec/step)\n",
            "I0517 09:54:19.915116 139851376510848 learning.py:507] global step 7398: loss = 3.1603 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7399: loss = 1.8271 (0.518 sec/step)\n",
            "I0517 09:54:20.435424 139851376510848 learning.py:507] global step 7399: loss = 1.8271 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7400: loss = 1.8720 (0.556 sec/step)\n",
            "I0517 09:54:20.993547 139851376510848 learning.py:507] global step 7400: loss = 1.8720 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7401: loss = 2.1050 (0.544 sec/step)\n",
            "I0517 09:54:21.539557 139851376510848 learning.py:507] global step 7401: loss = 2.1050 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7402: loss = 1.4740 (0.559 sec/step)\n",
            "I0517 09:54:22.100723 139851376510848 learning.py:507] global step 7402: loss = 1.4740 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7403: loss = 2.3425 (0.536 sec/step)\n",
            "I0517 09:54:22.638931 139851376510848 learning.py:507] global step 7403: loss = 2.3425 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7404: loss = 2.0605 (0.561 sec/step)\n",
            "I0517 09:54:23.202172 139851376510848 learning.py:507] global step 7404: loss = 2.0605 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7405: loss = 3.1437 (0.544 sec/step)\n",
            "I0517 09:54:23.748294 139851376510848 learning.py:507] global step 7405: loss = 3.1437 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7406: loss = 2.5481 (0.563 sec/step)\n",
            "I0517 09:54:24.314498 139851376510848 learning.py:507] global step 7406: loss = 2.5481 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7407: loss = 1.7210 (0.613 sec/step)\n",
            "I0517 09:54:24.928935 139851376510848 learning.py:507] global step 7407: loss = 1.7210 (0.613 sec/step)\n",
            "INFO:tensorflow:global step 7408: loss = 1.7094 (0.548 sec/step)\n",
            "I0517 09:54:25.478364 139851376510848 learning.py:507] global step 7408: loss = 1.7094 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7409: loss = 2.9405 (0.519 sec/step)\n",
            "I0517 09:54:25.999152 139851376510848 learning.py:507] global step 7409: loss = 2.9405 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7410: loss = 1.9130 (0.570 sec/step)\n",
            "I0517 09:54:26.570446 139851376510848 learning.py:507] global step 7410: loss = 1.9130 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7411: loss = 1.5085 (0.569 sec/step)\n",
            "I0517 09:54:27.141511 139851376510848 learning.py:507] global step 7411: loss = 1.5085 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7412: loss = 1.9547 (0.566 sec/step)\n",
            "I0517 09:54:27.709573 139851376510848 learning.py:507] global step 7412: loss = 1.9547 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7413: loss = 1.9779 (0.551 sec/step)\n",
            "I0517 09:54:28.262698 139851376510848 learning.py:507] global step 7413: loss = 1.9779 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7414: loss = 4.1780 (0.547 sec/step)\n",
            "I0517 09:54:28.811218 139851376510848 learning.py:507] global step 7414: loss = 4.1780 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7415: loss = 1.7866 (0.530 sec/step)\n",
            "I0517 09:54:29.342749 139851376510848 learning.py:507] global step 7415: loss = 1.7866 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7416: loss = 2.3713 (0.538 sec/step)\n",
            "I0517 09:54:29.882619 139851376510848 learning.py:507] global step 7416: loss = 2.3713 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7417: loss = 1.9945 (0.530 sec/step)\n",
            "I0517 09:54:30.414286 139851376510848 learning.py:507] global step 7417: loss = 1.9945 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7418: loss = 1.3974 (0.542 sec/step)\n",
            "I0517 09:54:30.958442 139851376510848 learning.py:507] global step 7418: loss = 1.3974 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7419: loss = 2.3305 (0.540 sec/step)\n",
            "I0517 09:54:31.501718 139851376510848 learning.py:507] global step 7419: loss = 2.3305 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7420: loss = 2.2111 (0.548 sec/step)\n",
            "I0517 09:54:32.051447 139851376510848 learning.py:507] global step 7420: loss = 2.2111 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7421: loss = 1.7218 (0.541 sec/step)\n",
            "I0517 09:54:32.593932 139851376510848 learning.py:507] global step 7421: loss = 1.7218 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7422: loss = 2.3776 (0.557 sec/step)\n",
            "I0517 09:54:33.152767 139851376510848 learning.py:507] global step 7422: loss = 2.3776 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7423: loss = 2.4253 (0.535 sec/step)\n",
            "I0517 09:54:33.689103 139851376510848 learning.py:507] global step 7423: loss = 2.4253 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7424: loss = 1.9196 (0.525 sec/step)\n",
            "I0517 09:54:34.215845 139851376510848 learning.py:507] global step 7424: loss = 1.9196 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7425: loss = 1.7833 (0.524 sec/step)\n",
            "I0517 09:54:34.741499 139851376510848 learning.py:507] global step 7425: loss = 1.7833 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7426: loss = 1.8460 (0.578 sec/step)\n",
            "I0517 09:54:35.320737 139851376510848 learning.py:507] global step 7426: loss = 1.8460 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7427: loss = 2.2793 (0.531 sec/step)\n",
            "I0517 09:54:35.853010 139851376510848 learning.py:507] global step 7427: loss = 2.2793 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7428: loss = 2.4268 (0.568 sec/step)\n",
            "I0517 09:54:36.422437 139851376510848 learning.py:507] global step 7428: loss = 2.4268 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7429: loss = 1.6846 (0.548 sec/step)\n",
            "I0517 09:54:36.971754 139851376510848 learning.py:507] global step 7429: loss = 1.6846 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7430: loss = 1.8528 (0.555 sec/step)\n",
            "I0517 09:54:37.528392 139851376510848 learning.py:507] global step 7430: loss = 1.8528 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7431: loss = 2.2901 (0.532 sec/step)\n",
            "I0517 09:54:38.063245 139851376510848 learning.py:507] global step 7431: loss = 2.2901 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7432: loss = 3.2218 (0.541 sec/step)\n",
            "I0517 09:54:38.606066 139851376510848 learning.py:507] global step 7432: loss = 3.2218 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7433: loss = 2.1538 (0.530 sec/step)\n",
            "I0517 09:54:39.137317 139851376510848 learning.py:507] global step 7433: loss = 2.1538 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7434: loss = 1.5944 (0.536 sec/step)\n",
            "I0517 09:54:39.674543 139851376510848 learning.py:507] global step 7434: loss = 1.5944 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7435: loss = 2.6312 (0.524 sec/step)\n",
            "I0517 09:54:40.200785 139851376510848 learning.py:507] global step 7435: loss = 2.6312 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7436: loss = 2.3911 (0.523 sec/step)\n",
            "I0517 09:54:40.726098 139851376510848 learning.py:507] global step 7436: loss = 2.3911 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7437: loss = 1.3965 (0.560 sec/step)\n",
            "I0517 09:54:41.288100 139851376510848 learning.py:507] global step 7437: loss = 1.3965 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7438: loss = 1.6504 (0.567 sec/step)\n",
            "I0517 09:54:41.857130 139851376510848 learning.py:507] global step 7438: loss = 1.6504 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7439: loss = 2.0913 (0.529 sec/step)\n",
            "I0517 09:54:42.387355 139851376510848 learning.py:507] global step 7439: loss = 2.0913 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7440: loss = 2.5799 (0.538 sec/step)\n",
            "I0517 09:54:42.927716 139851376510848 learning.py:507] global step 7440: loss = 2.5799 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7441: loss = 2.2583 (0.570 sec/step)\n",
            "I0517 09:54:43.499147 139851376510848 learning.py:507] global step 7441: loss = 2.2583 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7442: loss = 1.6032 (0.535 sec/step)\n",
            "I0517 09:54:44.035464 139851376510848 learning.py:507] global step 7442: loss = 1.6032 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7443: loss = 1.7616 (0.547 sec/step)\n",
            "I0517 09:54:44.583830 139851376510848 learning.py:507] global step 7443: loss = 1.7616 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7444: loss = 2.0563 (0.530 sec/step)\n",
            "I0517 09:54:45.115756 139851376510848 learning.py:507] global step 7444: loss = 2.0563 (0.530 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "I0517 09:54:45.556655 139847658321664 supervisor.py:1117] Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "INFO:tensorflow:global step 7445: loss = 1.6447 (1.122 sec/step)\n",
            "I0517 09:54:46.414455 139851376510848 learning.py:507] global step 7445: loss = 1.6447 (1.122 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7446.\n",
            "I0517 09:54:47.696800 139847641536256 supervisor.py:1050] Recording summary at step 7446.\n",
            "INFO:tensorflow:global step 7446: loss = 1.6242 (1.304 sec/step)\n",
            "I0517 09:54:47.738075 139851376510848 learning.py:507] global step 7446: loss = 1.6242 (1.304 sec/step)\n",
            "INFO:tensorflow:global step 7447: loss = 2.3937 (0.733 sec/step)\n",
            "I0517 09:54:48.494009 139851376510848 learning.py:507] global step 7447: loss = 2.3937 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 7448: loss = 1.6169 (0.928 sec/step)\n",
            "I0517 09:54:49.515370 139851376510848 learning.py:507] global step 7448: loss = 1.6169 (0.928 sec/step)\n",
            "INFO:tensorflow:global step 7449: loss = 1.5626 (0.546 sec/step)\n",
            "I0517 09:54:50.063707 139851376510848 learning.py:507] global step 7449: loss = 1.5626 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7450: loss = 1.1030 (0.547 sec/step)\n",
            "I0517 09:54:50.611997 139851376510848 learning.py:507] global step 7450: loss = 1.1030 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7451: loss = 3.0996 (0.575 sec/step)\n",
            "I0517 09:54:51.190060 139851376510848 learning.py:507] global step 7451: loss = 3.0996 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7452: loss = 2.5030 (0.556 sec/step)\n",
            "I0517 09:54:51.747960 139851376510848 learning.py:507] global step 7452: loss = 2.5030 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7453: loss = 1.6114 (0.556 sec/step)\n",
            "I0517 09:54:52.305814 139851376510848 learning.py:507] global step 7453: loss = 1.6114 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7454: loss = 2.0234 (0.551 sec/step)\n",
            "I0517 09:54:52.858864 139851376510848 learning.py:507] global step 7454: loss = 2.0234 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7455: loss = 2.3534 (0.524 sec/step)\n",
            "I0517 09:54:53.384293 139851376510848 learning.py:507] global step 7455: loss = 2.3534 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7456: loss = 1.7932 (0.546 sec/step)\n",
            "I0517 09:54:53.931825 139851376510848 learning.py:507] global step 7456: loss = 1.7932 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7457: loss = 1.7208 (0.531 sec/step)\n",
            "I0517 09:54:54.464998 139851376510848 learning.py:507] global step 7457: loss = 1.7208 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7458: loss = 2.0301 (0.578 sec/step)\n",
            "I0517 09:54:55.044939 139851376510848 learning.py:507] global step 7458: loss = 2.0301 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7459: loss = 1.4502 (0.549 sec/step)\n",
            "I0517 09:54:55.595247 139851376510848 learning.py:507] global step 7459: loss = 1.4502 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7460: loss = 1.4926 (0.576 sec/step)\n",
            "I0517 09:54:56.173218 139851376510848 learning.py:507] global step 7460: loss = 1.4926 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 7461: loss = 2.2753 (0.565 sec/step)\n",
            "I0517 09:54:56.740767 139851376510848 learning.py:507] global step 7461: loss = 2.2753 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7462: loss = 1.8578 (0.534 sec/step)\n",
            "I0517 09:54:57.277024 139851376510848 learning.py:507] global step 7462: loss = 1.8578 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7463: loss = 1.9272 (0.554 sec/step)\n",
            "I0517 09:54:57.832406 139851376510848 learning.py:507] global step 7463: loss = 1.9272 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7464: loss = 2.2474 (0.540 sec/step)\n",
            "I0517 09:54:58.374112 139851376510848 learning.py:507] global step 7464: loss = 2.2474 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7465: loss = 1.9677 (0.553 sec/step)\n",
            "I0517 09:54:58.929094 139851376510848 learning.py:507] global step 7465: loss = 1.9677 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7466: loss = 1.8874 (0.556 sec/step)\n",
            "I0517 09:54:59.486649 139851376510848 learning.py:507] global step 7466: loss = 1.8874 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7467: loss = 1.9347 (0.544 sec/step)\n",
            "I0517 09:55:00.032801 139851376510848 learning.py:507] global step 7467: loss = 1.9347 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7468: loss = 1.7134 (0.531 sec/step)\n",
            "I0517 09:55:00.566912 139851376510848 learning.py:507] global step 7468: loss = 1.7134 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7469: loss = 2.3438 (0.533 sec/step)\n",
            "I0517 09:55:01.101509 139851376510848 learning.py:507] global step 7469: loss = 2.3438 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7470: loss = 2.1830 (0.511 sec/step)\n",
            "I0517 09:55:01.614450 139851376510848 learning.py:507] global step 7470: loss = 2.1830 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 7471: loss = 1.5780 (0.539 sec/step)\n",
            "I0517 09:55:02.154623 139851376510848 learning.py:507] global step 7471: loss = 1.5780 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7472: loss = 2.0761 (0.522 sec/step)\n",
            "I0517 09:55:02.677916 139851376510848 learning.py:507] global step 7472: loss = 2.0761 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7473: loss = 1.8179 (0.553 sec/step)\n",
            "I0517 09:55:03.232352 139851376510848 learning.py:507] global step 7473: loss = 1.8179 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7474: loss = 1.6353 (0.554 sec/step)\n",
            "I0517 09:55:03.788148 139851376510848 learning.py:507] global step 7474: loss = 1.6353 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7475: loss = 1.8024 (0.550 sec/step)\n",
            "I0517 09:55:04.339359 139851376510848 learning.py:507] global step 7475: loss = 1.8024 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7476: loss = 1.9714 (0.527 sec/step)\n",
            "I0517 09:55:04.868595 139851376510848 learning.py:507] global step 7476: loss = 1.9714 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7477: loss = 1.9066 (0.556 sec/step)\n",
            "I0517 09:55:05.426705 139851376510848 learning.py:507] global step 7477: loss = 1.9066 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7478: loss = 1.5347 (0.538 sec/step)\n",
            "I0517 09:55:05.966647 139851376510848 learning.py:507] global step 7478: loss = 1.5347 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7479: loss = 1.6649 (0.556 sec/step)\n",
            "I0517 09:55:06.524801 139851376510848 learning.py:507] global step 7479: loss = 1.6649 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7480: loss = 1.6713 (0.552 sec/step)\n",
            "I0517 09:55:07.078639 139851376510848 learning.py:507] global step 7480: loss = 1.6713 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7481: loss = 1.7790 (0.534 sec/step)\n",
            "I0517 09:55:07.615566 139851376510848 learning.py:507] global step 7481: loss = 1.7790 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7482: loss = 1.7225 (0.563 sec/step)\n",
            "I0517 09:55:08.180617 139851376510848 learning.py:507] global step 7482: loss = 1.7225 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7483: loss = 1.7494 (0.525 sec/step)\n",
            "I0517 09:55:08.706965 139851376510848 learning.py:507] global step 7483: loss = 1.7494 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7484: loss = 1.9645 (0.546 sec/step)\n",
            "I0517 09:55:09.255018 139851376510848 learning.py:507] global step 7484: loss = 1.9645 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7485: loss = 1.7949 (0.561 sec/step)\n",
            "I0517 09:55:09.817632 139851376510848 learning.py:507] global step 7485: loss = 1.7949 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7486: loss = 1.8885 (0.566 sec/step)\n",
            "I0517 09:55:10.384920 139851376510848 learning.py:507] global step 7486: loss = 1.8885 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7487: loss = 1.7790 (0.531 sec/step)\n",
            "I0517 09:55:10.917665 139851376510848 learning.py:507] global step 7487: loss = 1.7790 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7488: loss = 2.4604 (0.576 sec/step)\n",
            "I0517 09:55:11.495372 139851376510848 learning.py:507] global step 7488: loss = 2.4604 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 7489: loss = 1.7114 (0.524 sec/step)\n",
            "I0517 09:55:12.021518 139851376510848 learning.py:507] global step 7489: loss = 1.7114 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7490: loss = 2.0442 (0.558 sec/step)\n",
            "I0517 09:55:12.580839 139851376510848 learning.py:507] global step 7490: loss = 2.0442 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7491: loss = 1.5464 (0.525 sec/step)\n",
            "I0517 09:55:13.108211 139851376510848 learning.py:507] global step 7491: loss = 1.5464 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7492: loss = 1.8027 (0.529 sec/step)\n",
            "I0517 09:55:13.639245 139851376510848 learning.py:507] global step 7492: loss = 1.8027 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7493: loss = 1.6254 (0.540 sec/step)\n",
            "I0517 09:55:14.181409 139851376510848 learning.py:507] global step 7493: loss = 1.6254 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7494: loss = 2.7072 (0.523 sec/step)\n",
            "I0517 09:55:14.706692 139851376510848 learning.py:507] global step 7494: loss = 2.7072 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7495: loss = 1.6985 (0.553 sec/step)\n",
            "I0517 09:55:15.261081 139851376510848 learning.py:507] global step 7495: loss = 1.6985 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7496: loss = 2.8400 (0.531 sec/step)\n",
            "I0517 09:55:15.793862 139851376510848 learning.py:507] global step 7496: loss = 2.8400 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7497: loss = 1.4628 (0.549 sec/step)\n",
            "I0517 09:55:16.344890 139851376510848 learning.py:507] global step 7497: loss = 1.4628 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7498: loss = 1.3134 (0.541 sec/step)\n",
            "I0517 09:55:16.888097 139851376510848 learning.py:507] global step 7498: loss = 1.3134 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7499: loss = 2.5648 (0.577 sec/step)\n",
            "I0517 09:55:17.467311 139851376510848 learning.py:507] global step 7499: loss = 2.5648 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 7500: loss = 2.1262 (0.525 sec/step)\n",
            "I0517 09:55:17.993688 139851376510848 learning.py:507] global step 7500: loss = 2.1262 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7501: loss = 1.8258 (0.545 sec/step)\n",
            "I0517 09:55:18.540004 139851376510848 learning.py:507] global step 7501: loss = 1.8258 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7502: loss = 2.1619 (0.525 sec/step)\n",
            "I0517 09:55:19.067571 139851376510848 learning.py:507] global step 7502: loss = 2.1619 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7503: loss = 1.9229 (0.533 sec/step)\n",
            "I0517 09:55:19.602406 139851376510848 learning.py:507] global step 7503: loss = 1.9229 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7504: loss = 1.9360 (0.533 sec/step)\n",
            "I0517 09:55:20.136960 139851376510848 learning.py:507] global step 7504: loss = 1.9360 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7505: loss = 1.6628 (0.588 sec/step)\n",
            "I0517 09:55:20.726590 139851376510848 learning.py:507] global step 7505: loss = 1.6628 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 7506: loss = 1.3895 (0.533 sec/step)\n",
            "I0517 09:55:21.261093 139851376510848 learning.py:507] global step 7506: loss = 1.3895 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7507: loss = 2.6749 (0.523 sec/step)\n",
            "I0517 09:55:21.785311 139851376510848 learning.py:507] global step 7507: loss = 2.6749 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7508: loss = 2.1225 (0.513 sec/step)\n",
            "I0517 09:55:22.300610 139851376510848 learning.py:507] global step 7508: loss = 2.1225 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 7509: loss = 1.9170 (0.530 sec/step)\n",
            "I0517 09:55:22.833275 139851376510848 learning.py:507] global step 7509: loss = 1.9170 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7510: loss = 1.4279 (0.530 sec/step)\n",
            "I0517 09:55:23.365409 139851376510848 learning.py:507] global step 7510: loss = 1.4279 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7511: loss = 2.0166 (0.531 sec/step)\n",
            "I0517 09:55:23.897716 139851376510848 learning.py:507] global step 7511: loss = 2.0166 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7512: loss = 1.6880 (0.532 sec/step)\n",
            "I0517 09:55:24.430934 139851376510848 learning.py:507] global step 7512: loss = 1.6880 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7513: loss = 1.4166 (0.525 sec/step)\n",
            "I0517 09:55:24.957590 139851376510848 learning.py:507] global step 7513: loss = 1.4166 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7514: loss = 1.7261 (0.558 sec/step)\n",
            "I0517 09:55:25.517603 139851376510848 learning.py:507] global step 7514: loss = 1.7261 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7515: loss = 1.8152 (0.535 sec/step)\n",
            "I0517 09:55:26.054629 139851376510848 learning.py:507] global step 7515: loss = 1.8152 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7516: loss = 2.5205 (0.547 sec/step)\n",
            "I0517 09:55:26.602951 139851376510848 learning.py:507] global step 7516: loss = 2.5205 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7517: loss = 1.4254 (0.546 sec/step)\n",
            "I0517 09:55:27.150217 139851376510848 learning.py:507] global step 7517: loss = 1.4254 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7518: loss = 1.7045 (0.576 sec/step)\n",
            "I0517 09:55:27.728269 139851376510848 learning.py:507] global step 7518: loss = 1.7045 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 7519: loss = 2.2008 (0.566 sec/step)\n",
            "I0517 09:55:28.295818 139851376510848 learning.py:507] global step 7519: loss = 2.2008 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7520: loss = 2.4055 (0.559 sec/step)\n",
            "I0517 09:55:28.856346 139851376510848 learning.py:507] global step 7520: loss = 2.4055 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7521: loss = 2.0129 (0.528 sec/step)\n",
            "I0517 09:55:29.385806 139851376510848 learning.py:507] global step 7521: loss = 2.0129 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7522: loss = 1.4526 (0.553 sec/step)\n",
            "I0517 09:55:29.940312 139851376510848 learning.py:507] global step 7522: loss = 1.4526 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7523: loss = 2.0180 (0.522 sec/step)\n",
            "I0517 09:55:30.464776 139851376510848 learning.py:507] global step 7523: loss = 2.0180 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7524: loss = 1.8323 (0.544 sec/step)\n",
            "I0517 09:55:31.010680 139851376510848 learning.py:507] global step 7524: loss = 1.8323 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7525: loss = 1.4425 (0.528 sec/step)\n",
            "I0517 09:55:31.540808 139851376510848 learning.py:507] global step 7525: loss = 1.4425 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7526: loss = 1.9217 (0.526 sec/step)\n",
            "I0517 09:55:32.068594 139851376510848 learning.py:507] global step 7526: loss = 1.9217 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7527: loss = 1.5827 (0.550 sec/step)\n",
            "I0517 09:55:32.620922 139851376510848 learning.py:507] global step 7527: loss = 1.5827 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7528: loss = 1.9296 (0.534 sec/step)\n",
            "I0517 09:55:33.156481 139851376510848 learning.py:507] global step 7528: loss = 1.9296 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7529: loss = 1.5745 (0.578 sec/step)\n",
            "I0517 09:55:33.736496 139851376510848 learning.py:507] global step 7529: loss = 1.5745 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7530: loss = 2.1077 (0.558 sec/step)\n",
            "I0517 09:55:34.296432 139851376510848 learning.py:507] global step 7530: loss = 2.1077 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7531: loss = 2.1005 (0.532 sec/step)\n",
            "I0517 09:55:34.829838 139851376510848 learning.py:507] global step 7531: loss = 2.1005 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7532: loss = 1.9240 (0.517 sec/step)\n",
            "I0517 09:55:35.349273 139851376510848 learning.py:507] global step 7532: loss = 1.9240 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 7533: loss = 2.0074 (0.542 sec/step)\n",
            "I0517 09:55:35.893430 139851376510848 learning.py:507] global step 7533: loss = 2.0074 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7534: loss = 1.6024 (0.547 sec/step)\n",
            "I0517 09:55:36.441754 139851376510848 learning.py:507] global step 7534: loss = 1.6024 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7535: loss = 1.9065 (0.534 sec/step)\n",
            "I0517 09:55:36.977744 139851376510848 learning.py:507] global step 7535: loss = 1.9065 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7536: loss = 2.2282 (0.566 sec/step)\n",
            "I0517 09:55:37.545144 139851376510848 learning.py:507] global step 7536: loss = 2.2282 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7537: loss = 1.7142 (0.556 sec/step)\n",
            "I0517 09:55:38.103230 139851376510848 learning.py:507] global step 7537: loss = 1.7142 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7538: loss = 1.6416 (0.569 sec/step)\n",
            "I0517 09:55:38.674363 139851376510848 learning.py:507] global step 7538: loss = 1.6416 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7539: loss = 1.4222 (0.570 sec/step)\n",
            "I0517 09:55:39.246515 139851376510848 learning.py:507] global step 7539: loss = 1.4222 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7540: loss = 3.5683 (0.563 sec/step)\n",
            "I0517 09:55:39.811476 139851376510848 learning.py:507] global step 7540: loss = 3.5683 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7541: loss = 2.4844 (0.550 sec/step)\n",
            "I0517 09:55:40.363648 139851376510848 learning.py:507] global step 7541: loss = 2.4844 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7542: loss = 1.3419 (0.539 sec/step)\n",
            "I0517 09:55:40.903840 139851376510848 learning.py:507] global step 7542: loss = 1.3419 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7543: loss = 2.0062 (0.534 sec/step)\n",
            "I0517 09:55:41.439564 139851376510848 learning.py:507] global step 7543: loss = 2.0062 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7544: loss = 2.0544 (0.562 sec/step)\n",
            "I0517 09:55:42.004358 139851376510848 learning.py:507] global step 7544: loss = 2.0544 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7545: loss = 1.7185 (0.536 sec/step)\n",
            "I0517 09:55:42.542267 139851376510848 learning.py:507] global step 7545: loss = 1.7185 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7546: loss = 2.1301 (0.548 sec/step)\n",
            "I0517 09:55:43.091532 139851376510848 learning.py:507] global step 7546: loss = 2.1301 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7547: loss = 2.5450 (0.569 sec/step)\n",
            "I0517 09:55:43.662381 139851376510848 learning.py:507] global step 7547: loss = 2.5450 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7548: loss = 1.8990 (0.561 sec/step)\n",
            "I0517 09:55:44.225188 139851376510848 learning.py:507] global step 7548: loss = 1.8990 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7549: loss = 2.3077 (0.525 sec/step)\n",
            "I0517 09:55:44.752331 139851376510848 learning.py:507] global step 7549: loss = 2.3077 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7550: loss = 2.4845 (0.544 sec/step)\n",
            "I0517 09:55:45.297812 139851376510848 learning.py:507] global step 7550: loss = 2.4845 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7551: loss = 1.8505 (0.539 sec/step)\n",
            "I0517 09:55:45.838906 139851376510848 learning.py:507] global step 7551: loss = 1.8505 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7552: loss = 1.6614 (0.524 sec/step)\n",
            "I0517 09:55:46.364428 139851376510848 learning.py:507] global step 7552: loss = 1.6614 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7553: loss = 2.5962 (0.560 sec/step)\n",
            "I0517 09:55:46.926304 139851376510848 learning.py:507] global step 7553: loss = 2.5962 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7554: loss = 2.0794 (0.575 sec/step)\n",
            "I0517 09:55:47.502622 139851376510848 learning.py:507] global step 7554: loss = 2.0794 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7555: loss = 1.3464 (0.578 sec/step)\n",
            "I0517 09:55:48.082371 139851376510848 learning.py:507] global step 7555: loss = 1.3464 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7556: loss = 2.6212 (0.529 sec/step)\n",
            "I0517 09:55:48.612884 139851376510848 learning.py:507] global step 7556: loss = 2.6212 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7557: loss = 1.6382 (0.545 sec/step)\n",
            "I0517 09:55:49.160601 139851376510848 learning.py:507] global step 7557: loss = 1.6382 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7558: loss = 2.3085 (0.557 sec/step)\n",
            "I0517 09:55:49.719285 139851376510848 learning.py:507] global step 7558: loss = 2.3085 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7559: loss = 1.3308 (0.548 sec/step)\n",
            "I0517 09:55:50.268740 139851376510848 learning.py:507] global step 7559: loss = 1.3308 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7560: loss = 3.4943 (0.516 sec/step)\n",
            "I0517 09:55:50.786535 139851376510848 learning.py:507] global step 7560: loss = 3.4943 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7561: loss = 1.8057 (0.525 sec/step)\n",
            "I0517 09:55:51.312891 139851376510848 learning.py:507] global step 7561: loss = 1.8057 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7562: loss = 2.2052 (0.531 sec/step)\n",
            "I0517 09:55:51.845972 139851376510848 learning.py:507] global step 7562: loss = 2.2052 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7563: loss = 1.6083 (0.530 sec/step)\n",
            "I0517 09:55:52.378024 139851376510848 learning.py:507] global step 7563: loss = 1.6083 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7564: loss = 1.3758 (0.516 sec/step)\n",
            "I0517 09:55:52.896300 139851376510848 learning.py:507] global step 7564: loss = 1.3758 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7565: loss = 1.4791 (0.540 sec/step)\n",
            "I0517 09:55:53.438235 139851376510848 learning.py:507] global step 7565: loss = 1.4791 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7566: loss = 2.3872 (0.547 sec/step)\n",
            "I0517 09:55:53.987417 139851376510848 learning.py:507] global step 7566: loss = 2.3872 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7567: loss = 2.0352 (0.539 sec/step)\n",
            "I0517 09:55:54.527822 139851376510848 learning.py:507] global step 7567: loss = 2.0352 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7568: loss = 1.7991 (0.527 sec/step)\n",
            "I0517 09:55:55.056742 139851376510848 learning.py:507] global step 7568: loss = 1.7991 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7569: loss = 1.8419 (0.558 sec/step)\n",
            "I0517 09:55:55.616225 139851376510848 learning.py:507] global step 7569: loss = 1.8419 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7570: loss = 1.9231 (0.542 sec/step)\n",
            "I0517 09:55:56.160096 139851376510848 learning.py:507] global step 7570: loss = 1.9231 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7571: loss = 2.7909 (0.555 sec/step)\n",
            "I0517 09:55:56.716757 139851376510848 learning.py:507] global step 7571: loss = 2.7909 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7572: loss = 1.9679 (0.571 sec/step)\n",
            "I0517 09:55:57.289514 139851376510848 learning.py:507] global step 7572: loss = 1.9679 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7573: loss = 2.0074 (0.529 sec/step)\n",
            "I0517 09:55:57.820063 139851376510848 learning.py:507] global step 7573: loss = 2.0074 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7574: loss = 1.6769 (0.571 sec/step)\n",
            "I0517 09:55:58.392886 139851376510848 learning.py:507] global step 7574: loss = 1.6769 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7575: loss = 1.8856 (0.539 sec/step)\n",
            "I0517 09:55:58.935212 139851376510848 learning.py:507] global step 7575: loss = 1.8856 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7576: loss = 2.1674 (0.538 sec/step)\n",
            "I0517 09:55:59.475470 139851376510848 learning.py:507] global step 7576: loss = 2.1674 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7577: loss = 1.9002 (0.550 sec/step)\n",
            "I0517 09:56:00.027238 139851376510848 learning.py:507] global step 7577: loss = 1.9002 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7578: loss = 1.6429 (0.585 sec/step)\n",
            "I0517 09:56:00.614105 139851376510848 learning.py:507] global step 7578: loss = 1.6429 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 7579: loss = 1.1410 (0.563 sec/step)\n",
            "I0517 09:56:01.178745 139851376510848 learning.py:507] global step 7579: loss = 1.1410 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7580: loss = 2.3535 (0.561 sec/step)\n",
            "I0517 09:56:01.741365 139851376510848 learning.py:507] global step 7580: loss = 2.3535 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7581: loss = 2.5854 (0.566 sec/step)\n",
            "I0517 09:56:02.309376 139851376510848 learning.py:507] global step 7581: loss = 2.5854 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7582: loss = 2.0418 (0.550 sec/step)\n",
            "I0517 09:56:02.860802 139851376510848 learning.py:507] global step 7582: loss = 2.0418 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7583: loss = 1.7232 (0.551 sec/step)\n",
            "I0517 09:56:03.416649 139851376510848 learning.py:507] global step 7583: loss = 1.7232 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7584: loss = 2.2844 (0.549 sec/step)\n",
            "I0517 09:56:03.967070 139851376510848 learning.py:507] global step 7584: loss = 2.2844 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7585: loss = 1.6800 (0.559 sec/step)\n",
            "I0517 09:56:04.527626 139851376510848 learning.py:507] global step 7585: loss = 1.6800 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7586: loss = 2.2461 (0.542 sec/step)\n",
            "I0517 09:56:05.071813 139851376510848 learning.py:507] global step 7586: loss = 2.2461 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7587: loss = 1.9005 (0.563 sec/step)\n",
            "I0517 09:56:05.636275 139851376510848 learning.py:507] global step 7587: loss = 1.9005 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7588: loss = 1.4942 (0.536 sec/step)\n",
            "I0517 09:56:06.174647 139851376510848 learning.py:507] global step 7588: loss = 1.4942 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7589: loss = 2.5766 (0.541 sec/step)\n",
            "I0517 09:56:06.717978 139851376510848 learning.py:507] global step 7589: loss = 2.5766 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7590: loss = 2.3946 (0.563 sec/step)\n",
            "I0517 09:56:07.283141 139851376510848 learning.py:507] global step 7590: loss = 2.3946 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7591: loss = 1.2599 (0.545 sec/step)\n",
            "I0517 09:56:07.830210 139851376510848 learning.py:507] global step 7591: loss = 1.2599 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7592: loss = 1.5267 (0.568 sec/step)\n",
            "I0517 09:56:08.399686 139851376510848 learning.py:507] global step 7592: loss = 1.5267 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7593: loss = 1.8179 (0.588 sec/step)\n",
            "I0517 09:56:08.989951 139851376510848 learning.py:507] global step 7593: loss = 1.8179 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 7594: loss = 1.8145 (0.537 sec/step)\n",
            "I0517 09:56:09.528258 139851376510848 learning.py:507] global step 7594: loss = 1.8145 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7595: loss = 1.6252 (0.542 sec/step)\n",
            "I0517 09:56:10.072557 139851376510848 learning.py:507] global step 7595: loss = 1.6252 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7596: loss = 1.4871 (0.556 sec/step)\n",
            "I0517 09:56:10.630159 139851376510848 learning.py:507] global step 7596: loss = 1.4871 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7597: loss = 2.8640 (0.535 sec/step)\n",
            "I0517 09:56:11.166990 139851376510848 learning.py:507] global step 7597: loss = 2.8640 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7598: loss = 1.9135 (0.516 sec/step)\n",
            "I0517 09:56:11.685199 139851376510848 learning.py:507] global step 7598: loss = 1.9135 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7599: loss = 2.4878 (0.562 sec/step)\n",
            "I0517 09:56:12.249364 139851376510848 learning.py:507] global step 7599: loss = 2.4878 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7600: loss = 1.3614 (0.575 sec/step)\n",
            "I0517 09:56:12.826915 139851376510848 learning.py:507] global step 7600: loss = 1.3614 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7601: loss = 1.7028 (0.548 sec/step)\n",
            "I0517 09:56:13.376944 139851376510848 learning.py:507] global step 7601: loss = 1.7028 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7602: loss = 1.9126 (0.572 sec/step)\n",
            "I0517 09:56:13.950464 139851376510848 learning.py:507] global step 7602: loss = 1.9126 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7603: loss = 2.1799 (0.553 sec/step)\n",
            "I0517 09:56:14.504922 139851376510848 learning.py:507] global step 7603: loss = 2.1799 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7604: loss = 2.1354 (0.582 sec/step)\n",
            "I0517 09:56:15.088933 139851376510848 learning.py:507] global step 7604: loss = 2.1354 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 7605: loss = 1.5927 (0.557 sec/step)\n",
            "I0517 09:56:15.647237 139851376510848 learning.py:507] global step 7605: loss = 1.5927 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7606: loss = 2.0355 (0.538 sec/step)\n",
            "I0517 09:56:16.187008 139851376510848 learning.py:507] global step 7606: loss = 2.0355 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7607: loss = 1.8863 (0.528 sec/step)\n",
            "I0517 09:56:16.716621 139851376510848 learning.py:507] global step 7607: loss = 1.8863 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7608: loss = 1.5831 (0.546 sec/step)\n",
            "I0517 09:56:17.264941 139851376510848 learning.py:507] global step 7608: loss = 1.5831 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7609: loss = 2.0529 (0.543 sec/step)\n",
            "I0517 09:56:17.811975 139851376510848 learning.py:507] global step 7609: loss = 2.0529 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7610: loss = 2.0879 (0.537 sec/step)\n",
            "I0517 09:56:18.351762 139851376510848 learning.py:507] global step 7610: loss = 2.0879 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7611: loss = 2.3151 (0.531 sec/step)\n",
            "I0517 09:56:18.884344 139851376510848 learning.py:507] global step 7611: loss = 2.3151 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7612: loss = 1.8338 (0.520 sec/step)\n",
            "I0517 09:56:19.405780 139851376510848 learning.py:507] global step 7612: loss = 1.8338 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 7613: loss = 1.7458 (0.518 sec/step)\n",
            "I0517 09:56:19.926024 139851376510848 learning.py:507] global step 7613: loss = 1.7458 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7614: loss = 1.9182 (0.538 sec/step)\n",
            "I0517 09:56:20.466235 139851376510848 learning.py:507] global step 7614: loss = 1.9182 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7615: loss = 1.5523 (0.563 sec/step)\n",
            "I0517 09:56:21.031528 139851376510848 learning.py:507] global step 7615: loss = 1.5523 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7616: loss = 1.5014 (0.573 sec/step)\n",
            "I0517 09:56:21.605963 139851376510848 learning.py:507] global step 7616: loss = 1.5014 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 7617: loss = 1.6269 (0.533 sec/step)\n",
            "I0517 09:56:22.140453 139851376510848 learning.py:507] global step 7617: loss = 1.6269 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7618: loss = 1.6017 (0.521 sec/step)\n",
            "I0517 09:56:22.663271 139851376510848 learning.py:507] global step 7618: loss = 1.6017 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7619: loss = 2.4136 (0.567 sec/step)\n",
            "I0517 09:56:23.231764 139851376510848 learning.py:507] global step 7619: loss = 2.4136 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7620: loss = 2.0770 (0.537 sec/step)\n",
            "I0517 09:56:23.770451 139851376510848 learning.py:507] global step 7620: loss = 2.0770 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7621: loss = 1.9347 (0.554 sec/step)\n",
            "I0517 09:56:24.325865 139851376510848 learning.py:507] global step 7621: loss = 1.9347 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7622: loss = 2.5402 (0.548 sec/step)\n",
            "I0517 09:56:24.875976 139851376510848 learning.py:507] global step 7622: loss = 2.5402 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7623: loss = 1.7350 (0.538 sec/step)\n",
            "I0517 09:56:25.415970 139851376510848 learning.py:507] global step 7623: loss = 1.7350 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7624: loss = 2.7430 (0.519 sec/step)\n",
            "I0517 09:56:25.936983 139851376510848 learning.py:507] global step 7624: loss = 2.7430 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7625: loss = 1.9258 (0.524 sec/step)\n",
            "I0517 09:56:26.463166 139851376510848 learning.py:507] global step 7625: loss = 1.9258 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7626: loss = 1.6854 (0.518 sec/step)\n",
            "I0517 09:56:26.983330 139851376510848 learning.py:507] global step 7626: loss = 1.6854 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7627: loss = 1.3874 (0.564 sec/step)\n",
            "I0517 09:56:27.549260 139851376510848 learning.py:507] global step 7627: loss = 1.3874 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7628: loss = 1.6260 (0.558 sec/step)\n",
            "I0517 09:56:28.109025 139851376510848 learning.py:507] global step 7628: loss = 1.6260 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7629: loss = 2.4993 (0.546 sec/step)\n",
            "I0517 09:56:28.656344 139851376510848 learning.py:507] global step 7629: loss = 2.4993 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7630: loss = 1.7701 (0.529 sec/step)\n",
            "I0517 09:56:29.187399 139851376510848 learning.py:507] global step 7630: loss = 1.7701 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7631: loss = 2.1509 (0.527 sec/step)\n",
            "I0517 09:56:29.716293 139851376510848 learning.py:507] global step 7631: loss = 2.1509 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7632: loss = 3.2705 (0.533 sec/step)\n",
            "I0517 09:56:30.252262 139851376510848 learning.py:507] global step 7632: loss = 3.2705 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7633: loss = 2.1013 (0.567 sec/step)\n",
            "I0517 09:56:30.821475 139851376510848 learning.py:507] global step 7633: loss = 2.1013 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7634: loss = 2.5700 (0.542 sec/step)\n",
            "I0517 09:56:31.365399 139851376510848 learning.py:507] global step 7634: loss = 2.5700 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7635: loss = 1.3936 (0.557 sec/step)\n",
            "I0517 09:56:31.924012 139851376510848 learning.py:507] global step 7635: loss = 1.3936 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7636: loss = 1.6303 (0.560 sec/step)\n",
            "I0517 09:56:32.485777 139851376510848 learning.py:507] global step 7636: loss = 1.6303 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7637: loss = 3.5210 (0.513 sec/step)\n",
            "I0517 09:56:33.001022 139851376510848 learning.py:507] global step 7637: loss = 3.5210 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 7638: loss = 2.2873 (0.556 sec/step)\n",
            "I0517 09:56:33.558924 139851376510848 learning.py:507] global step 7638: loss = 2.2873 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7639: loss = 1.5957 (0.515 sec/step)\n",
            "I0517 09:56:34.075948 139851376510848 learning.py:507] global step 7639: loss = 1.5957 (0.515 sec/step)\n",
            "INFO:tensorflow:global step 7640: loss = 1.9225 (0.554 sec/step)\n",
            "I0517 09:56:34.631816 139851376510848 learning.py:507] global step 7640: loss = 1.9225 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7641: loss = 1.8310 (0.533 sec/step)\n",
            "I0517 09:56:35.166086 139851376510848 learning.py:507] global step 7641: loss = 1.8310 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7642: loss = 2.3962 (0.541 sec/step)\n",
            "I0517 09:56:35.708529 139851376510848 learning.py:507] global step 7642: loss = 2.3962 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7643: loss = 1.7143 (0.524 sec/step)\n",
            "I0517 09:56:36.234168 139851376510848 learning.py:507] global step 7643: loss = 1.7143 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7644: loss = 2.4320 (0.557 sec/step)\n",
            "I0517 09:56:36.793500 139851376510848 learning.py:507] global step 7644: loss = 2.4320 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7645: loss = 2.0221 (0.566 sec/step)\n",
            "I0517 09:56:37.362274 139851376510848 learning.py:507] global step 7645: loss = 2.0221 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7646: loss = 2.2393 (0.582 sec/step)\n",
            "I0517 09:56:37.945989 139851376510848 learning.py:507] global step 7646: loss = 2.2393 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 7647: loss = 2.3482 (0.525 sec/step)\n",
            "I0517 09:56:38.472747 139851376510848 learning.py:507] global step 7647: loss = 2.3482 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7648: loss = 1.6788 (0.532 sec/step)\n",
            "I0517 09:56:39.006667 139851376510848 learning.py:507] global step 7648: loss = 1.6788 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7649: loss = 1.3963 (0.560 sec/step)\n",
            "I0517 09:56:39.568564 139851376510848 learning.py:507] global step 7649: loss = 1.3963 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7650: loss = 2.5573 (0.548 sec/step)\n",
            "I0517 09:56:40.118368 139851376510848 learning.py:507] global step 7650: loss = 2.5573 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7651: loss = 2.1147 (0.545 sec/step)\n",
            "I0517 09:56:40.665526 139851376510848 learning.py:507] global step 7651: loss = 2.1147 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7652: loss = 2.0977 (0.543 sec/step)\n",
            "I0517 09:56:41.211456 139851376510848 learning.py:507] global step 7652: loss = 2.0977 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7653: loss = 2.0906 (0.551 sec/step)\n",
            "I0517 09:56:41.763770 139851376510848 learning.py:507] global step 7653: loss = 2.0906 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7654: loss = 2.4927 (0.525 sec/step)\n",
            "I0517 09:56:42.290883 139851376510848 learning.py:507] global step 7654: loss = 2.4927 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7655: loss = 2.7383 (0.562 sec/step)\n",
            "I0517 09:56:42.854686 139851376510848 learning.py:507] global step 7655: loss = 2.7383 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7656: loss = 1.9969 (0.554 sec/step)\n",
            "I0517 09:56:43.411378 139851376510848 learning.py:507] global step 7656: loss = 1.9969 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7657: loss = 2.3392 (0.543 sec/step)\n",
            "I0517 09:56:43.956422 139851376510848 learning.py:507] global step 7657: loss = 2.3392 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7658: loss = 1.6539 (0.528 sec/step)\n",
            "I0517 09:56:44.486299 139851376510848 learning.py:507] global step 7658: loss = 1.6539 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7659: loss = 1.7590 (0.547 sec/step)\n",
            "I0517 09:56:45.034793 139851376510848 learning.py:507] global step 7659: loss = 1.7590 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7660: loss = 2.0788 (0.553 sec/step)\n",
            "I0517 09:56:45.743073 139851376510848 learning.py:507] global step 7660: loss = 2.0788 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7661: loss = 2.0884 (0.945 sec/step)\n",
            "I0517 09:56:46.871105 139851376510848 learning.py:507] global step 7661: loss = 2.0884 (0.945 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7661.\n",
            "I0517 09:56:46.992483 139847641536256 supervisor.py:1050] Recording summary at step 7661.\n",
            "INFO:tensorflow:global step 7662: loss = 2.4185 (0.571 sec/step)\n",
            "I0517 09:56:47.444288 139851376510848 learning.py:507] global step 7662: loss = 2.4185 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7663: loss = 1.7041 (0.558 sec/step)\n",
            "I0517 09:56:48.004013 139851376510848 learning.py:507] global step 7663: loss = 1.7041 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7664: loss = 2.7153 (0.537 sec/step)\n",
            "I0517 09:56:48.542995 139851376510848 learning.py:507] global step 7664: loss = 2.7153 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7665: loss = 3.2803 (0.534 sec/step)\n",
            "I0517 09:56:49.079733 139851376510848 learning.py:507] global step 7665: loss = 3.2803 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7666: loss = 2.5863 (0.526 sec/step)\n",
            "I0517 09:56:49.607380 139851376510848 learning.py:507] global step 7666: loss = 2.5863 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7667: loss = 1.7701 (0.537 sec/step)\n",
            "I0517 09:56:50.146340 139851376510848 learning.py:507] global step 7667: loss = 1.7701 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7668: loss = 1.9114 (0.546 sec/step)\n",
            "I0517 09:56:50.693660 139851376510848 learning.py:507] global step 7668: loss = 1.9114 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7669: loss = 2.2907 (0.534 sec/step)\n",
            "I0517 09:56:51.229580 139851376510848 learning.py:507] global step 7669: loss = 2.2907 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7670: loss = 1.5804 (0.528 sec/step)\n",
            "I0517 09:56:51.759419 139851376510848 learning.py:507] global step 7670: loss = 1.5804 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7671: loss = 1.7093 (0.541 sec/step)\n",
            "I0517 09:56:52.302315 139851376510848 learning.py:507] global step 7671: loss = 1.7093 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7672: loss = 1.9684 (0.527 sec/step)\n",
            "I0517 09:56:52.832632 139851376510848 learning.py:507] global step 7672: loss = 1.9684 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7673: loss = 2.3275 (0.538 sec/step)\n",
            "I0517 09:56:53.372583 139851376510848 learning.py:507] global step 7673: loss = 2.3275 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7674: loss = 1.8763 (0.533 sec/step)\n",
            "I0517 09:56:53.907812 139851376510848 learning.py:507] global step 7674: loss = 1.8763 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7675: loss = 1.9608 (0.520 sec/step)\n",
            "I0517 09:56:54.429347 139851376510848 learning.py:507] global step 7675: loss = 1.9608 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 7676: loss = 1.8276 (0.525 sec/step)\n",
            "I0517 09:56:54.956605 139851376510848 learning.py:507] global step 7676: loss = 1.8276 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7677: loss = 2.2548 (0.542 sec/step)\n",
            "I0517 09:56:55.500568 139851376510848 learning.py:507] global step 7677: loss = 2.2548 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7678: loss = 1.9827 (0.529 sec/step)\n",
            "I0517 09:56:56.031702 139851376510848 learning.py:507] global step 7678: loss = 1.9827 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7679: loss = 1.6386 (0.539 sec/step)\n",
            "I0517 09:56:56.572537 139851376510848 learning.py:507] global step 7679: loss = 1.6386 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7680: loss = 1.9985 (0.583 sec/step)\n",
            "I0517 09:56:57.157642 139851376510848 learning.py:507] global step 7680: loss = 1.9985 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 7681: loss = 1.5551 (0.539 sec/step)\n",
            "I0517 09:56:57.698143 139851376510848 learning.py:507] global step 7681: loss = 1.5551 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7682: loss = 1.6905 (0.530 sec/step)\n",
            "I0517 09:56:58.229441 139851376510848 learning.py:507] global step 7682: loss = 1.6905 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7683: loss = 2.3350 (0.542 sec/step)\n",
            "I0517 09:56:58.773853 139851376510848 learning.py:507] global step 7683: loss = 2.3350 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7684: loss = 1.9788 (0.529 sec/step)\n",
            "I0517 09:56:59.304936 139851376510848 learning.py:507] global step 7684: loss = 1.9788 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7685: loss = 2.3113 (0.527 sec/step)\n",
            "I0517 09:56:59.833659 139851376510848 learning.py:507] global step 7685: loss = 2.3113 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7686: loss = 1.6601 (0.543 sec/step)\n",
            "I0517 09:57:00.379608 139851376510848 learning.py:507] global step 7686: loss = 1.6601 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7687: loss = 1.4272 (0.543 sec/step)\n",
            "I0517 09:57:00.924941 139851376510848 learning.py:507] global step 7687: loss = 1.4272 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7688: loss = 1.6295 (0.530 sec/step)\n",
            "I0517 09:57:01.457706 139851376510848 learning.py:507] global step 7688: loss = 1.6295 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7689: loss = 1.7357 (0.530 sec/step)\n",
            "I0517 09:57:01.988888 139851376510848 learning.py:507] global step 7689: loss = 1.7357 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7690: loss = 1.8537 (0.571 sec/step)\n",
            "I0517 09:57:02.561973 139851376510848 learning.py:507] global step 7690: loss = 1.8537 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7691: loss = 2.2448 (0.528 sec/step)\n",
            "I0517 09:57:03.091708 139851376510848 learning.py:507] global step 7691: loss = 2.2448 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7692: loss = 1.9317 (0.532 sec/step)\n",
            "I0517 09:57:03.625387 139851376510848 learning.py:507] global step 7692: loss = 1.9317 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7693: loss = 1.7493 (0.553 sec/step)\n",
            "I0517 09:57:04.180135 139851376510848 learning.py:507] global step 7693: loss = 1.7493 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7694: loss = 1.5267 (0.527 sec/step)\n",
            "I0517 09:57:04.709242 139851376510848 learning.py:507] global step 7694: loss = 1.5267 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7695: loss = 2.0867 (0.537 sec/step)\n",
            "I0517 09:57:05.247727 139851376510848 learning.py:507] global step 7695: loss = 2.0867 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7696: loss = 1.8418 (0.524 sec/step)\n",
            "I0517 09:57:05.773216 139851376510848 learning.py:507] global step 7696: loss = 1.8418 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7697: loss = 2.7133 (0.544 sec/step)\n",
            "I0517 09:57:06.319111 139851376510848 learning.py:507] global step 7697: loss = 2.7133 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7698: loss = 1.6778 (0.541 sec/step)\n",
            "I0517 09:57:06.861758 139851376510848 learning.py:507] global step 7698: loss = 1.6778 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7699: loss = 2.6255 (0.569 sec/step)\n",
            "I0517 09:57:07.432527 139851376510848 learning.py:507] global step 7699: loss = 2.6255 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 7700: loss = 2.3250 (0.532 sec/step)\n",
            "I0517 09:57:07.966131 139851376510848 learning.py:507] global step 7700: loss = 2.3250 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7701: loss = 1.5444 (0.567 sec/step)\n",
            "I0517 09:57:08.535146 139851376510848 learning.py:507] global step 7701: loss = 1.5444 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7702: loss = 1.6601 (0.557 sec/step)\n",
            "I0517 09:57:09.094430 139851376510848 learning.py:507] global step 7702: loss = 1.6601 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7703: loss = 2.1214 (0.553 sec/step)\n",
            "I0517 09:57:09.649316 139851376510848 learning.py:507] global step 7703: loss = 2.1214 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7704: loss = 2.5918 (0.549 sec/step)\n",
            "I0517 09:57:10.200910 139851376510848 learning.py:507] global step 7704: loss = 2.5918 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7705: loss = 1.8868 (0.574 sec/step)\n",
            "I0517 09:57:10.776962 139851376510848 learning.py:507] global step 7705: loss = 1.8868 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7706: loss = 1.8599 (0.565 sec/step)\n",
            "I0517 09:57:11.344123 139851376510848 learning.py:507] global step 7706: loss = 1.8599 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7707: loss = 1.4045 (0.530 sec/step)\n",
            "I0517 09:57:11.875283 139851376510848 learning.py:507] global step 7707: loss = 1.4045 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7708: loss = 2.3053 (0.544 sec/step)\n",
            "I0517 09:57:12.422416 139851376510848 learning.py:507] global step 7708: loss = 2.3053 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7709: loss = 1.6461 (0.552 sec/step)\n",
            "I0517 09:57:12.975889 139851376510848 learning.py:507] global step 7709: loss = 1.6461 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7710: loss = 2.2583 (0.575 sec/step)\n",
            "I0517 09:57:13.552298 139851376510848 learning.py:507] global step 7710: loss = 2.2583 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7711: loss = 3.0745 (0.577 sec/step)\n",
            "I0517 09:57:14.131644 139851376510848 learning.py:507] global step 7711: loss = 3.0745 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 7712: loss = 1.7624 (0.578 sec/step)\n",
            "I0517 09:57:14.711693 139851376510848 learning.py:507] global step 7712: loss = 1.7624 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7713: loss = 1.7133 (0.557 sec/step)\n",
            "I0517 09:57:15.270873 139851376510848 learning.py:507] global step 7713: loss = 1.7133 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7714: loss = 2.1050 (0.581 sec/step)\n",
            "I0517 09:57:15.853282 139851376510848 learning.py:507] global step 7714: loss = 2.1050 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 7715: loss = 2.8477 (0.593 sec/step)\n",
            "I0517 09:57:16.448087 139851376510848 learning.py:507] global step 7715: loss = 2.8477 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 7716: loss = 2.6165 (0.542 sec/step)\n",
            "I0517 09:57:16.991803 139851376510848 learning.py:507] global step 7716: loss = 2.6165 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7717: loss = 2.1770 (0.545 sec/step)\n",
            "I0517 09:57:17.538436 139851376510848 learning.py:507] global step 7717: loss = 2.1770 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7718: loss = 1.7430 (0.548 sec/step)\n",
            "I0517 09:57:18.088761 139851376510848 learning.py:507] global step 7718: loss = 1.7430 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7719: loss = 1.4945 (0.556 sec/step)\n",
            "I0517 09:57:18.647200 139851376510848 learning.py:507] global step 7719: loss = 1.4945 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7720: loss = 1.4611 (0.548 sec/step)\n",
            "I0517 09:57:19.197069 139851376510848 learning.py:507] global step 7720: loss = 1.4611 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7721: loss = 1.8993 (0.554 sec/step)\n",
            "I0517 09:57:19.752665 139851376510848 learning.py:507] global step 7721: loss = 1.8993 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7722: loss = 2.1764 (0.533 sec/step)\n",
            "I0517 09:57:20.287168 139851376510848 learning.py:507] global step 7722: loss = 2.1764 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7723: loss = 1.8375 (0.551 sec/step)\n",
            "I0517 09:57:20.840204 139851376510848 learning.py:507] global step 7723: loss = 1.8375 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7724: loss = 2.1598 (0.540 sec/step)\n",
            "I0517 09:57:21.382190 139851376510848 learning.py:507] global step 7724: loss = 2.1598 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7725: loss = 2.2378 (0.531 sec/step)\n",
            "I0517 09:57:21.914809 139851376510848 learning.py:507] global step 7725: loss = 2.2378 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7726: loss = 1.8659 (0.518 sec/step)\n",
            "I0517 09:57:22.435280 139851376510848 learning.py:507] global step 7726: loss = 1.8659 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7727: loss = 2.0239 (0.529 sec/step)\n",
            "I0517 09:57:22.967224 139851376510848 learning.py:507] global step 7727: loss = 2.0239 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7728: loss = 3.3131 (0.556 sec/step)\n",
            "I0517 09:57:23.524389 139851376510848 learning.py:507] global step 7728: loss = 3.3131 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7729: loss = 1.7163 (0.534 sec/step)\n",
            "I0517 09:57:24.059765 139851376510848 learning.py:507] global step 7729: loss = 1.7163 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7730: loss = 1.9278 (0.531 sec/step)\n",
            "I0517 09:57:24.592487 139851376510848 learning.py:507] global step 7730: loss = 1.9278 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7731: loss = 2.1655 (0.522 sec/step)\n",
            "I0517 09:57:25.115935 139851376510848 learning.py:507] global step 7731: loss = 2.1655 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7732: loss = 3.2027 (0.552 sec/step)\n",
            "I0517 09:57:25.670770 139851376510848 learning.py:507] global step 7732: loss = 3.2027 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7733: loss = 1.6605 (0.541 sec/step)\n",
            "I0517 09:57:26.214204 139851376510848 learning.py:507] global step 7733: loss = 1.6605 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7734: loss = 2.0390 (0.531 sec/step)\n",
            "I0517 09:57:26.747124 139851376510848 learning.py:507] global step 7734: loss = 2.0390 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7735: loss = 1.6719 (0.529 sec/step)\n",
            "I0517 09:57:27.277579 139851376510848 learning.py:507] global step 7735: loss = 1.6719 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7736: loss = 1.8254 (0.563 sec/step)\n",
            "I0517 09:57:27.842193 139851376510848 learning.py:507] global step 7736: loss = 1.8254 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 7737: loss = 2.5575 (0.540 sec/step)\n",
            "I0517 09:57:28.383413 139851376510848 learning.py:507] global step 7737: loss = 2.5575 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7738: loss = 2.7129 (0.561 sec/step)\n",
            "I0517 09:57:28.946357 139851376510848 learning.py:507] global step 7738: loss = 2.7129 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7739: loss = 3.6101 (0.568 sec/step)\n",
            "I0517 09:57:29.516715 139851376510848 learning.py:507] global step 7739: loss = 3.6101 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7740: loss = 2.1999 (0.581 sec/step)\n",
            "I0517 09:57:30.100007 139851376510848 learning.py:507] global step 7740: loss = 2.1999 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 7741: loss = 1.8856 (0.542 sec/step)\n",
            "I0517 09:57:30.643937 139851376510848 learning.py:507] global step 7741: loss = 1.8856 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7742: loss = 1.8966 (0.548 sec/step)\n",
            "I0517 09:57:31.193758 139851376510848 learning.py:507] global step 7742: loss = 1.8966 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7743: loss = 2.1044 (0.532 sec/step)\n",
            "I0517 09:57:31.727849 139851376510848 learning.py:507] global step 7743: loss = 2.1044 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7744: loss = 2.1591 (0.573 sec/step)\n",
            "I0517 09:57:32.302275 139851376510848 learning.py:507] global step 7744: loss = 2.1591 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 7745: loss = 1.8421 (0.555 sec/step)\n",
            "I0517 09:57:32.859230 139851376510848 learning.py:507] global step 7745: loss = 1.8421 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7746: loss = 1.3912 (0.531 sec/step)\n",
            "I0517 09:57:33.392122 139851376510848 learning.py:507] global step 7746: loss = 1.3912 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7747: loss = 1.9999 (0.548 sec/step)\n",
            "I0517 09:57:33.941652 139851376510848 learning.py:507] global step 7747: loss = 1.9999 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7748: loss = 2.5813 (0.557 sec/step)\n",
            "I0517 09:57:34.501601 139851376510848 learning.py:507] global step 7748: loss = 2.5813 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7749: loss = 1.8293 (0.572 sec/step)\n",
            "I0517 09:57:35.075604 139851376510848 learning.py:507] global step 7749: loss = 1.8293 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7750: loss = 1.3935 (0.560 sec/step)\n",
            "I0517 09:57:35.637290 139851376510848 learning.py:507] global step 7750: loss = 1.3935 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7751: loss = 2.5536 (0.567 sec/step)\n",
            "I0517 09:57:36.205886 139851376510848 learning.py:507] global step 7751: loss = 2.5536 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7752: loss = 1.7234 (0.556 sec/step)\n",
            "I0517 09:57:36.764360 139851376510848 learning.py:507] global step 7752: loss = 1.7234 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7753: loss = 2.0978 (0.566 sec/step)\n",
            "I0517 09:57:37.332056 139851376510848 learning.py:507] global step 7753: loss = 2.0978 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7754: loss = 1.6674 (0.570 sec/step)\n",
            "I0517 09:57:37.904053 139851376510848 learning.py:507] global step 7754: loss = 1.6674 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 7755: loss = 2.2139 (0.537 sec/step)\n",
            "I0517 09:57:38.442353 139851376510848 learning.py:507] global step 7755: loss = 2.2139 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7756: loss = 2.1371 (0.537 sec/step)\n",
            "I0517 09:57:38.980963 139851376510848 learning.py:507] global step 7756: loss = 2.1371 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7757: loss = 2.3673 (0.532 sec/step)\n",
            "I0517 09:57:39.514806 139851376510848 learning.py:507] global step 7757: loss = 2.3673 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7758: loss = 2.5160 (0.540 sec/step)\n",
            "I0517 09:57:40.056972 139851376510848 learning.py:507] global step 7758: loss = 2.5160 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7759: loss = 2.0463 (0.543 sec/step)\n",
            "I0517 09:57:40.602181 139851376510848 learning.py:507] global step 7759: loss = 2.0463 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7760: loss = 3.3731 (0.533 sec/step)\n",
            "I0517 09:57:41.136847 139851376510848 learning.py:507] global step 7760: loss = 3.3731 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7761: loss = 1.8932 (0.524 sec/step)\n",
            "I0517 09:57:41.662340 139851376510848 learning.py:507] global step 7761: loss = 1.8932 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 7762: loss = 1.9681 (0.529 sec/step)\n",
            "I0517 09:57:42.193203 139851376510848 learning.py:507] global step 7762: loss = 1.9681 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7763: loss = 1.7237 (0.538 sec/step)\n",
            "I0517 09:57:42.733265 139851376510848 learning.py:507] global step 7763: loss = 1.7237 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7764: loss = 2.1997 (0.567 sec/step)\n",
            "I0517 09:57:43.301976 139851376510848 learning.py:507] global step 7764: loss = 2.1997 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7765: loss = 1.6137 (0.545 sec/step)\n",
            "I0517 09:57:43.848357 139851376510848 learning.py:507] global step 7765: loss = 1.6137 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7766: loss = 2.4749 (0.523 sec/step)\n",
            "I0517 09:57:44.373134 139851376510848 learning.py:507] global step 7766: loss = 2.4749 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 7767: loss = 1.8342 (0.543 sec/step)\n",
            "I0517 09:57:44.918245 139851376510848 learning.py:507] global step 7767: loss = 1.8342 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7768: loss = 2.1418 (0.546 sec/step)\n",
            "I0517 09:57:45.466705 139851376510848 learning.py:507] global step 7768: loss = 2.1418 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7769: loss = 1.8324 (0.530 sec/step)\n",
            "I0517 09:57:45.998079 139851376510848 learning.py:507] global step 7769: loss = 1.8324 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7770: loss = 1.8686 (0.539 sec/step)\n",
            "I0517 09:57:46.539162 139851376510848 learning.py:507] global step 7770: loss = 1.8686 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7771: loss = 1.6220 (0.529 sec/step)\n",
            "I0517 09:57:47.070722 139851376510848 learning.py:507] global step 7771: loss = 1.6220 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7772: loss = 2.4771 (0.556 sec/step)\n",
            "I0517 09:57:47.628799 139851376510848 learning.py:507] global step 7772: loss = 2.4771 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7773: loss = 1.8981 (0.537 sec/step)\n",
            "I0517 09:57:48.167001 139851376510848 learning.py:507] global step 7773: loss = 1.8981 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7774: loss = 1.5866 (0.532 sec/step)\n",
            "I0517 09:57:48.700896 139851376510848 learning.py:507] global step 7774: loss = 1.5866 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7775: loss = 2.8094 (0.540 sec/step)\n",
            "I0517 09:57:49.243103 139851376510848 learning.py:507] global step 7775: loss = 2.8094 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7776: loss = 1.7440 (0.531 sec/step)\n",
            "I0517 09:57:49.775599 139851376510848 learning.py:507] global step 7776: loss = 1.7440 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7777: loss = 2.1106 (0.519 sec/step)\n",
            "I0517 09:57:50.296272 139851376510848 learning.py:507] global step 7777: loss = 2.1106 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7778: loss = 2.0172 (0.533 sec/step)\n",
            "I0517 09:57:50.831001 139851376510848 learning.py:507] global step 7778: loss = 2.0172 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7779: loss = 2.2364 (0.534 sec/step)\n",
            "I0517 09:57:51.368736 139851376510848 learning.py:507] global step 7779: loss = 2.2364 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7780: loss = 4.5545 (0.560 sec/step)\n",
            "I0517 09:57:51.931860 139851376510848 learning.py:507] global step 7780: loss = 4.5545 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7781: loss = 1.8453 (0.542 sec/step)\n",
            "I0517 09:57:52.475755 139851376510848 learning.py:507] global step 7781: loss = 1.8453 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7782: loss = 2.3102 (0.539 sec/step)\n",
            "I0517 09:57:53.016285 139851376510848 learning.py:507] global step 7782: loss = 2.3102 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7783: loss = 2.6208 (0.538 sec/step)\n",
            "I0517 09:57:53.556289 139851376510848 learning.py:507] global step 7783: loss = 2.6208 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7784: loss = 2.0235 (0.520 sec/step)\n",
            "I0517 09:57:54.077548 139851376510848 learning.py:507] global step 7784: loss = 2.0235 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 7785: loss = 1.7083 (0.528 sec/step)\n",
            "I0517 09:57:54.607422 139851376510848 learning.py:507] global step 7785: loss = 1.7083 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7786: loss = 1.5741 (0.530 sec/step)\n",
            "I0517 09:57:55.139001 139851376510848 learning.py:507] global step 7786: loss = 1.5741 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7787: loss = 2.3324 (0.605 sec/step)\n",
            "I0517 09:57:55.746122 139851376510848 learning.py:507] global step 7787: loss = 2.3324 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 7788: loss = 2.3605 (0.557 sec/step)\n",
            "I0517 09:57:56.305100 139851376510848 learning.py:507] global step 7788: loss = 2.3605 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7789: loss = 1.9340 (0.555 sec/step)\n",
            "I0517 09:57:56.861342 139851376510848 learning.py:507] global step 7789: loss = 1.9340 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7790: loss = 2.8036 (0.544 sec/step)\n",
            "I0517 09:57:57.407011 139851376510848 learning.py:507] global step 7790: loss = 2.8036 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7791: loss = 1.9691 (0.577 sec/step)\n",
            "I0517 09:57:57.985891 139851376510848 learning.py:507] global step 7791: loss = 1.9691 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 7792: loss = 2.5591 (0.525 sec/step)\n",
            "I0517 09:57:58.513079 139851376510848 learning.py:507] global step 7792: loss = 2.5591 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7793: loss = 1.7774 (0.551 sec/step)\n",
            "I0517 09:57:59.066081 139851376510848 learning.py:507] global step 7793: loss = 1.7774 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7794: loss = 1.6402 (0.533 sec/step)\n",
            "I0517 09:57:59.600446 139851376510848 learning.py:507] global step 7794: loss = 1.6402 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7795: loss = 1.8334 (0.564 sec/step)\n",
            "I0517 09:58:00.166419 139851376510848 learning.py:507] global step 7795: loss = 1.8334 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7796: loss = 1.7335 (0.556 sec/step)\n",
            "I0517 09:58:00.724236 139851376510848 learning.py:507] global step 7796: loss = 1.7335 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7797: loss = 2.7132 (0.551 sec/step)\n",
            "I0517 09:58:01.278112 139851376510848 learning.py:507] global step 7797: loss = 2.7132 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7798: loss = 2.2891 (0.525 sec/step)\n",
            "I0517 09:58:01.805109 139851376510848 learning.py:507] global step 7798: loss = 2.2891 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7799: loss = 1.4437 (0.545 sec/step)\n",
            "I0517 09:58:02.352151 139851376510848 learning.py:507] global step 7799: loss = 1.4437 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7800: loss = 3.3432 (0.555 sec/step)\n",
            "I0517 09:58:02.909236 139851376510848 learning.py:507] global step 7800: loss = 3.3432 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7801: loss = 2.5134 (0.533 sec/step)\n",
            "I0517 09:58:03.444083 139851376510848 learning.py:507] global step 7801: loss = 2.5134 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7802: loss = 2.8881 (0.549 sec/step)\n",
            "I0517 09:58:03.994558 139851376510848 learning.py:507] global step 7802: loss = 2.8881 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7803: loss = 2.9778 (0.561 sec/step)\n",
            "I0517 09:58:04.557884 139851376510848 learning.py:507] global step 7803: loss = 2.9778 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7804: loss = 2.3920 (0.548 sec/step)\n",
            "I0517 09:58:05.107345 139851376510848 learning.py:507] global step 7804: loss = 2.3920 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7805: loss = 1.8699 (0.549 sec/step)\n",
            "I0517 09:58:05.657908 139851376510848 learning.py:507] global step 7805: loss = 1.8699 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7806: loss = 1.9193 (0.575 sec/step)\n",
            "I0517 09:58:06.234483 139851376510848 learning.py:507] global step 7806: loss = 1.9193 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7807: loss = 2.3776 (0.525 sec/step)\n",
            "I0517 09:58:06.761451 139851376510848 learning.py:507] global step 7807: loss = 2.3776 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7808: loss = 2.9447 (0.551 sec/step)\n",
            "I0517 09:58:07.315482 139851376510848 learning.py:507] global step 7808: loss = 2.9447 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7809: loss = 1.9504 (0.525 sec/step)\n",
            "I0517 09:58:07.842160 139851376510848 learning.py:507] global step 7809: loss = 1.9504 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7810: loss = 2.1486 (0.537 sec/step)\n",
            "I0517 09:58:08.380526 139851376510848 learning.py:507] global step 7810: loss = 2.1486 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7811: loss = 1.8775 (0.571 sec/step)\n",
            "I0517 09:58:08.953063 139851376510848 learning.py:507] global step 7811: loss = 1.8775 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7812: loss = 1.6550 (0.567 sec/step)\n",
            "I0517 09:58:09.522412 139851376510848 learning.py:507] global step 7812: loss = 1.6550 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7813: loss = 2.3049 (0.540 sec/step)\n",
            "I0517 09:58:10.064769 139851376510848 learning.py:507] global step 7813: loss = 2.3049 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7814: loss = 1.7414 (0.535 sec/step)\n",
            "I0517 09:58:10.601744 139851376510848 learning.py:507] global step 7814: loss = 1.7414 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7815: loss = 2.3016 (0.531 sec/step)\n",
            "I0517 09:58:11.134353 139851376510848 learning.py:507] global step 7815: loss = 2.3016 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7816: loss = 2.0070 (0.527 sec/step)\n",
            "I0517 09:58:11.663287 139851376510848 learning.py:507] global step 7816: loss = 2.0070 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7817: loss = 2.1593 (0.542 sec/step)\n",
            "I0517 09:58:12.207166 139851376510848 learning.py:507] global step 7817: loss = 2.1593 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7818: loss = 1.9283 (0.529 sec/step)\n",
            "I0517 09:58:12.737959 139851376510848 learning.py:507] global step 7818: loss = 1.9283 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7819: loss = 2.4996 (0.528 sec/step)\n",
            "I0517 09:58:13.267871 139851376510848 learning.py:507] global step 7819: loss = 2.4996 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7820: loss = 1.5938 (0.552 sec/step)\n",
            "I0517 09:58:13.821947 139851376510848 learning.py:507] global step 7820: loss = 1.5938 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7821: loss = 2.4320 (0.557 sec/step)\n",
            "I0517 09:58:14.380123 139851376510848 learning.py:507] global step 7821: loss = 2.4320 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7822: loss = 2.9815 (0.525 sec/step)\n",
            "I0517 09:58:14.907732 139851376510848 learning.py:507] global step 7822: loss = 2.9815 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7823: loss = 1.8136 (0.557 sec/step)\n",
            "I0517 09:58:15.466150 139851376510848 learning.py:507] global step 7823: loss = 1.8136 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7824: loss = 1.3577 (0.525 sec/step)\n",
            "I0517 09:58:15.992462 139851376510848 learning.py:507] global step 7824: loss = 1.3577 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 7825: loss = 1.6058 (0.566 sec/step)\n",
            "I0517 09:58:16.559859 139851376510848 learning.py:507] global step 7825: loss = 1.6058 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7826: loss = 1.6607 (0.545 sec/step)\n",
            "I0517 09:58:17.106586 139851376510848 learning.py:507] global step 7826: loss = 1.6607 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7827: loss = 1.6800 (0.546 sec/step)\n",
            "I0517 09:58:17.654487 139851376510848 learning.py:507] global step 7827: loss = 1.6800 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7828: loss = 2.2127 (0.559 sec/step)\n",
            "I0517 09:58:18.214827 139851376510848 learning.py:507] global step 7828: loss = 2.2127 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7829: loss = 2.2191 (0.541 sec/step)\n",
            "I0517 09:58:18.757814 139851376510848 learning.py:507] global step 7829: loss = 2.2191 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7830: loss = 1.9841 (0.560 sec/step)\n",
            "I0517 09:58:19.320048 139851376510848 learning.py:507] global step 7830: loss = 1.9841 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7831: loss = 1.8361 (0.546 sec/step)\n",
            "I0517 09:58:19.867837 139851376510848 learning.py:507] global step 7831: loss = 1.8361 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7832: loss = 2.9081 (0.559 sec/step)\n",
            "I0517 09:58:20.429103 139851376510848 learning.py:507] global step 7832: loss = 2.9081 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7833: loss = 1.6708 (0.565 sec/step)\n",
            "I0517 09:58:20.996236 139851376510848 learning.py:507] global step 7833: loss = 1.6708 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 7834: loss = 2.3024 (0.579 sec/step)\n",
            "I0517 09:58:21.578089 139851376510848 learning.py:507] global step 7834: loss = 2.3024 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 7835: loss = 1.7531 (0.545 sec/step)\n",
            "I0517 09:58:22.124549 139851376510848 learning.py:507] global step 7835: loss = 1.7531 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7836: loss = 2.3402 (0.535 sec/step)\n",
            "I0517 09:58:22.661656 139851376510848 learning.py:507] global step 7836: loss = 2.3402 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7837: loss = 1.6661 (0.536 sec/step)\n",
            "I0517 09:58:23.199205 139851376510848 learning.py:507] global step 7837: loss = 1.6661 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7838: loss = 2.1019 (0.566 sec/step)\n",
            "I0517 09:58:23.767813 139851376510848 learning.py:507] global step 7838: loss = 2.1019 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 7839: loss = 2.3870 (0.538 sec/step)\n",
            "I0517 09:58:24.308703 139851376510848 learning.py:507] global step 7839: loss = 2.3870 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7840: loss = 1.7598 (0.561 sec/step)\n",
            "I0517 09:58:24.871903 139851376510848 learning.py:507] global step 7840: loss = 1.7598 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7841: loss = 1.2233 (0.551 sec/step)\n",
            "I0517 09:58:25.425087 139851376510848 learning.py:507] global step 7841: loss = 1.2233 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7842: loss = 1.6403 (0.568 sec/step)\n",
            "I0517 09:58:25.995018 139851376510848 learning.py:507] global step 7842: loss = 1.6403 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7843: loss = 2.0455 (0.548 sec/step)\n",
            "I0517 09:58:26.544429 139851376510848 learning.py:507] global step 7843: loss = 2.0455 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7844: loss = 1.7850 (0.574 sec/step)\n",
            "I0517 09:58:27.120370 139851376510848 learning.py:507] global step 7844: loss = 1.7850 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7845: loss = 2.6957 (0.574 sec/step)\n",
            "I0517 09:58:27.696306 139851376510848 learning.py:507] global step 7845: loss = 2.6957 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 7846: loss = 2.1202 (0.518 sec/step)\n",
            "I0517 09:58:28.215726 139851376510848 learning.py:507] global step 7846: loss = 2.1202 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7847: loss = 2.0351 (0.549 sec/step)\n",
            "I0517 09:58:28.766838 139851376510848 learning.py:507] global step 7847: loss = 2.0351 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7848: loss = 2.5420 (0.575 sec/step)\n",
            "I0517 09:58:29.343299 139851376510848 learning.py:507] global step 7848: loss = 2.5420 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7849: loss = 1.7257 (0.541 sec/step)\n",
            "I0517 09:58:29.885832 139851376510848 learning.py:507] global step 7849: loss = 1.7257 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7850: loss = 1.9582 (0.537 sec/step)\n",
            "I0517 09:58:30.424836 139851376510848 learning.py:507] global step 7850: loss = 1.9582 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7851: loss = 1.9337 (0.562 sec/step)\n",
            "I0517 09:58:30.988470 139851376510848 learning.py:507] global step 7851: loss = 1.9337 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7852: loss = 2.2499 (0.543 sec/step)\n",
            "I0517 09:58:31.532881 139851376510848 learning.py:507] global step 7852: loss = 2.2499 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 7853: loss = 2.3545 (0.522 sec/step)\n",
            "I0517 09:58:32.056976 139851376510848 learning.py:507] global step 7853: loss = 2.3545 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7854: loss = 2.5138 (0.511 sec/step)\n",
            "I0517 09:58:32.569901 139851376510848 learning.py:507] global step 7854: loss = 2.5138 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 7855: loss = 1.4104 (0.541 sec/step)\n",
            "I0517 09:58:33.113053 139851376510848 learning.py:507] global step 7855: loss = 1.4104 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7856: loss = 2.4163 (0.548 sec/step)\n",
            "I0517 09:58:33.662668 139851376510848 learning.py:507] global step 7856: loss = 2.4163 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7857: loss = 2.3222 (0.546 sec/step)\n",
            "I0517 09:58:34.210239 139851376510848 learning.py:507] global step 7857: loss = 2.3222 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7858: loss = 1.7548 (0.541 sec/step)\n",
            "I0517 09:58:34.752482 139851376510848 learning.py:507] global step 7858: loss = 1.7548 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7859: loss = 1.8101 (0.529 sec/step)\n",
            "I0517 09:58:35.283451 139851376510848 learning.py:507] global step 7859: loss = 1.8101 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7860: loss = 1.8713 (0.544 sec/step)\n",
            "I0517 09:58:35.829709 139851376510848 learning.py:507] global step 7860: loss = 1.8713 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7861: loss = 1.4856 (0.533 sec/step)\n",
            "I0517 09:58:36.363927 139851376510848 learning.py:507] global step 7861: loss = 1.4856 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7862: loss = 1.6302 (0.564 sec/step)\n",
            "I0517 09:58:36.929922 139851376510848 learning.py:507] global step 7862: loss = 1.6302 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7863: loss = 1.5768 (0.526 sec/step)\n",
            "I0517 09:58:37.457587 139851376510848 learning.py:507] global step 7863: loss = 1.5768 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7864: loss = 2.0341 (0.562 sec/step)\n",
            "I0517 09:58:38.021021 139851376510848 learning.py:507] global step 7864: loss = 2.0341 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7865: loss = 1.6293 (0.538 sec/step)\n",
            "I0517 09:58:38.560756 139851376510848 learning.py:507] global step 7865: loss = 1.6293 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7866: loss = 1.4716 (0.537 sec/step)\n",
            "I0517 09:58:39.099793 139851376510848 learning.py:507] global step 7866: loss = 1.4716 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7867: loss = 2.1492 (0.564 sec/step)\n",
            "I0517 09:58:39.665822 139851376510848 learning.py:507] global step 7867: loss = 2.1492 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7868: loss = 2.1935 (0.541 sec/step)\n",
            "I0517 09:58:40.208917 139851376510848 learning.py:507] global step 7868: loss = 2.1935 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7869: loss = 2.2730 (0.578 sec/step)\n",
            "I0517 09:58:40.788383 139851376510848 learning.py:507] global step 7869: loss = 2.2730 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 7870: loss = 1.5843 (0.559 sec/step)\n",
            "I0517 09:58:41.348616 139851376510848 learning.py:507] global step 7870: loss = 1.5843 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7871: loss = 2.3374 (0.567 sec/step)\n",
            "I0517 09:58:41.917615 139851376510848 learning.py:507] global step 7871: loss = 2.3374 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7872: loss = 2.1716 (0.521 sec/step)\n",
            "I0517 09:58:42.440987 139851376510848 learning.py:507] global step 7872: loss = 2.1716 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7873: loss = 2.1006 (0.567 sec/step)\n",
            "I0517 09:58:43.009790 139851376510848 learning.py:507] global step 7873: loss = 2.1006 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7874: loss = 2.0595 (0.550 sec/step)\n",
            "I0517 09:58:43.561939 139851376510848 learning.py:507] global step 7874: loss = 2.0595 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7875: loss = 1.8106 (0.559 sec/step)\n",
            "I0517 09:58:44.122791 139851376510848 learning.py:507] global step 7875: loss = 1.8106 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 7876: loss = 1.7134 (0.530 sec/step)\n",
            "I0517 09:58:44.654683 139851376510848 learning.py:507] global step 7876: loss = 1.7134 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7877: loss = 1.7115 (0.544 sec/step)\n",
            "I0517 09:58:45.200709 139851376510848 learning.py:507] global step 7877: loss = 1.7115 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7878: loss = 2.1481 (0.657 sec/step)\n",
            "I0517 09:58:46.070863 139851376510848 learning.py:507] global step 7878: loss = 2.1481 (0.657 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7878.\n",
            "I0517 09:58:46.953841 139847641536256 supervisor.py:1050] Recording summary at step 7878.\n",
            "INFO:tensorflow:global step 7879: loss = 1.8475 (0.987 sec/step)\n",
            "I0517 09:58:47.061541 139851376510848 learning.py:507] global step 7879: loss = 1.8475 (0.987 sec/step)\n",
            "INFO:tensorflow:global step 7880: loss = 2.5202 (0.528 sec/step)\n",
            "I0517 09:58:47.592347 139851376510848 learning.py:507] global step 7880: loss = 2.5202 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7881: loss = 1.8868 (0.595 sec/step)\n",
            "I0517 09:58:48.188685 139851376510848 learning.py:507] global step 7881: loss = 1.8868 (0.595 sec/step)\n",
            "INFO:tensorflow:global step 7882: loss = 2.3230 (0.549 sec/step)\n",
            "I0517 09:58:48.739351 139851376510848 learning.py:507] global step 7882: loss = 2.3230 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 7883: loss = 2.2222 (0.571 sec/step)\n",
            "I0517 09:58:49.311729 139851376510848 learning.py:507] global step 7883: loss = 2.2222 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7884: loss = 1.5601 (0.534 sec/step)\n",
            "I0517 09:58:49.846908 139851376510848 learning.py:507] global step 7884: loss = 1.5601 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7885: loss = 2.5789 (0.553 sec/step)\n",
            "I0517 09:58:50.402084 139851376510848 learning.py:507] global step 7885: loss = 2.5789 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7886: loss = 1.5530 (0.534 sec/step)\n",
            "I0517 09:58:50.938374 139851376510848 learning.py:507] global step 7886: loss = 1.5530 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7887: loss = 2.5477 (0.541 sec/step)\n",
            "I0517 09:58:51.481392 139851376510848 learning.py:507] global step 7887: loss = 2.5477 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7888: loss = 2.3544 (0.567 sec/step)\n",
            "I0517 09:58:52.053870 139851376510848 learning.py:507] global step 7888: loss = 2.3544 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7889: loss = 2.5162 (0.551 sec/step)\n",
            "I0517 09:58:52.606208 139851376510848 learning.py:507] global step 7889: loss = 2.5162 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 7890: loss = 1.5966 (0.537 sec/step)\n",
            "I0517 09:58:53.144575 139851376510848 learning.py:507] global step 7890: loss = 1.5966 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7891: loss = 2.1719 (0.528 sec/step)\n",
            "I0517 09:58:53.674515 139851376510848 learning.py:507] global step 7891: loss = 2.1719 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7892: loss = 2.0567 (0.514 sec/step)\n",
            "I0517 09:58:54.190258 139851376510848 learning.py:507] global step 7892: loss = 2.0567 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 7893: loss = 1.9357 (0.519 sec/step)\n",
            "I0517 09:58:54.711324 139851376510848 learning.py:507] global step 7893: loss = 1.9357 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7894: loss = 1.6654 (0.518 sec/step)\n",
            "I0517 09:58:55.230967 139851376510848 learning.py:507] global step 7894: loss = 1.6654 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7895: loss = 1.7853 (0.561 sec/step)\n",
            "I0517 09:58:55.793974 139851376510848 learning.py:507] global step 7895: loss = 1.7853 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7896: loss = 1.3056 (0.555 sec/step)\n",
            "I0517 09:58:56.350907 139851376510848 learning.py:507] global step 7896: loss = 1.3056 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7897: loss = 1.9382 (0.547 sec/step)\n",
            "I0517 09:58:56.899470 139851376510848 learning.py:507] global step 7897: loss = 1.9382 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7898: loss = 1.5248 (0.540 sec/step)\n",
            "I0517 09:58:57.441724 139851376510848 learning.py:507] global step 7898: loss = 1.5248 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7899: loss = 1.6391 (0.534 sec/step)\n",
            "I0517 09:58:57.977229 139851376510848 learning.py:507] global step 7899: loss = 1.6391 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7900: loss = 1.6776 (0.550 sec/step)\n",
            "I0517 09:58:58.529192 139851376510848 learning.py:507] global step 7900: loss = 1.6776 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7901: loss = 1.8643 (0.553 sec/step)\n",
            "I0517 09:58:59.083472 139851376510848 learning.py:507] global step 7901: loss = 1.8643 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 7902: loss = 1.6769 (0.552 sec/step)\n",
            "I0517 09:58:59.637327 139851376510848 learning.py:507] global step 7902: loss = 1.6769 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7903: loss = 2.0914 (0.517 sec/step)\n",
            "I0517 09:59:00.156620 139851376510848 learning.py:507] global step 7903: loss = 2.0914 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 7904: loss = 1.7815 (0.535 sec/step)\n",
            "I0517 09:59:00.693825 139851376510848 learning.py:507] global step 7904: loss = 1.7815 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7905: loss = 2.6236 (0.534 sec/step)\n",
            "I0517 09:59:01.230020 139851376510848 learning.py:507] global step 7905: loss = 2.6236 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7906: loss = 1.9068 (0.532 sec/step)\n",
            "I0517 09:59:01.765318 139851376510848 learning.py:507] global step 7906: loss = 1.9068 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7907: loss = 1.3877 (0.521 sec/step)\n",
            "I0517 09:59:02.287852 139851376510848 learning.py:507] global step 7907: loss = 1.3877 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7908: loss = 1.6401 (0.554 sec/step)\n",
            "I0517 09:59:02.843845 139851376510848 learning.py:507] global step 7908: loss = 1.6401 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7909: loss = 2.0609 (0.544 sec/step)\n",
            "I0517 09:59:03.389791 139851376510848 learning.py:507] global step 7909: loss = 2.0609 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7910: loss = 1.5698 (0.557 sec/step)\n",
            "I0517 09:59:03.948843 139851376510848 learning.py:507] global step 7910: loss = 1.5698 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 7911: loss = 2.6631 (0.521 sec/step)\n",
            "I0517 09:59:04.471417 139851376510848 learning.py:507] global step 7911: loss = 2.6631 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 7912: loss = 2.4550 (0.534 sec/step)\n",
            "I0517 09:59:05.007061 139851376510848 learning.py:507] global step 7912: loss = 2.4550 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 7913: loss = 1.4539 (0.556 sec/step)\n",
            "I0517 09:59:05.564250 139851376510848 learning.py:507] global step 7913: loss = 1.4539 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 7914: loss = 1.5775 (0.532 sec/step)\n",
            "I0517 09:59:06.097693 139851376510848 learning.py:507] global step 7914: loss = 1.5775 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7915: loss = 1.6578 (0.536 sec/step)\n",
            "I0517 09:59:06.636672 139851376510848 learning.py:507] global step 7915: loss = 1.6578 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7916: loss = 2.1582 (0.542 sec/step)\n",
            "I0517 09:59:07.180871 139851376510848 learning.py:507] global step 7916: loss = 2.1582 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7917: loss = 1.8910 (0.545 sec/step)\n",
            "I0517 09:59:07.727770 139851376510848 learning.py:507] global step 7917: loss = 1.8910 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7918: loss = 2.4863 (0.548 sec/step)\n",
            "I0517 09:59:08.278055 139851376510848 learning.py:507] global step 7918: loss = 2.4863 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7919: loss = 1.7753 (0.564 sec/step)\n",
            "I0517 09:59:08.844168 139851376510848 learning.py:507] global step 7919: loss = 1.7753 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7920: loss = 2.2058 (0.546 sec/step)\n",
            "I0517 09:59:09.392366 139851376510848 learning.py:507] global step 7920: loss = 2.2058 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7921: loss = 2.5460 (0.540 sec/step)\n",
            "I0517 09:59:09.934530 139851376510848 learning.py:507] global step 7921: loss = 2.5460 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7922: loss = 2.3389 (0.531 sec/step)\n",
            "I0517 09:59:10.467248 139851376510848 learning.py:507] global step 7922: loss = 2.3389 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7923: loss = 1.6965 (0.531 sec/step)\n",
            "I0517 09:59:10.999879 139851376510848 learning.py:507] global step 7923: loss = 1.6965 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7924: loss = 1.6527 (0.541 sec/step)\n",
            "I0517 09:59:11.543117 139851376510848 learning.py:507] global step 7924: loss = 1.6527 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 7925: loss = 1.8099 (0.550 sec/step)\n",
            "I0517 09:59:12.095255 139851376510848 learning.py:507] global step 7925: loss = 1.8099 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 7926: loss = 1.9936 (0.532 sec/step)\n",
            "I0517 09:59:12.630273 139851376510848 learning.py:507] global step 7926: loss = 1.9936 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 7927: loss = 1.3964 (0.548 sec/step)\n",
            "I0517 09:59:13.179941 139851376510848 learning.py:507] global step 7927: loss = 1.3964 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7928: loss = 1.4460 (0.548 sec/step)\n",
            "I0517 09:59:13.729346 139851376510848 learning.py:507] global step 7928: loss = 1.4460 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7929: loss = 2.0417 (0.533 sec/step)\n",
            "I0517 09:59:14.264419 139851376510848 learning.py:507] global step 7929: loss = 2.0417 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 7930: loss = 3.2398 (0.529 sec/step)\n",
            "I0517 09:59:14.795278 139851376510848 learning.py:507] global step 7930: loss = 3.2398 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7931: loss = 2.9954 (0.540 sec/step)\n",
            "I0517 09:59:15.337540 139851376510848 learning.py:507] global step 7931: loss = 2.9954 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 7932: loss = 1.8758 (0.567 sec/step)\n",
            "I0517 09:59:15.905903 139851376510848 learning.py:507] global step 7932: loss = 1.8758 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7933: loss = 1.7127 (0.527 sec/step)\n",
            "I0517 09:59:16.435472 139851376510848 learning.py:507] global step 7933: loss = 1.7127 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7934: loss = 2.1898 (0.529 sec/step)\n",
            "I0517 09:59:16.965969 139851376510848 learning.py:507] global step 7934: loss = 2.1898 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7935: loss = 2.5415 (0.547 sec/step)\n",
            "I0517 09:59:17.514605 139851376510848 learning.py:507] global step 7935: loss = 2.5415 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7936: loss = 1.6961 (0.583 sec/step)\n",
            "I0517 09:59:18.099505 139851376510848 learning.py:507] global step 7936: loss = 1.6961 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 7937: loss = 1.4171 (0.537 sec/step)\n",
            "I0517 09:59:18.639319 139851376510848 learning.py:507] global step 7937: loss = 1.4171 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7938: loss = 2.1320 (0.561 sec/step)\n",
            "I0517 09:59:19.202104 139851376510848 learning.py:507] global step 7938: loss = 2.1320 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7939: loss = 1.7083 (0.539 sec/step)\n",
            "I0517 09:59:19.743201 139851376510848 learning.py:507] global step 7939: loss = 1.7083 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7940: loss = 3.1405 (0.537 sec/step)\n",
            "I0517 09:59:20.281589 139851376510848 learning.py:507] global step 7940: loss = 3.1405 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 7941: loss = 1.5323 (0.515 sec/step)\n",
            "I0517 09:59:20.798674 139851376510848 learning.py:507] global step 7941: loss = 1.5323 (0.515 sec/step)\n",
            "INFO:tensorflow:global step 7942: loss = 1.6754 (0.560 sec/step)\n",
            "I0517 09:59:21.360634 139851376510848 learning.py:507] global step 7942: loss = 1.6754 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7943: loss = 1.3191 (0.531 sec/step)\n",
            "I0517 09:59:21.893491 139851376510848 learning.py:507] global step 7943: loss = 1.3191 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 7944: loss = 1.7141 (0.529 sec/step)\n",
            "I0517 09:59:22.424106 139851376510848 learning.py:507] global step 7944: loss = 1.7141 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 7945: loss = 2.3073 (0.548 sec/step)\n",
            "I0517 09:59:22.973446 139851376510848 learning.py:507] global step 7945: loss = 2.3073 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7946: loss = 2.3380 (0.512 sec/step)\n",
            "I0517 09:59:23.488297 139851376510848 learning.py:507] global step 7946: loss = 2.3380 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 7947: loss = 1.5615 (0.539 sec/step)\n",
            "I0517 09:59:24.029711 139851376510848 learning.py:507] global step 7947: loss = 1.5615 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7948: loss = 1.9067 (0.530 sec/step)\n",
            "I0517 09:59:24.561258 139851376510848 learning.py:507] global step 7948: loss = 1.9067 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 7949: loss = 2.4487 (0.519 sec/step)\n",
            "I0517 09:59:25.081779 139851376510848 learning.py:507] global step 7949: loss = 2.4487 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 7950: loss = 1.4230 (0.535 sec/step)\n",
            "I0517 09:59:25.618124 139851376510848 learning.py:507] global step 7950: loss = 1.4230 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7951: loss = 1.7165 (0.542 sec/step)\n",
            "I0517 09:59:26.162301 139851376510848 learning.py:507] global step 7951: loss = 1.7165 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7952: loss = 2.0812 (0.546 sec/step)\n",
            "I0517 09:59:26.709926 139851376510848 learning.py:507] global step 7952: loss = 2.0812 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 7953: loss = 1.8338 (0.548 sec/step)\n",
            "I0517 09:59:27.259661 139851376510848 learning.py:507] global step 7953: loss = 1.8338 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 7954: loss = 2.0994 (0.568 sec/step)\n",
            "I0517 09:59:27.829636 139851376510848 learning.py:507] global step 7954: loss = 2.0994 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7955: loss = 2.7581 (0.555 sec/step)\n",
            "I0517 09:59:28.386249 139851376510848 learning.py:507] global step 7955: loss = 2.7581 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7956: loss = 2.6130 (0.511 sec/step)\n",
            "I0517 09:59:28.898876 139851376510848 learning.py:507] global step 7956: loss = 2.6130 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 7957: loss = 3.6445 (0.561 sec/step)\n",
            "I0517 09:59:29.461311 139851376510848 learning.py:507] global step 7957: loss = 3.6445 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 7958: loss = 1.5529 (0.526 sec/step)\n",
            "I0517 09:59:29.988596 139851376510848 learning.py:507] global step 7958: loss = 1.5529 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7959: loss = 2.7412 (0.577 sec/step)\n",
            "I0517 09:59:30.567488 139851376510848 learning.py:507] global step 7959: loss = 2.7412 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 7960: loss = 3.5948 (0.545 sec/step)\n",
            "I0517 09:59:31.116425 139851376510848 learning.py:507] global step 7960: loss = 3.5948 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 7961: loss = 1.9660 (0.568 sec/step)\n",
            "I0517 09:59:31.686717 139851376510848 learning.py:507] global step 7961: loss = 1.9660 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7962: loss = 2.0251 (0.583 sec/step)\n",
            "I0517 09:59:32.271857 139851376510848 learning.py:507] global step 7962: loss = 2.0251 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 7963: loss = 1.9277 (0.575 sec/step)\n",
            "I0517 09:59:32.848095 139851376510848 learning.py:507] global step 7963: loss = 1.9277 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 7964: loss = 1.8904 (0.560 sec/step)\n",
            "I0517 09:59:33.409413 139851376510848 learning.py:507] global step 7964: loss = 1.8904 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7965: loss = 1.9871 (0.562 sec/step)\n",
            "I0517 09:59:33.973706 139851376510848 learning.py:507] global step 7965: loss = 1.9871 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 7966: loss = 2.4722 (0.535 sec/step)\n",
            "I0517 09:59:34.510234 139851376510848 learning.py:507] global step 7966: loss = 2.4722 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7967: loss = 1.6334 (0.516 sec/step)\n",
            "I0517 09:59:35.029152 139851376510848 learning.py:507] global step 7967: loss = 1.6334 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 7968: loss = 2.0990 (0.564 sec/step)\n",
            "I0517 09:59:35.594941 139851376510848 learning.py:507] global step 7968: loss = 2.0990 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 7969: loss = 2.0493 (0.544 sec/step)\n",
            "I0517 09:59:36.140832 139851376510848 learning.py:507] global step 7969: loss = 2.0493 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 7970: loss = 1.7480 (0.552 sec/step)\n",
            "I0517 09:59:36.694984 139851376510848 learning.py:507] global step 7970: loss = 1.7480 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7971: loss = 2.2059 (0.518 sec/step)\n",
            "I0517 09:59:37.215458 139851376510848 learning.py:507] global step 7971: loss = 2.2059 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 7972: loss = 1.8370 (0.568 sec/step)\n",
            "I0517 09:59:37.785485 139851376510848 learning.py:507] global step 7972: loss = 1.8370 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 7973: loss = 2.4667 (0.555 sec/step)\n",
            "I0517 09:59:38.341924 139851376510848 learning.py:507] global step 7973: loss = 2.4667 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7974: loss = 1.3256 (0.538 sec/step)\n",
            "I0517 09:59:38.882481 139851376510848 learning.py:507] global step 7974: loss = 1.3256 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 7975: loss = 2.0235 (0.528 sec/step)\n",
            "I0517 09:59:39.412353 139851376510848 learning.py:507] global step 7975: loss = 2.0235 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 7976: loss = 2.5982 (0.536 sec/step)\n",
            "I0517 09:59:39.950073 139851376510848 learning.py:507] global step 7976: loss = 2.5982 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7977: loss = 2.2723 (0.542 sec/step)\n",
            "I0517 09:59:40.493766 139851376510848 learning.py:507] global step 7977: loss = 2.2723 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 7978: loss = 1.9102 (0.527 sec/step)\n",
            "I0517 09:59:41.022943 139851376510848 learning.py:507] global step 7978: loss = 1.9102 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7979: loss = 1.5572 (0.547 sec/step)\n",
            "I0517 09:59:41.571878 139851376510848 learning.py:507] global step 7979: loss = 1.5572 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 7980: loss = 1.7139 (0.572 sec/step)\n",
            "I0517 09:59:42.144948 139851376510848 learning.py:507] global step 7980: loss = 1.7139 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 7981: loss = 4.3312 (0.567 sec/step)\n",
            "I0517 09:59:42.713356 139851376510848 learning.py:507] global step 7981: loss = 4.3312 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7982: loss = 2.8378 (0.527 sec/step)\n",
            "I0517 09:59:43.241948 139851376510848 learning.py:507] global step 7982: loss = 2.8378 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 7983: loss = 1.9951 (0.585 sec/step)\n",
            "I0517 09:59:43.828816 139851376510848 learning.py:507] global step 7983: loss = 1.9951 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 7984: loss = 1.8887 (0.552 sec/step)\n",
            "I0517 09:59:44.382899 139851376510848 learning.py:507] global step 7984: loss = 1.8887 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7985: loss = 2.1855 (0.567 sec/step)\n",
            "I0517 09:59:44.951491 139851376510848 learning.py:507] global step 7985: loss = 2.1855 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7986: loss = 3.0586 (0.535 sec/step)\n",
            "I0517 09:59:45.489492 139851376510848 learning.py:507] global step 7986: loss = 3.0586 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 7987: loss = 1.9323 (0.555 sec/step)\n",
            "I0517 09:59:46.046629 139851376510848 learning.py:507] global step 7987: loss = 1.9323 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 7988: loss = 1.9980 (0.567 sec/step)\n",
            "I0517 09:59:46.615460 139851376510848 learning.py:507] global step 7988: loss = 1.9980 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 7989: loss = 4.8481 (0.552 sec/step)\n",
            "I0517 09:59:47.170290 139851376510848 learning.py:507] global step 7989: loss = 4.8481 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7990: loss = 1.5507 (0.560 sec/step)\n",
            "I0517 09:59:47.732318 139851376510848 learning.py:507] global step 7990: loss = 1.5507 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 7991: loss = 1.9314 (0.539 sec/step)\n",
            "I0517 09:59:48.273497 139851376510848 learning.py:507] global step 7991: loss = 1.9314 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 7992: loss = 1.8198 (0.558 sec/step)\n",
            "I0517 09:59:48.833907 139851376510848 learning.py:507] global step 7992: loss = 1.8198 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 7993: loss = 1.7463 (0.552 sec/step)\n",
            "I0517 09:59:49.387972 139851376510848 learning.py:507] global step 7993: loss = 1.7463 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 7994: loss = 1.3809 (0.571 sec/step)\n",
            "I0517 09:59:49.960491 139851376510848 learning.py:507] global step 7994: loss = 1.3809 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 7995: loss = 1.7784 (0.536 sec/step)\n",
            "I0517 09:59:50.498749 139851376510848 learning.py:507] global step 7995: loss = 1.7784 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 7996: loss = 1.6825 (0.526 sec/step)\n",
            "I0517 09:59:51.026013 139851376510848 learning.py:507] global step 7996: loss = 1.6825 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 7997: loss = 2.1173 (0.522 sec/step)\n",
            "I0517 09:59:51.550273 139851376510848 learning.py:507] global step 7997: loss = 2.1173 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 7998: loss = 1.7639 (0.554 sec/step)\n",
            "I0517 09:59:52.106612 139851376510848 learning.py:507] global step 7998: loss = 1.7639 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 7999: loss = 1.7651 (0.566 sec/step)\n",
            "I0517 09:59:52.674403 139851376510848 learning.py:507] global step 7999: loss = 1.7651 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8000: loss = 1.7676 (0.540 sec/step)\n",
            "I0517 09:59:53.216276 139851376510848 learning.py:507] global step 8000: loss = 1.7676 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8001: loss = 1.9471 (0.538 sec/step)\n",
            "I0517 09:59:53.756530 139851376510848 learning.py:507] global step 8001: loss = 1.9471 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8002: loss = 2.6131 (0.539 sec/step)\n",
            "I0517 09:59:54.296738 139851376510848 learning.py:507] global step 8002: loss = 2.6131 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8003: loss = 1.6584 (0.537 sec/step)\n",
            "I0517 09:59:54.835299 139851376510848 learning.py:507] global step 8003: loss = 1.6584 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8004: loss = 1.8684 (0.536 sec/step)\n",
            "I0517 09:59:55.373410 139851376510848 learning.py:507] global step 8004: loss = 1.8684 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8005: loss = 1.6919 (0.543 sec/step)\n",
            "I0517 09:59:55.917889 139851376510848 learning.py:507] global step 8005: loss = 1.6919 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8006: loss = 1.7428 (0.546 sec/step)\n",
            "I0517 09:59:56.465961 139851376510848 learning.py:507] global step 8006: loss = 1.7428 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8007: loss = 2.5285 (0.567 sec/step)\n",
            "I0517 09:59:57.034924 139851376510848 learning.py:507] global step 8007: loss = 2.5285 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 8008: loss = 1.7731 (0.555 sec/step)\n",
            "I0517 09:59:57.591730 139851376510848 learning.py:507] global step 8008: loss = 1.7731 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8009: loss = 1.5880 (0.545 sec/step)\n",
            "I0517 09:59:58.139486 139851376510848 learning.py:507] global step 8009: loss = 1.5880 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8010: loss = 2.0053 (0.550 sec/step)\n",
            "I0517 09:59:58.691020 139851376510848 learning.py:507] global step 8010: loss = 2.0053 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8011: loss = 1.5520 (0.564 sec/step)\n",
            "I0517 09:59:59.258665 139851376510848 learning.py:507] global step 8011: loss = 1.5520 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8012: loss = 1.6586 (0.544 sec/step)\n",
            "I0517 09:59:59.804124 139851376510848 learning.py:507] global step 8012: loss = 1.6586 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8013: loss = 2.8404 (0.534 sec/step)\n",
            "I0517 10:00:00.339690 139851376510848 learning.py:507] global step 8013: loss = 2.8404 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8014: loss = 2.2223 (0.546 sec/step)\n",
            "I0517 10:00:00.887640 139851376510848 learning.py:507] global step 8014: loss = 2.2223 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8015: loss = 1.4046 (0.575 sec/step)\n",
            "I0517 10:00:01.464390 139851376510848 learning.py:507] global step 8015: loss = 1.4046 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8016: loss = 1.7605 (0.552 sec/step)\n",
            "I0517 10:00:02.017978 139851376510848 learning.py:507] global step 8016: loss = 1.7605 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8017: loss = 1.8503 (0.547 sec/step)\n",
            "I0517 10:00:02.567023 139851376510848 learning.py:507] global step 8017: loss = 1.8503 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8018: loss = 1.6135 (0.540 sec/step)\n",
            "I0517 10:00:03.109122 139851376510848 learning.py:507] global step 8018: loss = 1.6135 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8019: loss = 1.7646 (0.549 sec/step)\n",
            "I0517 10:00:03.660169 139851376510848 learning.py:507] global step 8019: loss = 1.7646 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8020: loss = 1.6434 (0.560 sec/step)\n",
            "I0517 10:00:04.222456 139851376510848 learning.py:507] global step 8020: loss = 1.6434 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8021: loss = 1.9653 (0.553 sec/step)\n",
            "I0517 10:00:04.779104 139851376510848 learning.py:507] global step 8021: loss = 1.9653 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8022: loss = 1.7277 (0.556 sec/step)\n",
            "I0517 10:00:05.337059 139851376510848 learning.py:507] global step 8022: loss = 1.7277 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8023: loss = 1.9796 (0.529 sec/step)\n",
            "I0517 10:00:05.868097 139851376510848 learning.py:507] global step 8023: loss = 1.9796 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8024: loss = 2.2586 (0.542 sec/step)\n",
            "I0517 10:00:06.411866 139851376510848 learning.py:507] global step 8024: loss = 2.2586 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8025: loss = 1.5231 (0.526 sec/step)\n",
            "I0517 10:00:06.939375 139851376510848 learning.py:507] global step 8025: loss = 1.5231 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8026: loss = 2.5013 (0.538 sec/step)\n",
            "I0517 10:00:07.478866 139851376510848 learning.py:507] global step 8026: loss = 2.5013 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8027: loss = 1.8119 (0.567 sec/step)\n",
            "I0517 10:00:08.047845 139851376510848 learning.py:507] global step 8027: loss = 1.8119 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 8028: loss = 3.0189 (0.532 sec/step)\n",
            "I0517 10:00:08.582251 139851376510848 learning.py:507] global step 8028: loss = 3.0189 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8029: loss = 1.3330 (0.546 sec/step)\n",
            "I0517 10:00:09.129594 139851376510848 learning.py:507] global step 8029: loss = 1.3330 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8030: loss = 2.3947 (0.549 sec/step)\n",
            "I0517 10:00:09.680540 139851376510848 learning.py:507] global step 8030: loss = 2.3947 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8031: loss = 2.4896 (0.551 sec/step)\n",
            "I0517 10:00:10.233596 139851376510848 learning.py:507] global step 8031: loss = 2.4896 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8032: loss = 2.3499 (0.526 sec/step)\n",
            "I0517 10:00:10.761862 139851376510848 learning.py:507] global step 8032: loss = 2.3499 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8033: loss = 1.8058 (0.535 sec/step)\n",
            "I0517 10:00:11.299217 139851376510848 learning.py:507] global step 8033: loss = 1.8058 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8034: loss = 1.5495 (0.528 sec/step)\n",
            "I0517 10:00:11.828902 139851376510848 learning.py:507] global step 8034: loss = 1.5495 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8035: loss = 1.7963 (0.532 sec/step)\n",
            "I0517 10:00:12.362883 139851376510848 learning.py:507] global step 8035: loss = 1.7963 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8036: loss = 1.9803 (0.544 sec/step)\n",
            "I0517 10:00:12.908761 139851376510848 learning.py:507] global step 8036: loss = 1.9803 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8037: loss = 2.5065 (0.533 sec/step)\n",
            "I0517 10:00:13.443576 139851376510848 learning.py:507] global step 8037: loss = 2.5065 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8038: loss = 2.0892 (0.556 sec/step)\n",
            "I0517 10:00:14.001243 139851376510848 learning.py:507] global step 8038: loss = 2.0892 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8039: loss = 2.4584 (0.534 sec/step)\n",
            "I0517 10:00:14.537083 139851376510848 learning.py:507] global step 8039: loss = 2.4584 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8040: loss = 1.7004 (0.540 sec/step)\n",
            "I0517 10:00:15.078495 139851376510848 learning.py:507] global step 8040: loss = 1.7004 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8041: loss = 1.5424 (0.549 sec/step)\n",
            "I0517 10:00:15.628938 139851376510848 learning.py:507] global step 8041: loss = 1.5424 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8042: loss = 2.0178 (0.545 sec/step)\n",
            "I0517 10:00:16.175121 139851376510848 learning.py:507] global step 8042: loss = 2.0178 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8043: loss = 3.2683 (0.572 sec/step)\n",
            "I0517 10:00:16.749478 139851376510848 learning.py:507] global step 8043: loss = 3.2683 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 8044: loss = 1.8463 (0.584 sec/step)\n",
            "I0517 10:00:17.335179 139851376510848 learning.py:507] global step 8044: loss = 1.8463 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 8045: loss = 1.3239 (0.556 sec/step)\n",
            "I0517 10:00:17.892609 139851376510848 learning.py:507] global step 8045: loss = 1.3239 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8046: loss = 2.1800 (0.588 sec/step)\n",
            "I0517 10:00:18.482528 139851376510848 learning.py:507] global step 8046: loss = 2.1800 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 8047: loss = 1.8145 (0.534 sec/step)\n",
            "I0517 10:00:19.018594 139851376510848 learning.py:507] global step 8047: loss = 1.8145 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8048: loss = 1.8338 (0.534 sec/step)\n",
            "I0517 10:00:19.554858 139851376510848 learning.py:507] global step 8048: loss = 1.8338 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8049: loss = 1.9868 (0.529 sec/step)\n",
            "I0517 10:00:20.085937 139851376510848 learning.py:507] global step 8049: loss = 1.9868 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8050: loss = 1.8046 (0.524 sec/step)\n",
            "I0517 10:00:20.611346 139851376510848 learning.py:507] global step 8050: loss = 1.8046 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8051: loss = 2.7864 (0.566 sec/step)\n",
            "I0517 10:00:21.178956 139851376510848 learning.py:507] global step 8051: loss = 2.7864 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8052: loss = 2.3584 (0.537 sec/step)\n",
            "I0517 10:00:21.718189 139851376510848 learning.py:507] global step 8052: loss = 2.3584 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8053: loss = 3.1394 (0.555 sec/step)\n",
            "I0517 10:00:22.275135 139851376510848 learning.py:507] global step 8053: loss = 3.1394 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8054: loss = 1.9602 (0.538 sec/step)\n",
            "I0517 10:00:22.814569 139851376510848 learning.py:507] global step 8054: loss = 1.9602 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8055: loss = 1.8421 (0.534 sec/step)\n",
            "I0517 10:00:23.349993 139851376510848 learning.py:507] global step 8055: loss = 1.8421 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8056: loss = 2.5404 (0.535 sec/step)\n",
            "I0517 10:00:23.886887 139851376510848 learning.py:507] global step 8056: loss = 2.5404 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8057: loss = 2.2030 (0.548 sec/step)\n",
            "I0517 10:00:24.436525 139851376510848 learning.py:507] global step 8057: loss = 2.2030 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8058: loss = 2.5050 (0.539 sec/step)\n",
            "I0517 10:00:24.976791 139851376510848 learning.py:507] global step 8058: loss = 2.5050 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8059: loss = 2.3882 (0.547 sec/step)\n",
            "I0517 10:00:25.525275 139851376510848 learning.py:507] global step 8059: loss = 2.3882 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8060: loss = 3.2241 (0.534 sec/step)\n",
            "I0517 10:00:26.061213 139851376510848 learning.py:507] global step 8060: loss = 3.2241 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8061: loss = 1.4993 (0.530 sec/step)\n",
            "I0517 10:00:26.592904 139851376510848 learning.py:507] global step 8061: loss = 1.4993 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8062: loss = 1.8218 (0.543 sec/step)\n",
            "I0517 10:00:27.139711 139851376510848 learning.py:507] global step 8062: loss = 1.8218 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8063: loss = 1.8429 (0.523 sec/step)\n",
            "I0517 10:00:27.666313 139851376510848 learning.py:507] global step 8063: loss = 1.8429 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 8064: loss = 2.3471 (0.539 sec/step)\n",
            "I0517 10:00:28.207170 139851376510848 learning.py:507] global step 8064: loss = 2.3471 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8065: loss = 2.3249 (0.530 sec/step)\n",
            "I0517 10:00:28.739552 139851376510848 learning.py:507] global step 8065: loss = 2.3249 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8066: loss = 1.8098 (0.548 sec/step)\n",
            "I0517 10:00:29.289934 139851376510848 learning.py:507] global step 8066: loss = 1.8098 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8067: loss = 1.8970 (0.532 sec/step)\n",
            "I0517 10:00:29.824120 139851376510848 learning.py:507] global step 8067: loss = 1.8970 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8068: loss = 2.0287 (0.551 sec/step)\n",
            "I0517 10:00:30.376649 139851376510848 learning.py:507] global step 8068: loss = 2.0287 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8069: loss = 1.5578 (0.569 sec/step)\n",
            "I0517 10:00:30.946977 139851376510848 learning.py:507] global step 8069: loss = 1.5578 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 8070: loss = 1.7469 (0.541 sec/step)\n",
            "I0517 10:00:31.489346 139851376510848 learning.py:507] global step 8070: loss = 1.7469 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8071: loss = 2.1582 (0.547 sec/step)\n",
            "I0517 10:00:32.038471 139851376510848 learning.py:507] global step 8071: loss = 2.1582 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8072: loss = 2.0486 (0.541 sec/step)\n",
            "I0517 10:00:32.581504 139851376510848 learning.py:507] global step 8072: loss = 2.0486 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8073: loss = 2.0495 (0.549 sec/step)\n",
            "I0517 10:00:33.132080 139851376510848 learning.py:507] global step 8073: loss = 2.0495 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8074: loss = 1.8007 (0.546 sec/step)\n",
            "I0517 10:00:33.680017 139851376510848 learning.py:507] global step 8074: loss = 1.8007 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8075: loss = 2.7878 (0.545 sec/step)\n",
            "I0517 10:00:34.226945 139851376510848 learning.py:507] global step 8075: loss = 2.7878 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8076: loss = 1.4033 (0.534 sec/step)\n",
            "I0517 10:00:34.763287 139851376510848 learning.py:507] global step 8076: loss = 1.4033 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8077: loss = 1.9978 (0.541 sec/step)\n",
            "I0517 10:00:35.306287 139851376510848 learning.py:507] global step 8077: loss = 1.9978 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8078: loss = 1.4381 (0.529 sec/step)\n",
            "I0517 10:00:35.836894 139851376510848 learning.py:507] global step 8078: loss = 1.4381 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8079: loss = 1.3361 (0.542 sec/step)\n",
            "I0517 10:00:36.381100 139851376510848 learning.py:507] global step 8079: loss = 1.3361 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8080: loss = 1.5297 (0.525 sec/step)\n",
            "I0517 10:00:36.907916 139851376510848 learning.py:507] global step 8080: loss = 1.5297 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 8081: loss = 1.6101 (0.538 sec/step)\n",
            "I0517 10:00:37.447880 139851376510848 learning.py:507] global step 8081: loss = 1.6101 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8082: loss = 1.7179 (0.555 sec/step)\n",
            "I0517 10:00:38.004772 139851376510848 learning.py:507] global step 8082: loss = 1.7179 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8083: loss = 1.5367 (0.556 sec/step)\n",
            "I0517 10:00:38.562685 139851376510848 learning.py:507] global step 8083: loss = 1.5367 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8084: loss = 1.7846 (0.504 sec/step)\n",
            "I0517 10:00:39.068143 139851376510848 learning.py:507] global step 8084: loss = 1.7846 (0.504 sec/step)\n",
            "INFO:tensorflow:global step 8085: loss = 1.4724 (0.546 sec/step)\n",
            "I0517 10:00:39.615864 139851376510848 learning.py:507] global step 8085: loss = 1.4724 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8086: loss = 1.4782 (0.539 sec/step)\n",
            "I0517 10:00:40.156569 139851376510848 learning.py:507] global step 8086: loss = 1.4782 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8087: loss = 1.8869 (0.545 sec/step)\n",
            "I0517 10:00:40.703776 139851376510848 learning.py:507] global step 8087: loss = 1.8869 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8088: loss = 2.0845 (0.540 sec/step)\n",
            "I0517 10:00:41.245159 139851376510848 learning.py:507] global step 8088: loss = 2.0845 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8089: loss = 2.1549 (0.533 sec/step)\n",
            "I0517 10:00:41.779601 139851376510848 learning.py:507] global step 8089: loss = 2.1549 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8090: loss = 1.8642 (0.564 sec/step)\n",
            "I0517 10:00:42.345970 139851376510848 learning.py:507] global step 8090: loss = 1.8642 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8091: loss = 2.0774 (0.554 sec/step)\n",
            "I0517 10:00:42.902099 139851376510848 learning.py:507] global step 8091: loss = 2.0774 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8092: loss = 1.5694 (0.521 sec/step)\n",
            "I0517 10:00:43.425264 139851376510848 learning.py:507] global step 8092: loss = 1.5694 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8093: loss = 1.6057 (0.555 sec/step)\n",
            "I0517 10:00:43.982239 139851376510848 learning.py:507] global step 8093: loss = 1.6057 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8094: loss = 2.0149 (0.537 sec/step)\n",
            "I0517 10:00:44.520668 139851376510848 learning.py:507] global step 8094: loss = 2.0149 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8095: loss = 2.0583 (0.544 sec/step)\n",
            "I0517 10:00:45.066798 139851376510848 learning.py:507] global step 8095: loss = 2.0583 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8096: loss = 2.0419 (0.578 sec/step)\n",
            "I0517 10:00:45.811163 139851376510848 learning.py:507] global step 8096: loss = 2.0419 (0.578 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8096.\n",
            "I0517 10:00:46.809526 139847641536256 supervisor.py:1050] Recording summary at step 8096.\n",
            "INFO:tensorflow:global step 8097: loss = 2.9508 (1.100 sec/step)\n",
            "I0517 10:00:46.914165 139851376510848 learning.py:507] global step 8097: loss = 2.9508 (1.100 sec/step)\n",
            "INFO:tensorflow:global step 8098: loss = 2.3134 (0.571 sec/step)\n",
            "I0517 10:00:47.486338 139851376510848 learning.py:507] global step 8098: loss = 2.3134 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8099: loss = 1.4772 (0.523 sec/step)\n",
            "I0517 10:00:48.012105 139851376510848 learning.py:507] global step 8099: loss = 1.4772 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 8100: loss = 2.4444 (0.575 sec/step)\n",
            "I0517 10:00:48.588626 139851376510848 learning.py:507] global step 8100: loss = 2.4444 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8101: loss = 3.3469 (0.542 sec/step)\n",
            "I0517 10:00:49.132625 139851376510848 learning.py:507] global step 8101: loss = 3.3469 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8102: loss = 1.4264 (0.542 sec/step)\n",
            "I0517 10:00:49.676844 139851376510848 learning.py:507] global step 8102: loss = 1.4264 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8103: loss = 2.2525 (0.516 sec/step)\n",
            "I0517 10:00:50.194673 139851376510848 learning.py:507] global step 8103: loss = 2.2525 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 8104: loss = 2.4298 (0.539 sec/step)\n",
            "I0517 10:00:50.735800 139851376510848 learning.py:507] global step 8104: loss = 2.4298 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8105: loss = 1.8924 (0.543 sec/step)\n",
            "I0517 10:00:51.280436 139851376510848 learning.py:507] global step 8105: loss = 1.8924 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8106: loss = 1.9266 (0.556 sec/step)\n",
            "I0517 10:00:51.838425 139851376510848 learning.py:507] global step 8106: loss = 1.9266 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8107: loss = 1.2622 (0.549 sec/step)\n",
            "I0517 10:00:52.388732 139851376510848 learning.py:507] global step 8107: loss = 1.2622 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8108: loss = 1.3814 (0.530 sec/step)\n",
            "I0517 10:00:52.920181 139851376510848 learning.py:507] global step 8108: loss = 1.3814 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8109: loss = 2.2918 (0.557 sec/step)\n",
            "I0517 10:00:53.479222 139851376510848 learning.py:507] global step 8109: loss = 2.2918 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8110: loss = 3.1661 (0.531 sec/step)\n",
            "I0517 10:00:54.011914 139851376510848 learning.py:507] global step 8110: loss = 3.1661 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8111: loss = 1.7798 (0.555 sec/step)\n",
            "I0517 10:00:54.569685 139851376510848 learning.py:507] global step 8111: loss = 1.7798 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8112: loss = 1.8908 (0.557 sec/step)\n",
            "I0517 10:00:55.128570 139851376510848 learning.py:507] global step 8112: loss = 1.8908 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8113: loss = 2.2346 (0.569 sec/step)\n",
            "I0517 10:00:55.699070 139851376510848 learning.py:507] global step 8113: loss = 2.2346 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 8114: loss = 2.6777 (0.570 sec/step)\n",
            "I0517 10:00:56.270763 139851376510848 learning.py:507] global step 8114: loss = 2.6777 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 8115: loss = 1.9157 (0.587 sec/step)\n",
            "I0517 10:00:56.859850 139851376510848 learning.py:507] global step 8115: loss = 1.9157 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 8116: loss = 1.7866 (0.544 sec/step)\n",
            "I0517 10:00:57.405632 139851376510848 learning.py:507] global step 8116: loss = 1.7866 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8117: loss = 2.0517 (0.589 sec/step)\n",
            "I0517 10:00:57.996049 139851376510848 learning.py:507] global step 8117: loss = 2.0517 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 8118: loss = 2.2457 (0.531 sec/step)\n",
            "I0517 10:00:58.528942 139851376510848 learning.py:507] global step 8118: loss = 2.2457 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8119: loss = 1.6131 (0.553 sec/step)\n",
            "I0517 10:00:59.083987 139851376510848 learning.py:507] global step 8119: loss = 1.6131 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8120: loss = 1.8274 (0.525 sec/step)\n",
            "I0517 10:00:59.610688 139851376510848 learning.py:507] global step 8120: loss = 1.8274 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 8121: loss = 2.0366 (0.536 sec/step)\n",
            "I0517 10:01:00.148401 139851376510848 learning.py:507] global step 8121: loss = 2.0366 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8122: loss = 2.2508 (0.550 sec/step)\n",
            "I0517 10:01:00.700140 139851376510848 learning.py:507] global step 8122: loss = 2.2508 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8123: loss = 1.9091 (0.537 sec/step)\n",
            "I0517 10:01:01.239250 139851376510848 learning.py:507] global step 8123: loss = 1.9091 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8124: loss = 3.4944 (0.571 sec/step)\n",
            "I0517 10:01:01.811602 139851376510848 learning.py:507] global step 8124: loss = 3.4944 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8125: loss = 2.1731 (0.530 sec/step)\n",
            "I0517 10:01:02.343666 139851376510848 learning.py:507] global step 8125: loss = 2.1731 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8126: loss = 1.8421 (0.571 sec/step)\n",
            "I0517 10:01:02.916207 139851376510848 learning.py:507] global step 8126: loss = 1.8421 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8127: loss = 1.9830 (0.527 sec/step)\n",
            "I0517 10:01:03.445314 139851376510848 learning.py:507] global step 8127: loss = 1.9830 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8128: loss = 2.0248 (0.563 sec/step)\n",
            "I0517 10:01:04.010110 139851376510848 learning.py:507] global step 8128: loss = 2.0248 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8129: loss = 1.8702 (0.553 sec/step)\n",
            "I0517 10:01:04.565387 139851376510848 learning.py:507] global step 8129: loss = 1.8702 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8130: loss = 2.6317 (0.550 sec/step)\n",
            "I0517 10:01:05.117000 139851376510848 learning.py:507] global step 8130: loss = 2.6317 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8131: loss = 2.5023 (0.571 sec/step)\n",
            "I0517 10:01:05.689539 139851376510848 learning.py:507] global step 8131: loss = 2.5023 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8132: loss = 1.2939 (0.577 sec/step)\n",
            "I0517 10:01:06.268436 139851376510848 learning.py:507] global step 8132: loss = 1.2939 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 8133: loss = 2.1445 (0.543 sec/step)\n",
            "I0517 10:01:06.813995 139851376510848 learning.py:507] global step 8133: loss = 2.1445 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8134: loss = 1.9250 (0.540 sec/step)\n",
            "I0517 10:01:07.355684 139851376510848 learning.py:507] global step 8134: loss = 1.9250 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8135: loss = 2.3036 (0.603 sec/step)\n",
            "I0517 10:01:07.959986 139851376510848 learning.py:507] global step 8135: loss = 2.3036 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 8136: loss = 1.7477 (0.529 sec/step)\n",
            "I0517 10:01:08.490242 139851376510848 learning.py:507] global step 8136: loss = 1.7477 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8137: loss = 2.0116 (0.536 sec/step)\n",
            "I0517 10:01:09.028192 139851376510848 learning.py:507] global step 8137: loss = 2.0116 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8138: loss = 1.7500 (0.540 sec/step)\n",
            "I0517 10:01:09.570107 139851376510848 learning.py:507] global step 8138: loss = 1.7500 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8139: loss = 1.8503 (0.566 sec/step)\n",
            "I0517 10:01:10.138909 139851376510848 learning.py:507] global step 8139: loss = 1.8503 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8140: loss = 2.1497 (0.548 sec/step)\n",
            "I0517 10:01:10.688798 139851376510848 learning.py:507] global step 8140: loss = 2.1497 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8141: loss = 1.4602 (0.576 sec/step)\n",
            "I0517 10:01:11.266730 139851376510848 learning.py:507] global step 8141: loss = 1.4602 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 8142: loss = 1.8436 (0.529 sec/step)\n",
            "I0517 10:01:11.797343 139851376510848 learning.py:507] global step 8142: loss = 1.8436 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8143: loss = 2.8034 (0.559 sec/step)\n",
            "I0517 10:01:12.358252 139851376510848 learning.py:507] global step 8143: loss = 2.8034 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8144: loss = 2.1194 (0.548 sec/step)\n",
            "I0517 10:01:12.910310 139851376510848 learning.py:507] global step 8144: loss = 2.1194 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8145: loss = 1.9469 (0.562 sec/step)\n",
            "I0517 10:01:13.474803 139851376510848 learning.py:507] global step 8145: loss = 1.9469 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 8146: loss = 1.6159 (0.535 sec/step)\n",
            "I0517 10:01:14.011527 139851376510848 learning.py:507] global step 8146: loss = 1.6159 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8147: loss = 1.2126 (0.534 sec/step)\n",
            "I0517 10:01:14.546887 139851376510848 learning.py:507] global step 8147: loss = 1.2126 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8148: loss = 1.3193 (0.554 sec/step)\n",
            "I0517 10:01:15.102403 139851376510848 learning.py:507] global step 8148: loss = 1.3193 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8149: loss = 2.3578 (0.525 sec/step)\n",
            "I0517 10:01:15.628981 139851376510848 learning.py:507] global step 8149: loss = 2.3578 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 8150: loss = 1.4706 (0.543 sec/step)\n",
            "I0517 10:01:16.173647 139851376510848 learning.py:507] global step 8150: loss = 1.4706 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8151: loss = 2.4057 (0.547 sec/step)\n",
            "I0517 10:01:16.722770 139851376510848 learning.py:507] global step 8151: loss = 2.4057 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8152: loss = 3.2591 (0.553 sec/step)\n",
            "I0517 10:01:17.277565 139851376510848 learning.py:507] global step 8152: loss = 3.2591 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8153: loss = 2.5460 (0.521 sec/step)\n",
            "I0517 10:01:17.800502 139851376510848 learning.py:507] global step 8153: loss = 2.5460 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8154: loss = 1.6583 (0.556 sec/step)\n",
            "I0517 10:01:18.358173 139851376510848 learning.py:507] global step 8154: loss = 1.6583 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8155: loss = 2.2982 (0.539 sec/step)\n",
            "I0517 10:01:18.899226 139851376510848 learning.py:507] global step 8155: loss = 2.2982 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8156: loss = 2.2833 (0.552 sec/step)\n",
            "I0517 10:01:19.452442 139851376510848 learning.py:507] global step 8156: loss = 2.2833 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8157: loss = 1.6067 (0.551 sec/step)\n",
            "I0517 10:01:20.004825 139851376510848 learning.py:507] global step 8157: loss = 1.6067 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8158: loss = 1.7630 (0.539 sec/step)\n",
            "I0517 10:01:20.545626 139851376510848 learning.py:507] global step 8158: loss = 1.7630 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8159: loss = 2.1277 (0.540 sec/step)\n",
            "I0517 10:01:21.087156 139851376510848 learning.py:507] global step 8159: loss = 2.1277 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8160: loss = 1.6055 (0.573 sec/step)\n",
            "I0517 10:01:21.662140 139851376510848 learning.py:507] global step 8160: loss = 1.6055 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 8161: loss = 3.2897 (0.577 sec/step)\n",
            "I0517 10:01:22.240783 139851376510848 learning.py:507] global step 8161: loss = 3.2897 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 8162: loss = 2.1587 (0.528 sec/step)\n",
            "I0517 10:01:22.770567 139851376510848 learning.py:507] global step 8162: loss = 2.1587 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8163: loss = 1.9631 (0.540 sec/step)\n",
            "I0517 10:01:23.311882 139851376510848 learning.py:507] global step 8163: loss = 1.9631 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8164: loss = 1.5280 (0.549 sec/step)\n",
            "I0517 10:01:23.862943 139851376510848 learning.py:507] global step 8164: loss = 1.5280 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8165: loss = 1.6532 (0.541 sec/step)\n",
            "I0517 10:01:24.405743 139851376510848 learning.py:507] global step 8165: loss = 1.6532 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8166: loss = 1.9130 (0.530 sec/step)\n",
            "I0517 10:01:24.937203 139851376510848 learning.py:507] global step 8166: loss = 1.9130 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8167: loss = 2.4550 (0.552 sec/step)\n",
            "I0517 10:01:25.490818 139851376510848 learning.py:507] global step 8167: loss = 2.4550 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8168: loss = 1.7933 (0.530 sec/step)\n",
            "I0517 10:01:26.022498 139851376510848 learning.py:507] global step 8168: loss = 1.7933 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8169: loss = 1.6011 (0.580 sec/step)\n",
            "I0517 10:01:26.604594 139851376510848 learning.py:507] global step 8169: loss = 1.6011 (0.580 sec/step)\n",
            "INFO:tensorflow:global step 8170: loss = 1.6331 (0.560 sec/step)\n",
            "I0517 10:01:27.166539 139851376510848 learning.py:507] global step 8170: loss = 1.6331 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8171: loss = 2.5688 (0.538 sec/step)\n",
            "I0517 10:01:27.706890 139851376510848 learning.py:507] global step 8171: loss = 2.5688 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8172: loss = 2.3791 (0.541 sec/step)\n",
            "I0517 10:01:28.250324 139851376510848 learning.py:507] global step 8172: loss = 2.3791 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8173: loss = 2.0900 (0.574 sec/step)\n",
            "I0517 10:01:28.826335 139851376510848 learning.py:507] global step 8173: loss = 2.0900 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 8174: loss = 2.8877 (0.574 sec/step)\n",
            "I0517 10:01:29.403813 139851376510848 learning.py:507] global step 8174: loss = 2.8877 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 8175: loss = 2.1294 (0.553 sec/step)\n",
            "I0517 10:01:29.960874 139851376510848 learning.py:507] global step 8175: loss = 2.1294 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8176: loss = 1.7102 (0.557 sec/step)\n",
            "I0517 10:01:30.519875 139851376510848 learning.py:507] global step 8176: loss = 1.7102 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8177: loss = 1.8918 (0.564 sec/step)\n",
            "I0517 10:01:31.085630 139851376510848 learning.py:507] global step 8177: loss = 1.8918 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8178: loss = 1.8949 (0.545 sec/step)\n",
            "I0517 10:01:31.632384 139851376510848 learning.py:507] global step 8178: loss = 1.8949 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8179: loss = 1.8193 (0.531 sec/step)\n",
            "I0517 10:01:32.165604 139851376510848 learning.py:507] global step 8179: loss = 1.8193 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8180: loss = 1.7123 (0.537 sec/step)\n",
            "I0517 10:01:32.704896 139851376510848 learning.py:507] global step 8180: loss = 1.7123 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8181: loss = 2.3352 (0.540 sec/step)\n",
            "I0517 10:01:33.246356 139851376510848 learning.py:507] global step 8181: loss = 2.3352 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8182: loss = 1.7461 (0.549 sec/step)\n",
            "I0517 10:01:33.797270 139851376510848 learning.py:507] global step 8182: loss = 1.7461 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8183: loss = 2.0664 (0.531 sec/step)\n",
            "I0517 10:01:34.329605 139851376510848 learning.py:507] global step 8183: loss = 2.0664 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8184: loss = 1.4090 (0.546 sec/step)\n",
            "I0517 10:01:34.877753 139851376510848 learning.py:507] global step 8184: loss = 1.4090 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8185: loss = 1.9137 (0.527 sec/step)\n",
            "I0517 10:01:35.406373 139851376510848 learning.py:507] global step 8185: loss = 1.9137 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8186: loss = 2.9027 (0.565 sec/step)\n",
            "I0517 10:01:35.973409 139851376510848 learning.py:507] global step 8186: loss = 2.9027 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8187: loss = 1.8420 (0.545 sec/step)\n",
            "I0517 10:01:36.520472 139851376510848 learning.py:507] global step 8187: loss = 1.8420 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8188: loss = 1.9367 (0.554 sec/step)\n",
            "I0517 10:01:37.075991 139851376510848 learning.py:507] global step 8188: loss = 1.9367 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8189: loss = 2.0320 (0.565 sec/step)\n",
            "I0517 10:01:37.643296 139851376510848 learning.py:507] global step 8189: loss = 2.0320 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8190: loss = 2.0390 (0.542 sec/step)\n",
            "I0517 10:01:38.187077 139851376510848 learning.py:507] global step 8190: loss = 2.0390 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8191: loss = 2.0118 (0.541 sec/step)\n",
            "I0517 10:01:38.729821 139851376510848 learning.py:507] global step 8191: loss = 2.0118 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8192: loss = 1.3550 (0.524 sec/step)\n",
            "I0517 10:01:39.255809 139851376510848 learning.py:507] global step 8192: loss = 1.3550 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8193: loss = 1.7839 (0.566 sec/step)\n",
            "I0517 10:01:39.825088 139851376510848 learning.py:507] global step 8193: loss = 1.7839 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8194: loss = 1.8470 (0.566 sec/step)\n",
            "I0517 10:01:40.393519 139851376510848 learning.py:507] global step 8194: loss = 1.8470 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8195: loss = 2.2084 (0.547 sec/step)\n",
            "I0517 10:01:40.942150 139851376510848 learning.py:507] global step 8195: loss = 2.2084 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8196: loss = 1.6391 (0.538 sec/step)\n",
            "I0517 10:01:41.481728 139851376510848 learning.py:507] global step 8196: loss = 1.6391 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8197: loss = 1.8470 (0.542 sec/step)\n",
            "I0517 10:01:42.025888 139851376510848 learning.py:507] global step 8197: loss = 1.8470 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8198: loss = 1.3837 (0.565 sec/step)\n",
            "I0517 10:01:42.592214 139851376510848 learning.py:507] global step 8198: loss = 1.3837 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8199: loss = 1.5008 (0.572 sec/step)\n",
            "I0517 10:01:43.165945 139851376510848 learning.py:507] global step 8199: loss = 1.5008 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 8200: loss = 1.7497 (0.552 sec/step)\n",
            "I0517 10:01:43.719422 139851376510848 learning.py:507] global step 8200: loss = 1.7497 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8201: loss = 1.3338 (0.578 sec/step)\n",
            "I0517 10:01:44.299255 139851376510848 learning.py:507] global step 8201: loss = 1.3338 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 8202: loss = 2.1256 (0.541 sec/step)\n",
            "I0517 10:01:44.841908 139851376510848 learning.py:507] global step 8202: loss = 2.1256 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8203: loss = 1.9959 (0.521 sec/step)\n",
            "I0517 10:01:45.364208 139851376510848 learning.py:507] global step 8203: loss = 1.9959 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8204: loss = 2.2018 (0.593 sec/step)\n",
            "I0517 10:01:45.959201 139851376510848 learning.py:507] global step 8204: loss = 2.2018 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 8205: loss = 1.9142 (0.540 sec/step)\n",
            "I0517 10:01:46.500454 139851376510848 learning.py:507] global step 8205: loss = 1.9142 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8206: loss = 1.2116 (0.554 sec/step)\n",
            "I0517 10:01:47.055714 139851376510848 learning.py:507] global step 8206: loss = 1.2116 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8207: loss = 2.3728 (0.560 sec/step)\n",
            "I0517 10:01:47.617464 139851376510848 learning.py:507] global step 8207: loss = 2.3728 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8208: loss = 2.0107 (0.565 sec/step)\n",
            "I0517 10:01:48.184641 139851376510848 learning.py:507] global step 8208: loss = 2.0107 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8209: loss = 1.7067 (0.538 sec/step)\n",
            "I0517 10:01:48.724698 139851376510848 learning.py:507] global step 8209: loss = 1.7067 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8210: loss = 1.9786 (0.550 sec/step)\n",
            "I0517 10:01:49.276641 139851376510848 learning.py:507] global step 8210: loss = 1.9786 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8211: loss = 1.4387 (0.577 sec/step)\n",
            "I0517 10:01:49.855698 139851376510848 learning.py:507] global step 8211: loss = 1.4387 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 8212: loss = 1.9412 (0.544 sec/step)\n",
            "I0517 10:01:50.401565 139851376510848 learning.py:507] global step 8212: loss = 1.9412 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8213: loss = 2.1146 (0.528 sec/step)\n",
            "I0517 10:01:50.931454 139851376510848 learning.py:507] global step 8213: loss = 2.1146 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8214: loss = 2.3813 (0.528 sec/step)\n",
            "I0517 10:01:51.461310 139851376510848 learning.py:507] global step 8214: loss = 2.3813 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8215: loss = 2.9117 (0.546 sec/step)\n",
            "I0517 10:01:52.010395 139851376510848 learning.py:507] global step 8215: loss = 2.9117 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8216: loss = 2.1108 (0.526 sec/step)\n",
            "I0517 10:01:52.539245 139851376510848 learning.py:507] global step 8216: loss = 2.1108 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8217: loss = 1.4802 (0.556 sec/step)\n",
            "I0517 10:01:53.096946 139851376510848 learning.py:507] global step 8217: loss = 1.4802 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8218: loss = 1.8599 (0.566 sec/step)\n",
            "I0517 10:01:53.666224 139851376510848 learning.py:507] global step 8218: loss = 1.8599 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8219: loss = 1.5595 (0.566 sec/step)\n",
            "I0517 10:01:54.234285 139851376510848 learning.py:507] global step 8219: loss = 1.5595 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8220: loss = 1.6816 (0.544 sec/step)\n",
            "I0517 10:01:54.779632 139851376510848 learning.py:507] global step 8220: loss = 1.6816 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8221: loss = 2.5903 (0.575 sec/step)\n",
            "I0517 10:01:55.356059 139851376510848 learning.py:507] global step 8221: loss = 2.5903 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8222: loss = 1.5978 (0.546 sec/step)\n",
            "I0517 10:01:55.903852 139851376510848 learning.py:507] global step 8222: loss = 1.5978 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8223: loss = 2.1361 (0.558 sec/step)\n",
            "I0517 10:01:56.463678 139851376510848 learning.py:507] global step 8223: loss = 2.1361 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 8224: loss = 2.2881 (0.565 sec/step)\n",
            "I0517 10:01:57.030695 139851376510848 learning.py:507] global step 8224: loss = 2.2881 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8225: loss = 1.5623 (0.543 sec/step)\n",
            "I0517 10:01:57.575167 139851376510848 learning.py:507] global step 8225: loss = 1.5623 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8226: loss = 2.0894 (0.538 sec/step)\n",
            "I0517 10:01:58.115072 139851376510848 learning.py:507] global step 8226: loss = 2.0894 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8227: loss = 1.3349 (0.546 sec/step)\n",
            "I0517 10:01:58.662657 139851376510848 learning.py:507] global step 8227: loss = 1.3349 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8228: loss = 1.1619 (0.566 sec/step)\n",
            "I0517 10:01:59.232548 139851376510848 learning.py:507] global step 8228: loss = 1.1619 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8229: loss = 1.7547 (0.545 sec/step)\n",
            "I0517 10:01:59.779730 139851376510848 learning.py:507] global step 8229: loss = 1.7547 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8230: loss = 1.4966 (0.526 sec/step)\n",
            "I0517 10:02:00.307299 139851376510848 learning.py:507] global step 8230: loss = 1.4966 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8231: loss = 1.6577 (0.524 sec/step)\n",
            "I0517 10:02:00.833947 139851376510848 learning.py:507] global step 8231: loss = 1.6577 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8232: loss = 1.2448 (0.551 sec/step)\n",
            "I0517 10:02:01.386954 139851376510848 learning.py:507] global step 8232: loss = 1.2448 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8233: loss = 1.5778 (0.549 sec/step)\n",
            "I0517 10:02:01.938404 139851376510848 learning.py:507] global step 8233: loss = 1.5778 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8234: loss = 1.8143 (0.568 sec/step)\n",
            "I0517 10:02:02.507804 139851376510848 learning.py:507] global step 8234: loss = 1.8143 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 8235: loss = 1.7586 (0.528 sec/step)\n",
            "I0517 10:02:03.037364 139851376510848 learning.py:507] global step 8235: loss = 1.7586 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8236: loss = 1.7968 (0.521 sec/step)\n",
            "I0517 10:02:03.560650 139851376510848 learning.py:507] global step 8236: loss = 1.7968 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8237: loss = 1.5183 (0.542 sec/step)\n",
            "I0517 10:02:04.104232 139851376510848 learning.py:507] global step 8237: loss = 1.5183 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8238: loss = 2.8839 (0.554 sec/step)\n",
            "I0517 10:02:04.659706 139851376510848 learning.py:507] global step 8238: loss = 2.8839 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8239: loss = 1.6927 (0.553 sec/step)\n",
            "I0517 10:02:05.214251 139851376510848 learning.py:507] global step 8239: loss = 1.6927 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8240: loss = 1.6281 (0.527 sec/step)\n",
            "I0517 10:02:05.744257 139851376510848 learning.py:507] global step 8240: loss = 1.6281 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8241: loss = 1.7160 (0.520 sec/step)\n",
            "I0517 10:02:06.266082 139851376510848 learning.py:507] global step 8241: loss = 1.7160 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 8242: loss = 2.3236 (0.548 sec/step)\n",
            "I0517 10:02:06.815480 139851376510848 learning.py:507] global step 8242: loss = 2.3236 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8243: loss = 1.6679 (0.534 sec/step)\n",
            "I0517 10:02:07.350998 139851376510848 learning.py:507] global step 8243: loss = 1.6679 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8244: loss = 2.9873 (0.578 sec/step)\n",
            "I0517 10:02:07.930651 139851376510848 learning.py:507] global step 8244: loss = 2.9873 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 8245: loss = 2.0993 (0.555 sec/step)\n",
            "I0517 10:02:08.487497 139851376510848 learning.py:507] global step 8245: loss = 2.0993 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8246: loss = 1.8344 (0.551 sec/step)\n",
            "I0517 10:02:09.041079 139851376510848 learning.py:507] global step 8246: loss = 1.8344 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8247: loss = 2.5062 (0.562 sec/step)\n",
            "I0517 10:02:09.604632 139851376510848 learning.py:507] global step 8247: loss = 2.5062 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 8248: loss = 2.0022 (0.536 sec/step)\n",
            "I0517 10:02:10.143418 139851376510848 learning.py:507] global step 8248: loss = 2.0022 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8249: loss = 1.9385 (0.543 sec/step)\n",
            "I0517 10:02:10.688190 139851376510848 learning.py:507] global step 8249: loss = 1.9385 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8250: loss = 2.2163 (0.549 sec/step)\n",
            "I0517 10:02:11.239116 139851376510848 learning.py:507] global step 8250: loss = 2.2163 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8251: loss = 1.6925 (0.544 sec/step)\n",
            "I0517 10:02:11.786092 139851376510848 learning.py:507] global step 8251: loss = 1.6925 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8252: loss = 1.9545 (0.555 sec/step)\n",
            "I0517 10:02:12.342685 139851376510848 learning.py:507] global step 8252: loss = 1.9545 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8253: loss = 1.5417 (0.537 sec/step)\n",
            "I0517 10:02:12.881260 139851376510848 learning.py:507] global step 8253: loss = 1.5417 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8254: loss = 1.5737 (0.516 sec/step)\n",
            "I0517 10:02:13.399445 139851376510848 learning.py:507] global step 8254: loss = 1.5737 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 8255: loss = 1.4420 (0.556 sec/step)\n",
            "I0517 10:02:13.957227 139851376510848 learning.py:507] global step 8255: loss = 1.4420 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8256: loss = 2.4644 (0.520 sec/step)\n",
            "I0517 10:02:14.478562 139851376510848 learning.py:507] global step 8256: loss = 2.4644 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 8257: loss = 2.3663 (0.546 sec/step)\n",
            "I0517 10:02:15.026532 139851376510848 learning.py:507] global step 8257: loss = 2.3663 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8258: loss = 1.9261 (0.529 sec/step)\n",
            "I0517 10:02:15.557546 139851376510848 learning.py:507] global step 8258: loss = 1.9261 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8259: loss = 1.6515 (0.553 sec/step)\n",
            "I0517 10:02:16.112266 139851376510848 learning.py:507] global step 8259: loss = 1.6515 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8260: loss = 1.7963 (0.531 sec/step)\n",
            "I0517 10:02:16.645364 139851376510848 learning.py:507] global step 8260: loss = 1.7963 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8261: loss = 2.1627 (0.552 sec/step)\n",
            "I0517 10:02:17.199079 139851376510848 learning.py:507] global step 8261: loss = 2.1627 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8262: loss = 2.0322 (0.610 sec/step)\n",
            "I0517 10:02:17.810700 139851376510848 learning.py:507] global step 8262: loss = 2.0322 (0.610 sec/step)\n",
            "INFO:tensorflow:global step 8263: loss = 1.3375 (0.536 sec/step)\n",
            "I0517 10:02:18.348684 139851376510848 learning.py:507] global step 8263: loss = 1.3375 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8264: loss = 1.5267 (0.524 sec/step)\n",
            "I0517 10:02:18.874268 139851376510848 learning.py:507] global step 8264: loss = 1.5267 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8265: loss = 2.1058 (0.549 sec/step)\n",
            "I0517 10:02:19.424888 139851376510848 learning.py:507] global step 8265: loss = 2.1058 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8266: loss = 1.5560 (0.570 sec/step)\n",
            "I0517 10:02:19.997156 139851376510848 learning.py:507] global step 8266: loss = 1.5560 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 8267: loss = 1.7879 (0.557 sec/step)\n",
            "I0517 10:02:20.555336 139851376510848 learning.py:507] global step 8267: loss = 1.7879 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8268: loss = 1.9138 (0.551 sec/step)\n",
            "I0517 10:02:21.108653 139851376510848 learning.py:507] global step 8268: loss = 1.9138 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8269: loss = 1.6776 (0.533 sec/step)\n",
            "I0517 10:02:21.643393 139851376510848 learning.py:507] global step 8269: loss = 1.6776 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8270: loss = 1.7421 (0.537 sec/step)\n",
            "I0517 10:02:22.182996 139851376510848 learning.py:507] global step 8270: loss = 1.7421 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8271: loss = 2.1423 (0.550 sec/step)\n",
            "I0517 10:02:22.735527 139851376510848 learning.py:507] global step 8271: loss = 2.1423 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8272: loss = 2.0296 (0.546 sec/step)\n",
            "I0517 10:02:23.283451 139851376510848 learning.py:507] global step 8272: loss = 2.0296 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8273: loss = 1.7556 (0.534 sec/step)\n",
            "I0517 10:02:23.820442 139851376510848 learning.py:507] global step 8273: loss = 1.7556 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8274: loss = 1.9885 (0.533 sec/step)\n",
            "I0517 10:02:24.355532 139851376510848 learning.py:507] global step 8274: loss = 1.9885 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8275: loss = 2.7072 (0.538 sec/step)\n",
            "I0517 10:02:24.895723 139851376510848 learning.py:507] global step 8275: loss = 2.7072 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8276: loss = 1.8712 (0.557 sec/step)\n",
            "I0517 10:02:25.455113 139851376510848 learning.py:507] global step 8276: loss = 1.8712 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8277: loss = 1.2990 (0.534 sec/step)\n",
            "I0517 10:02:25.991012 139851376510848 learning.py:507] global step 8277: loss = 1.2990 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8278: loss = 1.6773 (0.543 sec/step)\n",
            "I0517 10:02:26.535387 139851376510848 learning.py:507] global step 8278: loss = 1.6773 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8279: loss = 3.0960 (0.562 sec/step)\n",
            "I0517 10:02:27.099666 139851376510848 learning.py:507] global step 8279: loss = 3.0960 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 8280: loss = 1.4257 (0.557 sec/step)\n",
            "I0517 10:02:27.658585 139851376510848 learning.py:507] global step 8280: loss = 1.4257 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8281: loss = 1.7175 (0.564 sec/step)\n",
            "I0517 10:02:28.224295 139851376510848 learning.py:507] global step 8281: loss = 1.7175 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8282: loss = 1.8600 (0.560 sec/step)\n",
            "I0517 10:02:28.785871 139851376510848 learning.py:507] global step 8282: loss = 1.8600 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8283: loss = 1.6671 (0.539 sec/step)\n",
            "I0517 10:02:29.326965 139851376510848 learning.py:507] global step 8283: loss = 1.6671 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8284: loss = 1.9357 (0.532 sec/step)\n",
            "I0517 10:02:29.860757 139851376510848 learning.py:507] global step 8284: loss = 1.9357 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8285: loss = 1.5679 (0.569 sec/step)\n",
            "I0517 10:02:30.431469 139851376510848 learning.py:507] global step 8285: loss = 1.5679 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 8286: loss = 1.5321 (0.522 sec/step)\n",
            "I0517 10:02:30.956746 139851376510848 learning.py:507] global step 8286: loss = 1.5321 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 8287: loss = 2.0566 (0.563 sec/step)\n",
            "I0517 10:02:31.521602 139851376510848 learning.py:507] global step 8287: loss = 2.0566 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8288: loss = 1.5489 (0.536 sec/step)\n",
            "I0517 10:02:32.059159 139851376510848 learning.py:507] global step 8288: loss = 1.5489 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8289: loss = 1.8797 (0.571 sec/step)\n",
            "I0517 10:02:32.632475 139851376510848 learning.py:507] global step 8289: loss = 1.8797 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8290: loss = 2.7508 (0.542 sec/step)\n",
            "I0517 10:02:33.177583 139851376510848 learning.py:507] global step 8290: loss = 2.7508 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8291: loss = 2.1925 (0.536 sec/step)\n",
            "I0517 10:02:33.717020 139851376510848 learning.py:507] global step 8291: loss = 2.1925 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8292: loss = 1.6566 (0.528 sec/step)\n",
            "I0517 10:02:34.247265 139851376510848 learning.py:507] global step 8292: loss = 1.6566 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8293: loss = 1.9548 (0.538 sec/step)\n",
            "I0517 10:02:34.787051 139851376510848 learning.py:507] global step 8293: loss = 1.9548 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8294: loss = 2.0204 (0.548 sec/step)\n",
            "I0517 10:02:35.336745 139851376510848 learning.py:507] global step 8294: loss = 2.0204 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8295: loss = 1.9408 (0.547 sec/step)\n",
            "I0517 10:02:35.886278 139851376510848 learning.py:507] global step 8295: loss = 1.9408 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8296: loss = 2.8435 (0.553 sec/step)\n",
            "I0517 10:02:36.440741 139851376510848 learning.py:507] global step 8296: loss = 2.8435 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8297: loss = 1.9195 (0.546 sec/step)\n",
            "I0517 10:02:36.988894 139851376510848 learning.py:507] global step 8297: loss = 1.9195 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8298: loss = 2.3989 (0.559 sec/step)\n",
            "I0517 10:02:37.549581 139851376510848 learning.py:507] global step 8298: loss = 2.3989 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8299: loss = 1.6499 (0.549 sec/step)\n",
            "I0517 10:02:38.100665 139851376510848 learning.py:507] global step 8299: loss = 1.6499 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8300: loss = 1.7250 (0.559 sec/step)\n",
            "I0517 10:02:38.661514 139851376510848 learning.py:507] global step 8300: loss = 1.7250 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8301: loss = 1.4497 (0.529 sec/step)\n",
            "I0517 10:02:39.192019 139851376510848 learning.py:507] global step 8301: loss = 1.4497 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8302: loss = 1.6514 (0.565 sec/step)\n",
            "I0517 10:02:39.758546 139851376510848 learning.py:507] global step 8302: loss = 1.6514 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8303: loss = 1.8761 (0.536 sec/step)\n",
            "I0517 10:02:40.296632 139851376510848 learning.py:507] global step 8303: loss = 1.8761 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8304: loss = 1.5668 (0.560 sec/step)\n",
            "I0517 10:02:40.858664 139851376510848 learning.py:507] global step 8304: loss = 1.5668 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8305: loss = 2.0655 (0.532 sec/step)\n",
            "I0517 10:02:41.392415 139851376510848 learning.py:507] global step 8305: loss = 2.0655 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8306: loss = 1.3952 (0.540 sec/step)\n",
            "I0517 10:02:41.933925 139851376510848 learning.py:507] global step 8306: loss = 1.3952 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8307: loss = 1.8518 (0.551 sec/step)\n",
            "I0517 10:02:42.486376 139851376510848 learning.py:507] global step 8307: loss = 1.8518 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8308: loss = 1.8684 (0.531 sec/step)\n",
            "I0517 10:02:43.018803 139851376510848 learning.py:507] global step 8308: loss = 1.8684 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8309: loss = 2.2205 (0.546 sec/step)\n",
            "I0517 10:02:43.566584 139851376510848 learning.py:507] global step 8309: loss = 2.2205 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8310: loss = 1.7243 (0.548 sec/step)\n",
            "I0517 10:02:44.116403 139851376510848 learning.py:507] global step 8310: loss = 1.7243 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8311: loss = 2.0497 (0.543 sec/step)\n",
            "I0517 10:02:44.660480 139851376510848 learning.py:507] global step 8311: loss = 2.0497 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8312: loss = 1.5267 (0.544 sec/step)\n",
            "I0517 10:02:45.205775 139851376510848 learning.py:507] global step 8312: loss = 1.5267 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8313: loss = 2.4876 (0.617 sec/step)\n",
            "I0517 10:02:46.012411 139851376510848 learning.py:507] global step 8313: loss = 2.4876 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 8314: loss = 1.5780 (1.020 sec/step)\n",
            "I0517 10:02:47.034797 139851376510848 learning.py:507] global step 8314: loss = 1.5780 (1.020 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8314.\n",
            "I0517 10:02:47.038265 139847641536256 supervisor.py:1050] Recording summary at step 8314.\n",
            "INFO:tensorflow:global step 8315: loss = 1.4514 (0.547 sec/step)\n",
            "I0517 10:02:47.585499 139851376510848 learning.py:507] global step 8315: loss = 1.4514 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8316: loss = 1.9925 (0.564 sec/step)\n",
            "I0517 10:02:48.150898 139851376510848 learning.py:507] global step 8316: loss = 1.9925 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8317: loss = 2.0205 (0.548 sec/step)\n",
            "I0517 10:02:48.701219 139851376510848 learning.py:507] global step 8317: loss = 2.0205 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8318: loss = 2.9271 (0.535 sec/step)\n",
            "I0517 10:02:49.239403 139851376510848 learning.py:507] global step 8318: loss = 2.9271 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8319: loss = 1.9266 (0.553 sec/step)\n",
            "I0517 10:02:49.793916 139851376510848 learning.py:507] global step 8319: loss = 1.9266 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8320: loss = 1.6328 (0.563 sec/step)\n",
            "I0517 10:02:50.358888 139851376510848 learning.py:507] global step 8320: loss = 1.6328 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8321: loss = 2.2906 (0.597 sec/step)\n",
            "I0517 10:02:50.957852 139851376510848 learning.py:507] global step 8321: loss = 2.2906 (0.597 sec/step)\n",
            "INFO:tensorflow:global step 8322: loss = 1.5409 (0.524 sec/step)\n",
            "I0517 10:02:51.483592 139851376510848 learning.py:507] global step 8322: loss = 1.5409 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8323: loss = 2.4257 (0.548 sec/step)\n",
            "I0517 10:02:52.033491 139851376510848 learning.py:507] global step 8323: loss = 2.4257 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8324: loss = 2.1189 (0.549 sec/step)\n",
            "I0517 10:02:52.584181 139851376510848 learning.py:507] global step 8324: loss = 2.1189 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8325: loss = 2.0952 (0.603 sec/step)\n",
            "I0517 10:02:53.188985 139851376510848 learning.py:507] global step 8325: loss = 2.0952 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 8326: loss = 1.3381 (0.547 sec/step)\n",
            "I0517 10:02:53.737160 139851376510848 learning.py:507] global step 8326: loss = 1.3381 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8327: loss = 1.7381 (0.566 sec/step)\n",
            "I0517 10:02:54.304816 139851376510848 learning.py:507] global step 8327: loss = 1.7381 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8328: loss = 2.7807 (0.561 sec/step)\n",
            "I0517 10:02:54.866962 139851376510848 learning.py:507] global step 8328: loss = 2.7807 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8329: loss = 3.3384 (0.526 sec/step)\n",
            "I0517 10:02:55.394848 139851376510848 learning.py:507] global step 8329: loss = 3.3384 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8330: loss = 2.1154 (0.533 sec/step)\n",
            "I0517 10:02:55.931065 139851376510848 learning.py:507] global step 8330: loss = 2.1154 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8331: loss = 1.4671 (0.531 sec/step)\n",
            "I0517 10:02:56.463793 139851376510848 learning.py:507] global step 8331: loss = 1.4671 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8332: loss = 1.5352 (0.558 sec/step)\n",
            "I0517 10:02:57.022958 139851376510848 learning.py:507] global step 8332: loss = 1.5352 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 8333: loss = 3.6646 (0.525 sec/step)\n",
            "I0517 10:02:57.551291 139851376510848 learning.py:507] global step 8333: loss = 3.6646 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 8334: loss = 1.5638 (0.526 sec/step)\n",
            "I0517 10:02:58.079783 139851376510848 learning.py:507] global step 8334: loss = 1.5638 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8335: loss = 1.3883 (0.544 sec/step)\n",
            "I0517 10:02:58.626898 139851376510848 learning.py:507] global step 8335: loss = 1.3883 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8336: loss = 1.5844 (0.540 sec/step)\n",
            "I0517 10:02:59.169175 139851376510848 learning.py:507] global step 8336: loss = 1.5844 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8337: loss = 2.2316 (0.526 sec/step)\n",
            "I0517 10:02:59.697113 139851376510848 learning.py:507] global step 8337: loss = 2.2316 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8338: loss = 2.0224 (0.546 sec/step)\n",
            "I0517 10:03:00.245001 139851376510848 learning.py:507] global step 8338: loss = 2.0224 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8339: loss = 1.8346 (0.538 sec/step)\n",
            "I0517 10:03:00.784500 139851376510848 learning.py:507] global step 8339: loss = 1.8346 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8340: loss = 2.0415 (0.559 sec/step)\n",
            "I0517 10:03:01.345163 139851376510848 learning.py:507] global step 8340: loss = 2.0415 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8341: loss = 2.1284 (0.532 sec/step)\n",
            "I0517 10:03:01.878732 139851376510848 learning.py:507] global step 8341: loss = 2.1284 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8342: loss = 2.0620 (0.543 sec/step)\n",
            "I0517 10:03:02.423771 139851376510848 learning.py:507] global step 8342: loss = 2.0620 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8343: loss = 1.4659 (0.527 sec/step)\n",
            "I0517 10:03:02.952006 139851376510848 learning.py:507] global step 8343: loss = 1.4659 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8344: loss = 2.8632 (0.534 sec/step)\n",
            "I0517 10:03:03.487519 139851376510848 learning.py:507] global step 8344: loss = 2.8632 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8345: loss = 2.0891 (0.521 sec/step)\n",
            "I0517 10:03:04.010120 139851376510848 learning.py:507] global step 8345: loss = 2.0891 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8346: loss = 1.9789 (0.557 sec/step)\n",
            "I0517 10:03:04.568361 139851376510848 learning.py:507] global step 8346: loss = 1.9789 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8347: loss = 1.9596 (0.551 sec/step)\n",
            "I0517 10:03:05.121271 139851376510848 learning.py:507] global step 8347: loss = 1.9596 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8348: loss = 1.9522 (0.526 sec/step)\n",
            "I0517 10:03:05.649991 139851376510848 learning.py:507] global step 8348: loss = 1.9522 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8349: loss = 2.5745 (0.541 sec/step)\n",
            "I0517 10:03:06.193092 139851376510848 learning.py:507] global step 8349: loss = 2.5745 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8350: loss = 1.8730 (0.536 sec/step)\n",
            "I0517 10:03:06.730501 139851376510848 learning.py:507] global step 8350: loss = 1.8730 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8351: loss = 1.8522 (0.563 sec/step)\n",
            "I0517 10:03:07.295382 139851376510848 learning.py:507] global step 8351: loss = 1.8522 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8352: loss = 1.9050 (0.527 sec/step)\n",
            "I0517 10:03:07.824397 139851376510848 learning.py:507] global step 8352: loss = 1.9050 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8353: loss = 2.2203 (0.548 sec/step)\n",
            "I0517 10:03:08.374296 139851376510848 learning.py:507] global step 8353: loss = 2.2203 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8354: loss = 2.5818 (0.527 sec/step)\n",
            "I0517 10:03:08.903357 139851376510848 learning.py:507] global step 8354: loss = 2.5818 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 8355: loss = 1.9010 (0.543 sec/step)\n",
            "I0517 10:03:09.447741 139851376510848 learning.py:507] global step 8355: loss = 1.9010 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8356: loss = 1.6003 (0.563 sec/step)\n",
            "I0517 10:03:10.012825 139851376510848 learning.py:507] global step 8356: loss = 1.6003 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8357: loss = 1.9149 (0.536 sec/step)\n",
            "I0517 10:03:10.550574 139851376510848 learning.py:507] global step 8357: loss = 1.9149 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8358: loss = 3.1497 (0.529 sec/step)\n",
            "I0517 10:03:11.081764 139851376510848 learning.py:507] global step 8358: loss = 3.1497 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8359: loss = 2.3775 (0.561 sec/step)\n",
            "I0517 10:03:11.644142 139851376510848 learning.py:507] global step 8359: loss = 2.3775 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8360: loss = 2.1151 (0.543 sec/step)\n",
            "I0517 10:03:12.189581 139851376510848 learning.py:507] global step 8360: loss = 2.1151 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8361: loss = 1.5617 (0.539 sec/step)\n",
            "I0517 10:03:12.730459 139851376510848 learning.py:507] global step 8361: loss = 1.5617 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8362: loss = 2.0704 (0.543 sec/step)\n",
            "I0517 10:03:13.276082 139851376510848 learning.py:507] global step 8362: loss = 2.0704 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8363: loss = 2.3281 (0.533 sec/step)\n",
            "I0517 10:03:13.811342 139851376510848 learning.py:507] global step 8363: loss = 2.3281 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8364: loss = 1.4897 (0.536 sec/step)\n",
            "I0517 10:03:14.348892 139851376510848 learning.py:507] global step 8364: loss = 1.4897 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8365: loss = 1.6129 (0.522 sec/step)\n",
            "I0517 10:03:14.872854 139851376510848 learning.py:507] global step 8365: loss = 1.6129 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 8366: loss = 2.0749 (0.539 sec/step)\n",
            "I0517 10:03:15.413302 139851376510848 learning.py:507] global step 8366: loss = 2.0749 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8367: loss = 2.3164 (0.550 sec/step)\n",
            "I0517 10:03:15.964804 139851376510848 learning.py:507] global step 8367: loss = 2.3164 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8368: loss = 1.5383 (0.540 sec/step)\n",
            "I0517 10:03:16.505954 139851376510848 learning.py:507] global step 8368: loss = 1.5383 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8369: loss = 2.0441 (0.521 sec/step)\n",
            "I0517 10:03:17.028601 139851376510848 learning.py:507] global step 8369: loss = 2.0441 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8370: loss = 3.8402 (0.539 sec/step)\n",
            "I0517 10:03:17.569353 139851376510848 learning.py:507] global step 8370: loss = 3.8402 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8371: loss = 2.2977 (0.545 sec/step)\n",
            "I0517 10:03:18.116492 139851376510848 learning.py:507] global step 8371: loss = 2.2977 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8372: loss = 2.7090 (0.539 sec/step)\n",
            "I0517 10:03:18.657446 139851376510848 learning.py:507] global step 8372: loss = 2.7090 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8373: loss = 3.4988 (0.550 sec/step)\n",
            "I0517 10:03:19.208985 139851376510848 learning.py:507] global step 8373: loss = 3.4988 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8374: loss = 1.9763 (0.564 sec/step)\n",
            "I0517 10:03:19.774152 139851376510848 learning.py:507] global step 8374: loss = 1.9763 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8375: loss = 2.1522 (0.538 sec/step)\n",
            "I0517 10:03:20.314400 139851376510848 learning.py:507] global step 8375: loss = 2.1522 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8376: loss = 1.6998 (0.565 sec/step)\n",
            "I0517 10:03:20.881681 139851376510848 learning.py:507] global step 8376: loss = 1.6998 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8377: loss = 1.9920 (0.565 sec/step)\n",
            "I0517 10:03:21.449010 139851376510848 learning.py:507] global step 8377: loss = 1.9920 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8378: loss = 3.0224 (0.550 sec/step)\n",
            "I0517 10:03:22.000650 139851376510848 learning.py:507] global step 8378: loss = 3.0224 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8379: loss = 1.8407 (0.559 sec/step)\n",
            "I0517 10:03:22.561283 139851376510848 learning.py:507] global step 8379: loss = 1.8407 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8380: loss = 2.5313 (0.570 sec/step)\n",
            "I0517 10:03:23.133284 139851376510848 learning.py:507] global step 8380: loss = 2.5313 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 8381: loss = 1.6120 (0.536 sec/step)\n",
            "I0517 10:03:23.671339 139851376510848 learning.py:507] global step 8381: loss = 1.6120 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8382: loss = 1.2048 (0.562 sec/step)\n",
            "I0517 10:03:24.234699 139851376510848 learning.py:507] global step 8382: loss = 1.2048 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 8383: loss = 1.7292 (0.552 sec/step)\n",
            "I0517 10:03:24.788382 139851376510848 learning.py:507] global step 8383: loss = 1.7292 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8384: loss = 1.9131 (0.557 sec/step)\n",
            "I0517 10:03:25.346959 139851376510848 learning.py:507] global step 8384: loss = 1.9131 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8385: loss = 1.4589 (0.549 sec/step)\n",
            "I0517 10:03:25.897776 139851376510848 learning.py:507] global step 8385: loss = 1.4589 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8386: loss = 1.8201 (0.526 sec/step)\n",
            "I0517 10:03:26.425968 139851376510848 learning.py:507] global step 8386: loss = 1.8201 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8387: loss = 1.6555 (0.552 sec/step)\n",
            "I0517 10:03:26.979709 139851376510848 learning.py:507] global step 8387: loss = 1.6555 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8388: loss = 1.9929 (0.543 sec/step)\n",
            "I0517 10:03:27.523953 139851376510848 learning.py:507] global step 8388: loss = 1.9929 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8389: loss = 2.3882 (0.532 sec/step)\n",
            "I0517 10:03:28.057294 139851376510848 learning.py:507] global step 8389: loss = 2.3882 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8390: loss = 1.7887 (0.532 sec/step)\n",
            "I0517 10:03:28.591349 139851376510848 learning.py:507] global step 8390: loss = 1.7887 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8391: loss = 2.8994 (0.535 sec/step)\n",
            "I0517 10:03:29.128437 139851376510848 learning.py:507] global step 8391: loss = 2.8994 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8392: loss = 1.5038 (0.552 sec/step)\n",
            "I0517 10:03:29.682491 139851376510848 learning.py:507] global step 8392: loss = 1.5038 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8393: loss = 1.6442 (0.565 sec/step)\n",
            "I0517 10:03:30.249200 139851376510848 learning.py:507] global step 8393: loss = 1.6442 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8394: loss = 1.5546 (0.514 sec/step)\n",
            "I0517 10:03:30.764718 139851376510848 learning.py:507] global step 8394: loss = 1.5546 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 8395: loss = 1.5642 (0.540 sec/step)\n",
            "I0517 10:03:31.306341 139851376510848 learning.py:507] global step 8395: loss = 1.5642 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8396: loss = 1.9209 (0.536 sec/step)\n",
            "I0517 10:03:31.843971 139851376510848 learning.py:507] global step 8396: loss = 1.9209 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8397: loss = 1.7773 (0.559 sec/step)\n",
            "I0517 10:03:32.404390 139851376510848 learning.py:507] global step 8397: loss = 1.7773 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8398: loss = 1.4891 (0.546 sec/step)\n",
            "I0517 10:03:32.952587 139851376510848 learning.py:507] global step 8398: loss = 1.4891 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8399: loss = 1.7328 (0.567 sec/step)\n",
            "I0517 10:03:33.521810 139851376510848 learning.py:507] global step 8399: loss = 1.7328 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 8400: loss = 1.2608 (0.562 sec/step)\n",
            "I0517 10:03:34.085867 139851376510848 learning.py:507] global step 8400: loss = 1.2608 (0.562 sec/step)\n",
            "INFO:tensorflow:global step 8401: loss = 2.0119 (0.553 sec/step)\n",
            "I0517 10:03:34.640352 139851376510848 learning.py:507] global step 8401: loss = 2.0119 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8402: loss = 2.1008 (0.541 sec/step)\n",
            "I0517 10:03:35.182603 139851376510848 learning.py:507] global step 8402: loss = 2.1008 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8403: loss = 2.0780 (0.531 sec/step)\n",
            "I0517 10:03:35.715886 139851376510848 learning.py:507] global step 8403: loss = 2.0780 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8404: loss = 1.8550 (0.547 sec/step)\n",
            "I0517 10:03:36.264930 139851376510848 learning.py:507] global step 8404: loss = 1.8550 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8405: loss = 2.1456 (0.554 sec/step)\n",
            "I0517 10:03:36.821139 139851376510848 learning.py:507] global step 8405: loss = 2.1456 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8406: loss = 1.6560 (0.538 sec/step)\n",
            "I0517 10:03:37.361574 139851376510848 learning.py:507] global step 8406: loss = 1.6560 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8407: loss = 1.6117 (0.534 sec/step)\n",
            "I0517 10:03:37.896967 139851376510848 learning.py:507] global step 8407: loss = 1.6117 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8408: loss = 1.3866 (0.530 sec/step)\n",
            "I0517 10:03:38.429044 139851376510848 learning.py:507] global step 8408: loss = 1.3866 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8409: loss = 4.4035 (0.505 sec/step)\n",
            "I0517 10:03:38.937100 139851376510848 learning.py:507] global step 8409: loss = 4.4035 (0.505 sec/step)\n",
            "INFO:tensorflow:global step 8410: loss = 1.9119 (0.544 sec/step)\n",
            "I0517 10:03:39.482706 139851376510848 learning.py:507] global step 8410: loss = 1.9119 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8411: loss = 1.9339 (0.534 sec/step)\n",
            "I0517 10:03:40.018819 139851376510848 learning.py:507] global step 8411: loss = 1.9339 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8412: loss = 2.1206 (0.555 sec/step)\n",
            "I0517 10:03:40.575050 139851376510848 learning.py:507] global step 8412: loss = 2.1206 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8413: loss = 1.4869 (0.543 sec/step)\n",
            "I0517 10:03:41.119356 139851376510848 learning.py:507] global step 8413: loss = 1.4869 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8414: loss = 2.3289 (0.541 sec/step)\n",
            "I0517 10:03:41.662494 139851376510848 learning.py:507] global step 8414: loss = 2.3289 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8415: loss = 3.0757 (0.554 sec/step)\n",
            "I0517 10:03:42.217834 139851376510848 learning.py:507] global step 8415: loss = 3.0757 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8416: loss = 1.9261 (0.528 sec/step)\n",
            "I0517 10:03:42.748308 139851376510848 learning.py:507] global step 8416: loss = 1.9261 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8417: loss = 1.5975 (0.549 sec/step)\n",
            "I0517 10:03:43.299486 139851376510848 learning.py:507] global step 8417: loss = 1.5975 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8418: loss = 1.6175 (0.540 sec/step)\n",
            "I0517 10:03:43.841220 139851376510848 learning.py:507] global step 8418: loss = 1.6175 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8419: loss = 1.7020 (0.538 sec/step)\n",
            "I0517 10:03:44.380960 139851376510848 learning.py:507] global step 8419: loss = 1.7020 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8420: loss = 2.5709 (0.559 sec/step)\n",
            "I0517 10:03:44.942368 139851376510848 learning.py:507] global step 8420: loss = 2.5709 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8421: loss = 1.5706 (0.529 sec/step)\n",
            "I0517 10:03:45.473451 139851376510848 learning.py:507] global step 8421: loss = 1.5706 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8422: loss = 2.3572 (0.541 sec/step)\n",
            "I0517 10:03:46.015802 139851376510848 learning.py:507] global step 8422: loss = 2.3572 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8423: loss = 1.8767 (0.555 sec/step)\n",
            "I0517 10:03:46.572204 139851376510848 learning.py:507] global step 8423: loss = 1.8767 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8424: loss = 2.1144 (0.543 sec/step)\n",
            "I0517 10:03:47.117268 139851376510848 learning.py:507] global step 8424: loss = 2.1144 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8425: loss = 1.3454 (0.572 sec/step)\n",
            "I0517 10:03:47.691449 139851376510848 learning.py:507] global step 8425: loss = 1.3454 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 8426: loss = 3.5696 (0.567 sec/step)\n",
            "I0517 10:03:48.263184 139851376510848 learning.py:507] global step 8426: loss = 3.5696 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 8427: loss = 1.8909 (0.564 sec/step)\n",
            "I0517 10:03:48.829178 139851376510848 learning.py:507] global step 8427: loss = 1.8909 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8428: loss = 1.8726 (0.536 sec/step)\n",
            "I0517 10:03:49.367486 139851376510848 learning.py:507] global step 8428: loss = 1.8726 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8429: loss = 1.4315 (0.557 sec/step)\n",
            "I0517 10:03:49.926965 139851376510848 learning.py:507] global step 8429: loss = 1.4315 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 8430: loss = 1.6943 (0.545 sec/step)\n",
            "I0517 10:03:50.473413 139851376510848 learning.py:507] global step 8430: loss = 1.6943 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8431: loss = 1.5602 (0.564 sec/step)\n",
            "I0517 10:03:51.039173 139851376510848 learning.py:507] global step 8431: loss = 1.5602 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 8432: loss = 1.9446 (0.538 sec/step)\n",
            "I0517 10:03:51.579256 139851376510848 learning.py:507] global step 8432: loss = 1.9446 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8433: loss = 2.2635 (0.551 sec/step)\n",
            "I0517 10:03:52.131690 139851376510848 learning.py:507] global step 8433: loss = 2.2635 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8434: loss = 1.5738 (0.539 sec/step)\n",
            "I0517 10:03:52.672653 139851376510848 learning.py:507] global step 8434: loss = 1.5738 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8435: loss = 1.8732 (0.524 sec/step)\n",
            "I0517 10:03:53.198003 139851376510848 learning.py:507] global step 8435: loss = 1.8732 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8436: loss = 1.5151 (0.540 sec/step)\n",
            "I0517 10:03:53.739657 139851376510848 learning.py:507] global step 8436: loss = 1.5151 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8437: loss = 1.9373 (0.542 sec/step)\n",
            "I0517 10:03:54.283954 139851376510848 learning.py:507] global step 8437: loss = 1.9373 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8438: loss = 1.7170 (0.558 sec/step)\n",
            "I0517 10:03:54.844310 139851376510848 learning.py:507] global step 8438: loss = 1.7170 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 8439: loss = 1.8709 (0.501 sec/step)\n",
            "I0517 10:03:55.346875 139851376510848 learning.py:507] global step 8439: loss = 1.8709 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 8440: loss = 1.7985 (0.541 sec/step)\n",
            "I0517 10:03:55.890024 139851376510848 learning.py:507] global step 8440: loss = 1.7985 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8441: loss = 1.6616 (0.555 sec/step)\n",
            "I0517 10:03:56.450171 139851376510848 learning.py:507] global step 8441: loss = 1.6616 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8442: loss = 1.9327 (0.533 sec/step)\n",
            "I0517 10:03:56.985182 139851376510848 learning.py:507] global step 8442: loss = 1.9327 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8443: loss = 1.7736 (0.539 sec/step)\n",
            "I0517 10:03:57.526884 139851376510848 learning.py:507] global step 8443: loss = 1.7736 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8444: loss = 2.2704 (0.537 sec/step)\n",
            "I0517 10:03:58.066349 139851376510848 learning.py:507] global step 8444: loss = 2.2704 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8445: loss = 2.0298 (0.545 sec/step)\n",
            "I0517 10:03:58.612891 139851376510848 learning.py:507] global step 8445: loss = 2.0298 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8446: loss = 1.7251 (0.541 sec/step)\n",
            "I0517 10:03:59.156138 139851376510848 learning.py:507] global step 8446: loss = 1.7251 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8447: loss = 2.4472 (0.545 sec/step)\n",
            "I0517 10:03:59.702625 139851376510848 learning.py:507] global step 8447: loss = 2.4472 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8448: loss = 1.6170 (0.553 sec/step)\n",
            "I0517 10:04:00.257756 139851376510848 learning.py:507] global step 8448: loss = 1.6170 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8449: loss = 1.4756 (0.578 sec/step)\n",
            "I0517 10:04:00.837362 139851376510848 learning.py:507] global step 8449: loss = 1.4756 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 8450: loss = 1.5559 (0.540 sec/step)\n",
            "I0517 10:04:01.379317 139851376510848 learning.py:507] global step 8450: loss = 1.5559 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8451: loss = 2.0286 (0.546 sec/step)\n",
            "I0517 10:04:01.927894 139851376510848 learning.py:507] global step 8451: loss = 2.0286 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8452: loss = 1.5069 (0.532 sec/step)\n",
            "I0517 10:04:02.461575 139851376510848 learning.py:507] global step 8452: loss = 1.5069 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8453: loss = 2.5642 (0.540 sec/step)\n",
            "I0517 10:04:03.002898 139851376510848 learning.py:507] global step 8453: loss = 2.5642 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8454: loss = 2.5258 (0.529 sec/step)\n",
            "I0517 10:04:03.533919 139851376510848 learning.py:507] global step 8454: loss = 2.5258 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8455: loss = 1.5876 (0.547 sec/step)\n",
            "I0517 10:04:04.082679 139851376510848 learning.py:507] global step 8455: loss = 1.5876 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8456: loss = 2.0349 (0.525 sec/step)\n",
            "I0517 10:04:04.609885 139851376510848 learning.py:507] global step 8456: loss = 2.0349 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 8457: loss = 1.8724 (0.537 sec/step)\n",
            "I0517 10:04:05.148853 139851376510848 learning.py:507] global step 8457: loss = 1.8724 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8458: loss = 1.3498 (0.526 sec/step)\n",
            "I0517 10:04:05.676855 139851376510848 learning.py:507] global step 8458: loss = 1.3498 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8459: loss = 1.8338 (0.561 sec/step)\n",
            "I0517 10:04:06.240217 139851376510848 learning.py:507] global step 8459: loss = 1.8338 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8460: loss = 1.8037 (0.551 sec/step)\n",
            "I0517 10:04:06.794235 139851376510848 learning.py:507] global step 8460: loss = 1.8037 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8461: loss = 2.0796 (0.514 sec/step)\n",
            "I0517 10:04:07.310966 139851376510848 learning.py:507] global step 8461: loss = 2.0796 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 8462: loss = 2.6450 (0.537 sec/step)\n",
            "I0517 10:04:07.849375 139851376510848 learning.py:507] global step 8462: loss = 2.6450 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8463: loss = 2.3229 (0.526 sec/step)\n",
            "I0517 10:04:08.377312 139851376510848 learning.py:507] global step 8463: loss = 2.3229 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8464: loss = 2.3706 (0.552 sec/step)\n",
            "I0517 10:04:08.931286 139851376510848 learning.py:507] global step 8464: loss = 2.3706 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8465: loss = 1.6223 (0.578 sec/step)\n",
            "I0517 10:04:09.510819 139851376510848 learning.py:507] global step 8465: loss = 1.6223 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 8466: loss = 1.4949 (0.540 sec/step)\n",
            "I0517 10:04:10.052725 139851376510848 learning.py:507] global step 8466: loss = 1.4949 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8467: loss = 2.4226 (0.534 sec/step)\n",
            "I0517 10:04:10.589978 139851376510848 learning.py:507] global step 8467: loss = 2.4226 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8468: loss = 2.1292 (0.552 sec/step)\n",
            "I0517 10:04:11.143938 139851376510848 learning.py:507] global step 8468: loss = 2.1292 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8469: loss = 2.0199 (0.538 sec/step)\n",
            "I0517 10:04:11.683454 139851376510848 learning.py:507] global step 8469: loss = 2.0199 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8470: loss = 2.0232 (0.555 sec/step)\n",
            "I0517 10:04:12.244955 139851376510848 learning.py:507] global step 8470: loss = 2.0232 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8471: loss = 2.5809 (0.563 sec/step)\n",
            "I0517 10:04:12.810216 139851376510848 learning.py:507] global step 8471: loss = 2.5809 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 8472: loss = 1.6904 (0.544 sec/step)\n",
            "I0517 10:04:13.356075 139851376510848 learning.py:507] global step 8472: loss = 1.6904 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8473: loss = 1.7452 (0.572 sec/step)\n",
            "I0517 10:04:13.929477 139851376510848 learning.py:507] global step 8473: loss = 1.7452 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 8474: loss = 2.5120 (0.548 sec/step)\n",
            "I0517 10:04:14.479825 139851376510848 learning.py:507] global step 8474: loss = 2.5120 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8475: loss = 1.9132 (0.575 sec/step)\n",
            "I0517 10:04:15.056639 139851376510848 learning.py:507] global step 8475: loss = 1.9132 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8476: loss = 2.1158 (0.542 sec/step)\n",
            "I0517 10:04:15.600387 139851376510848 learning.py:507] global step 8476: loss = 2.1158 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8477: loss = 1.8860 (0.553 sec/step)\n",
            "I0517 10:04:16.155339 139851376510848 learning.py:507] global step 8477: loss = 1.8860 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 8478: loss = 2.1992 (0.560 sec/step)\n",
            "I0517 10:04:16.716897 139851376510848 learning.py:507] global step 8478: loss = 2.1992 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8479: loss = 1.2577 (0.542 sec/step)\n",
            "I0517 10:04:17.260913 139851376510848 learning.py:507] global step 8479: loss = 1.2577 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8480: loss = 2.0130 (0.533 sec/step)\n",
            "I0517 10:04:17.795593 139851376510848 learning.py:507] global step 8480: loss = 2.0130 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8481: loss = 2.0412 (0.561 sec/step)\n",
            "I0517 10:04:18.358250 139851376510848 learning.py:507] global step 8481: loss = 2.0412 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8482: loss = 1.8322 (0.541 sec/step)\n",
            "I0517 10:04:18.900759 139851376510848 learning.py:507] global step 8482: loss = 1.8322 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8483: loss = 1.4073 (0.537 sec/step)\n",
            "I0517 10:04:19.439724 139851376510848 learning.py:507] global step 8483: loss = 1.4073 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8484: loss = 2.6931 (0.556 sec/step)\n",
            "I0517 10:04:19.997892 139851376510848 learning.py:507] global step 8484: loss = 2.6931 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8485: loss = 1.3822 (0.529 sec/step)\n",
            "I0517 10:04:20.529021 139851376510848 learning.py:507] global step 8485: loss = 1.3822 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8486: loss = 1.8240 (0.528 sec/step)\n",
            "I0517 10:04:21.058502 139851376510848 learning.py:507] global step 8486: loss = 1.8240 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8487: loss = 1.5179 (0.575 sec/step)\n",
            "I0517 10:04:21.635314 139851376510848 learning.py:507] global step 8487: loss = 1.5179 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8488: loss = 1.9478 (0.551 sec/step)\n",
            "I0517 10:04:22.188287 139851376510848 learning.py:507] global step 8488: loss = 1.9478 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8489: loss = 1.8410 (0.571 sec/step)\n",
            "I0517 10:04:22.760883 139851376510848 learning.py:507] global step 8489: loss = 1.8410 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 8490: loss = 2.4715 (0.545 sec/step)\n",
            "I0517 10:04:23.307464 139851376510848 learning.py:507] global step 8490: loss = 2.4715 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8491: loss = 1.6231 (0.572 sec/step)\n",
            "I0517 10:04:23.881118 139851376510848 learning.py:507] global step 8491: loss = 1.6231 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 8492: loss = 1.7205 (0.570 sec/step)\n",
            "I0517 10:04:24.452401 139851376510848 learning.py:507] global step 8492: loss = 1.7205 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 8493: loss = 2.7727 (0.551 sec/step)\n",
            "I0517 10:04:25.005620 139851376510848 learning.py:507] global step 8493: loss = 2.7727 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8494: loss = 1.5255 (0.533 sec/step)\n",
            "I0517 10:04:25.540306 139851376510848 learning.py:507] global step 8494: loss = 1.5255 (0.533 sec/step)\n",
            "INFO:tensorflow:global step 8495: loss = 2.2875 (0.555 sec/step)\n",
            "I0517 10:04:26.097460 139851376510848 learning.py:507] global step 8495: loss = 2.2875 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8496: loss = 1.9694 (0.526 sec/step)\n",
            "I0517 10:04:26.625349 139851376510848 learning.py:507] global step 8496: loss = 1.9694 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8497: loss = 2.0084 (0.514 sec/step)\n",
            "I0517 10:04:27.141296 139851376510848 learning.py:507] global step 8497: loss = 2.0084 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 8498: loss = 3.4172 (0.545 sec/step)\n",
            "I0517 10:04:27.688329 139851376510848 learning.py:507] global step 8498: loss = 3.4172 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8499: loss = 2.0919 (0.548 sec/step)\n",
            "I0517 10:04:28.238365 139851376510848 learning.py:507] global step 8499: loss = 2.0919 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8500: loss = 1.7260 (0.526 sec/step)\n",
            "I0517 10:04:28.766222 139851376510848 learning.py:507] global step 8500: loss = 1.7260 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8501: loss = 1.6684 (0.555 sec/step)\n",
            "I0517 10:04:29.322705 139851376510848 learning.py:507] global step 8501: loss = 1.6684 (0.555 sec/step)\n",
            "INFO:tensorflow:global step 8502: loss = 1.9472 (0.561 sec/step)\n",
            "I0517 10:04:29.886482 139851376510848 learning.py:507] global step 8502: loss = 1.9472 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8503: loss = 1.7945 (0.545 sec/step)\n",
            "I0517 10:04:30.434368 139851376510848 learning.py:507] global step 8503: loss = 1.7945 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8504: loss = 1.7157 (0.542 sec/step)\n",
            "I0517 10:04:30.979892 139851376510848 learning.py:507] global step 8504: loss = 1.7157 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8505: loss = 1.6509 (0.539 sec/step)\n",
            "I0517 10:04:31.520787 139851376510848 learning.py:507] global step 8505: loss = 1.6509 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8506: loss = 2.0995 (0.514 sec/step)\n",
            "I0517 10:04:32.036430 139851376510848 learning.py:507] global step 8506: loss = 2.0995 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 8507: loss = 1.4815 (0.540 sec/step)\n",
            "I0517 10:04:32.577708 139851376510848 learning.py:507] global step 8507: loss = 1.4815 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8508: loss = 2.8610 (0.545 sec/step)\n",
            "I0517 10:04:33.124330 139851376510848 learning.py:507] global step 8508: loss = 2.8610 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8509: loss = 2.1992 (0.569 sec/step)\n",
            "I0517 10:04:33.695229 139851376510848 learning.py:507] global step 8509: loss = 2.1992 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 8510: loss = 2.1309 (0.543 sec/step)\n",
            "I0517 10:04:34.239914 139851376510848 learning.py:507] global step 8510: loss = 2.1309 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 8511: loss = 2.2258 (0.547 sec/step)\n",
            "I0517 10:04:34.788839 139851376510848 learning.py:507] global step 8511: loss = 2.2258 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 8512: loss = 2.9051 (0.541 sec/step)\n",
            "I0517 10:04:35.331388 139851376510848 learning.py:507] global step 8512: loss = 2.9051 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8513: loss = 1.5623 (0.550 sec/step)\n",
            "I0517 10:04:35.883226 139851376510848 learning.py:507] global step 8513: loss = 1.5623 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8514: loss = 2.1699 (0.535 sec/step)\n",
            "I0517 10:04:36.419695 139851376510848 learning.py:507] global step 8514: loss = 2.1699 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 8515: loss = 1.9629 (0.550 sec/step)\n",
            "I0517 10:04:36.971147 139851376510848 learning.py:507] global step 8515: loss = 1.9629 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8516: loss = 1.8073 (0.560 sec/step)\n",
            "I0517 10:04:37.532623 139851376510848 learning.py:507] global step 8516: loss = 1.8073 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 8517: loss = 3.5675 (0.548 sec/step)\n",
            "I0517 10:04:38.082866 139851376510848 learning.py:507] global step 8517: loss = 3.5675 (0.548 sec/step)\n",
            "INFO:tensorflow:global step 8518: loss = 2.1656 (0.539 sec/step)\n",
            "I0517 10:04:38.623900 139851376510848 learning.py:507] global step 8518: loss = 2.1656 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 8519: loss = 1.5019 (0.570 sec/step)\n",
            "I0517 10:04:39.195620 139851376510848 learning.py:507] global step 8519: loss = 1.5019 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 8520: loss = 1.8482 (0.529 sec/step)\n",
            "I0517 10:04:39.726814 139851376510848 learning.py:507] global step 8520: loss = 1.8482 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8521: loss = 2.5005 (0.523 sec/step)\n",
            "I0517 10:04:40.252197 139851376510848 learning.py:507] global step 8521: loss = 2.5005 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 8522: loss = 1.6928 (0.546 sec/step)\n",
            "I0517 10:04:40.799885 139851376510848 learning.py:507] global step 8522: loss = 1.6928 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 8523: loss = 1.8794 (0.591 sec/step)\n",
            "I0517 10:04:41.393079 139851376510848 learning.py:507] global step 8523: loss = 1.8794 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 8524: loss = 1.5281 (0.565 sec/step)\n",
            "I0517 10:04:41.960306 139851376510848 learning.py:507] global step 8524: loss = 1.5281 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8525: loss = 1.3197 (0.522 sec/step)\n",
            "I0517 10:04:42.483889 139851376510848 learning.py:507] global step 8525: loss = 1.3197 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 8526: loss = 1.4432 (0.530 sec/step)\n",
            "I0517 10:04:43.015802 139851376510848 learning.py:507] global step 8526: loss = 1.4432 (0.530 sec/step)\n",
            "INFO:tensorflow:global step 8527: loss = 1.1448 (0.559 sec/step)\n",
            "I0517 10:04:43.576512 139851376510848 learning.py:507] global step 8527: loss = 1.1448 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 8528: loss = 2.4100 (0.545 sec/step)\n",
            "I0517 10:04:44.123172 139851376510848 learning.py:507] global step 8528: loss = 2.4100 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8529: loss = 2.1393 (0.575 sec/step)\n",
            "I0517 10:04:44.699951 139851376510848 learning.py:507] global step 8529: loss = 2.1393 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 8530: loss = 1.5595 (0.543 sec/step)\n",
            "I0517 10:04:45.244213 139851376510848 learning.py:507] global step 8530: loss = 1.5595 (0.543 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "I0517 10:04:45.556850 139847658321664 supervisor.py:1117] Saving checkpoint to path /content/workspace/training_demo/training/model.ckpt\n",
            "INFO:tensorflow:global step 8531: loss = 1.6404 (1.392 sec/step)\n",
            "I0517 10:04:46.638604 139851376510848 learning.py:507] global step 8531: loss = 1.6404 (1.392 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8532.\n",
            "I0517 10:04:48.034631 139847641536256 supervisor.py:1050] Recording summary at step 8532.\n",
            "INFO:tensorflow:global step 8532: loss = 2.0736 (1.389 sec/step)\n",
            "I0517 10:04:48.034812 139851376510848 learning.py:507] global step 8532: loss = 2.0736 (1.389 sec/step)\n",
            "INFO:tensorflow:global step 8533: loss = 1.7513 (0.801 sec/step)\n",
            "I0517 10:04:48.879450 139851376510848 learning.py:507] global step 8533: loss = 1.7513 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 8534: loss = 1.9640 (0.668 sec/step)\n",
            "I0517 10:04:49.549511 139851376510848 learning.py:507] global step 8534: loss = 1.9640 (0.668 sec/step)\n",
            "INFO:tensorflow:global step 8535: loss = 1.6794 (0.534 sec/step)\n",
            "I0517 10:04:50.085027 139851376510848 learning.py:507] global step 8535: loss = 1.6794 (0.534 sec/step)\n",
            "INFO:tensorflow:global step 8536: loss = 1.7759 (0.550 sec/step)\n",
            "I0517 10:04:50.636363 139851376510848 learning.py:507] global step 8536: loss = 1.7759 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 8537: loss = 1.7605 (0.538 sec/step)\n",
            "I0517 10:04:51.175653 139851376510848 learning.py:507] global step 8537: loss = 1.7605 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8538: loss = 2.4923 (0.576 sec/step)\n",
            "I0517 10:04:51.754020 139851376510848 learning.py:507] global step 8538: loss = 2.4923 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 8539: loss = 2.3278 (0.566 sec/step)\n",
            "I0517 10:04:52.321988 139851376510848 learning.py:507] global step 8539: loss = 2.3278 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 8540: loss = 1.9522 (0.524 sec/step)\n",
            "I0517 10:04:52.847889 139851376510848 learning.py:507] global step 8540: loss = 1.9522 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 8541: loss = 1.7194 (0.551 sec/step)\n",
            "I0517 10:04:53.400886 139851376510848 learning.py:507] global step 8541: loss = 1.7194 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 8542: loss = 1.3192 (0.541 sec/step)\n",
            "I0517 10:04:53.943449 139851376510848 learning.py:507] global step 8542: loss = 1.3192 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8543: loss = 1.6160 (0.537 sec/step)\n",
            "I0517 10:04:54.482463 139851376510848 learning.py:507] global step 8543: loss = 1.6160 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8544: loss = 2.2148 (0.517 sec/step)\n",
            "I0517 10:04:55.001540 139851376510848 learning.py:507] global step 8544: loss = 2.2148 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 8545: loss = 2.3311 (0.542 sec/step)\n",
            "I0517 10:04:55.544988 139851376510848 learning.py:507] global step 8545: loss = 2.3311 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 8546: loss = 1.3940 (0.529 sec/step)\n",
            "I0517 10:04:56.075965 139851376510848 learning.py:507] global step 8546: loss = 1.3940 (0.529 sec/step)\n",
            "INFO:tensorflow:global step 8547: loss = 2.2089 (0.556 sec/step)\n",
            "I0517 10:04:56.633710 139851376510848 learning.py:507] global step 8547: loss = 2.2089 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 8548: loss = 1.7537 (0.532 sec/step)\n",
            "I0517 10:04:57.167939 139851376510848 learning.py:507] global step 8548: loss = 1.7537 (0.532 sec/step)\n",
            "INFO:tensorflow:global step 8549: loss = 1.2749 (0.518 sec/step)\n",
            "I0517 10:04:57.688609 139851376510848 learning.py:507] global step 8549: loss = 1.2749 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 8550: loss = 1.7860 (0.526 sec/step)\n",
            "I0517 10:04:58.216850 139851376510848 learning.py:507] global step 8550: loss = 1.7860 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8551: loss = 2.1493 (0.544 sec/step)\n",
            "I0517 10:04:58.762433 139851376510848 learning.py:507] global step 8551: loss = 2.1493 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 8552: loss = 1.4177 (0.536 sec/step)\n",
            "I0517 10:04:59.300442 139851376510848 learning.py:507] global step 8552: loss = 1.4177 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 8553: loss = 1.4525 (0.565 sec/step)\n",
            "I0517 10:04:59.867455 139851376510848 learning.py:507] global step 8553: loss = 1.4525 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8554: loss = 1.5767 (0.540 sec/step)\n",
            "I0517 10:05:00.409197 139851376510848 learning.py:507] global step 8554: loss = 1.5767 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 8555: loss = 2.7736 (0.541 sec/step)\n",
            "I0517 10:05:00.952305 139851376510848 learning.py:507] global step 8555: loss = 2.7736 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 8556: loss = 2.5903 (0.552 sec/step)\n",
            "I0517 10:05:01.505700 139851376510848 learning.py:507] global step 8556: loss = 2.5903 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8557: loss = 2.7687 (0.531 sec/step)\n",
            "I0517 10:05:02.038372 139851376510848 learning.py:507] global step 8557: loss = 2.7687 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 8558: loss = 1.9270 (0.565 sec/step)\n",
            "I0517 10:05:02.605200 139851376510848 learning.py:507] global step 8558: loss = 1.9270 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 8559: loss = 1.5165 (0.561 sec/step)\n",
            "I0517 10:05:03.167311 139851376510848 learning.py:507] global step 8559: loss = 1.5165 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8560: loss = 3.6509 (0.545 sec/step)\n",
            "I0517 10:05:03.713559 139851376510848 learning.py:507] global step 8560: loss = 3.6509 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8561: loss = 2.0102 (0.526 sec/step)\n",
            "I0517 10:05:04.241445 139851376510848 learning.py:507] global step 8561: loss = 2.0102 (0.526 sec/step)\n",
            "INFO:tensorflow:global step 8562: loss = 1.7120 (0.554 sec/step)\n",
            "I0517 10:05:04.796820 139851376510848 learning.py:507] global step 8562: loss = 1.7120 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 8563: loss = 1.4039 (0.521 sec/step)\n",
            "I0517 10:05:05.319317 139851376510848 learning.py:507] global step 8563: loss = 1.4039 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 8564: loss = 1.7674 (0.552 sec/step)\n",
            "I0517 10:05:05.873478 139851376510848 learning.py:507] global step 8564: loss = 1.7674 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 8565: loss = 1.9082 (0.528 sec/step)\n",
            "I0517 10:05:06.403989 139851376510848 learning.py:507] global step 8565: loss = 1.9082 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 8566: loss = 2.8694 (0.538 sec/step)\n",
            "I0517 10:05:06.944054 139851376510848 learning.py:507] global step 8566: loss = 2.8694 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8567: loss = 1.5468 (0.579 sec/step)\n",
            "I0517 10:05:07.525321 139851376510848 learning.py:507] global step 8567: loss = 1.5468 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 8568: loss = 1.5386 (0.537 sec/step)\n",
            "I0517 10:05:08.064299 139851376510848 learning.py:507] global step 8568: loss = 1.5386 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 8569: loss = 2.3441 (0.545 sec/step)\n",
            "I0517 10:05:08.610782 139851376510848 learning.py:507] global step 8569: loss = 2.3441 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 8570: loss = 1.6735 (0.519 sec/step)\n",
            "I0517 10:05:09.131640 139851376510848 learning.py:507] global step 8570: loss = 1.6735 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 8571: loss = 1.1888 (0.549 sec/step)\n",
            "I0517 10:05:09.681890 139851376510848 learning.py:507] global step 8571: loss = 1.1888 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 8572: loss = 1.7512 (0.569 sec/step)\n",
            "I0517 10:05:10.252640 139851376510848 learning.py:507] global step 8572: loss = 1.7512 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 8573: loss = 1.9335 (0.585 sec/step)\n",
            "I0517 10:05:10.841436 139851376510848 learning.py:507] global step 8573: loss = 1.9335 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 8574: loss = 2.0192 (0.507 sec/step)\n",
            "I0517 10:05:11.349860 139851376510848 learning.py:507] global step 8574: loss = 2.0192 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 8575: loss = 1.5395 (0.538 sec/step)\n",
            "I0517 10:05:11.889488 139851376510848 learning.py:507] global step 8575: loss = 1.5395 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 8576: loss = 1.4728 (0.561 sec/step)\n",
            "I0517 10:05:12.452056 139851376510848 learning.py:507] global step 8576: loss = 1.4728 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 8577: loss = 2.1530 (0.589 sec/step)\n",
            "I0517 10:05:13.043109 139851376510848 learning.py:507] global step 8577: loss = 2.1530 (0.589 sec/step)\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 186, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"train.py\", line 182, in main\n",
            "    graph_hook_fn=graph_rewriter_fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py\", line 416, in train\n",
            "    saver=saver)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 775, in train\n",
            "    train_step_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 490, in train_step\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAyb-q88GKSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/workspace/training_demo/training/ /content/drive/My\\ Drive/tomNjerry_Object_Detection/workspace/training_demo/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIVLeIABZw15",
        "colab_type": "code",
        "outputId": "91d61aa0-b9a2-48c9-81eb-96498ef5b5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/workspace/training_demo\n",
        "!python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workspace/training_demo\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models-r1.13.0/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models-r1.13.0/research/slim/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From model_main.py:112: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0517 07:50:35.948660 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0517 07:50:35.951838 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0517 07:50:35.951975 140632426096512 model_lib.py:574] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0517 07:50:35.952117 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0517 07:50:35.952203 140632426096512 config_util.py:480] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0517 07:50:35.952277 140632426096512 config_util.py:480] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0517 07:50:35.952356 140632426096512 config_util.py:480] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0517 07:50:35.952429 140632426096512 config_util.py:480] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0517 07:50:35.952512 140632426096512 config_util.py:490] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0517 07:50:35.953099 140632426096512 model_lib.py:590] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0517 07:50:35.953209 140632426096512 model_lib.py:623] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe716a8ec88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0517 07:50:35.953595 140632426096512 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe716a8ec88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe716a996a8>) includes params argument, but params are not passed to Estimator.\n",
            "W0517 07:50:35.953801 140632426096512 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe716a996a8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0517 07:50:35.954456 140632426096512 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0517 07:50:35.954633 140632426096512 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0517 07:50:35.954840 140632426096512 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0517 07:50:35.962830 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/data_decoders/tf_example_decoder.py:167: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0517 07:50:35.971762 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/data_decoders/tf_example_decoder.py:167: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0517 07:50:35.971982 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0517 07:50:35.984216 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0517 07:50:35.985057 140632426096512 dataset_builder.py:66] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0517 07:50:35.989884 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0517 07:50:35.990048 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2020-05-17 07:50:36.048299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-17 07:50:36.069595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:50:36.070168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-17 07:50:36.070429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-17 07:50:36.071515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-17 07:50:36.072567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-17 07:50:36.072883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-17 07:50:36.074514: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-17 07:50:36.075679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-17 07:50:36.080740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-17 07:50:36.080858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:50:36.081469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:50:36.082057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:466: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0517 07:50:36.215880 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:466: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 07:50:36.216643 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:468: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0517 07:50:36.219969 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:468: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:287: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 07:50:36.239432 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:287: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0517 07:50:36.242475 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0517 07:50:36.296667 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "W0517 07:50:36.299268 140632426096512 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:2393: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0517 07:50:37.209566 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:2393: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0517 07:50:37.693924 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0517 07:50:37.705511 140632426096512 estimator.py:1145] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0517 07:50:37.826712 140632426096512 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe700c7d080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe700c7d080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:37.901885 140632426096512 ag_logging.py:145] Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe700c7d080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe700c7d080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:37.933717 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c7d278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c7d278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:37.981782 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c7d278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c7d278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c7d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c7d1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.036618 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c7d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c7d1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.065545 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bcbd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bcbd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.130361 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bcbd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bcbd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.155188 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c06a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c06a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.199710 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c06a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700c06a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.253837 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7db70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7db70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.278338 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7db70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7db70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.351134 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7dd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7dd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.376790 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7dd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7dd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.439882 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c06940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.466795 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c7d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a4fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a4fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.538480 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a4fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a4fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700993f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700993f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.563308 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700993f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700993f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c5f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c5f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.625809 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c5f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c5f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.650586 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.715945 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008fe908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008fe908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.747737 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008fe908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008fe908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700993f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700993f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.792803 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700993f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700993f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700970be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700970be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.846400 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700970be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700970be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70088a358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70088a358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.871195 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70088a358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70088a358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700809080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700809080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.935514 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700809080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700809080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c59d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c59d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:38.961224 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c59d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700c59d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bc54a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bc54a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.028186 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bc54a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700bc54a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007b9898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007b9898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.053873 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007b9898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007b9898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.120759 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c6e940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700845cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700845cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.146596 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700845cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700845cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.209486 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.235902 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008f0cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7009ae1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7009ae1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.299931 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7009ae1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7009ae1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008ee6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008ee6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.328565 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008ee6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7008ee6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c59d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c59d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.392162 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c59d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700c59d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005c7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005c7a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.418548 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005c7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005c7a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700aa5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700aa5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.464499 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700aa5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe700aa5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7008f06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7008f06d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.529153 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7008f06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7008f06d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005124a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005124a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.555517 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005124a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7005124a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70055d198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70055d198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.623882 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70055d198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70055d198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007a7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007a7fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.650849 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007a7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7007a7fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007a7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007a7fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.715320 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007a7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007a7fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.741385 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700571be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700571be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.815622 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700571be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700571be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.844224 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7006bcac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70092fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70092fcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.907990 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70092fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70092fcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700447f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700447f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.934233 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700447f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700447f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:39.999060 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002f3710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002f3710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.025109 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002f3710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002f3710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700524a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700524a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.069687 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700524a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700524a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700386860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700386860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.128131 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700386860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700386860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.156021 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.220512 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700524ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.247649 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a29da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a29da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.310684 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a29da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700a29da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70046d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70046d828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.337380 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70046d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70046d828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.401096 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe70030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.425941 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700280080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.488069 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.519846 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700167f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700167f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.716516 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700167f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700167f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70030c4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70030c4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.745621 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70030c4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70030c4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe7000702e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe7000702e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.795976 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe7000702e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe7000702e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.850644 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7006a0f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.875870 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617cb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617cb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.951518 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617cb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617cb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:40.976908 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe70024dc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700106198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700106198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.040061 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700106198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700106198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.065078 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe7002292e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7001eff28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7001eff28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.127858 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7001eff28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7001eff28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c61406a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c61406a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.154943 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c61406a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c61406a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617c2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617c2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.218453 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617c2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c617c2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.243448 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c6140860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700152be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700152be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.309813 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700152be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700152be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5fcdf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5fcdf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.337143 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5fcdf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5fcdf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6140c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6140c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.400105 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6140c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6140c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5f32c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5f32c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.425342 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5f32c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5f32c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c60e0e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c60e0e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.469643 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c60e0e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c60e0e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700115dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700115dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.523805 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700115dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700115dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5eaeef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5eaeef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.554547 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5eaeef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5eaeef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e1de80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e1de80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.618442 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e1de80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e1de80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5dee6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5dee6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.646756 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5dee6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5dee6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e72278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e72278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.710411 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e72278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e72278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ed2358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ed2358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.735209 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ed2358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ed2358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6060780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6060780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.803265 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6060780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6060780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5d465f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5d465f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.828662 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5d465f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5d465f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e9e5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e9e5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.893393 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e9e5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e9e5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5caf470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5caf470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.918304 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5caf470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5caf470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5fc03c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5fc03c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:41.981076 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5fc03c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5fc03c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5c35b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5c35b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.011646 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5c35b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5c35b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5d465f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5d465f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.078236 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5d465f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5d465f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5cfdeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5cfdeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.104305 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5cfdeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5cfdeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5d468d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5d468d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.150584 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5d468d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5d468d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.206213 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5e6e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5e6e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.232570 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5e6e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5e6e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.300629 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ddcda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ddcda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.326497 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ddcda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ddcda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.395111 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5adfb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5adfb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.421143 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5adfb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5adfb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.487137 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ad86d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ad86d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.513072 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ad86d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5ad86d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ddcf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ddcf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.585490 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ddcf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ddcf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e1be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e1be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.611804 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e1be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e1be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.678776 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5b34748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.705360 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5a2b7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5a2b7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.772017 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5a2b7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5a2b7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c58e11d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c58e11d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.803128 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c58e11d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c58e11d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5b34748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5b34748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.849481 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5b34748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c5b34748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.907810 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5e58da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c584da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c584da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:42.933744 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c584da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c584da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.001090 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5a76ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5a76ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.026093 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5a76ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5a76ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c59d3320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c59d3320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.094559 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c59d3320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c59d3320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5863cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5863cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.124125 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5863cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5863cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c57adac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c57adac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.191841 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c57adac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c57adac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e19b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e19b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.221443 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e19b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c59e19b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.288991 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c56b1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c56b1c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.315103 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c56b1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c56b1c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c56f0828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c56f0828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.382872 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c56f0828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c56f0828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.408988 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5944e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.461852 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c566df28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c566df28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.517840 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c566df28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c566df28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557eef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557eef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.544282 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557eef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557eef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.622081 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57ad518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57ad518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.649155 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57ad518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57ad518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584db70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584db70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.716386 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584db70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c584db70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c54a1908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c54a1908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.743430 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c54a1908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c54a1908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.813579 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5ca46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c547d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c547d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.838878 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c547d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c547d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.901256 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c575bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c563da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c563da58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.926712 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c563da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c563da58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5863f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5863f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:43.991807 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5863f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5863f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.017061 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c557ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c560eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c560eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.062446 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c560eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe6c560eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.120023 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57445c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57445c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.146669 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57445c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c57445c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.211843 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c549db38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c549db38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.238243 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c549db38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c549db38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.308595 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c58f5eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5368208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5368208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.335600 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5368208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5368208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.399481 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5311c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c51f24e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c51f24e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.425410 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c51f24e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c51f24e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007cba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007cba20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.492175 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007cba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe7007cba20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5561550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5561550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.674770 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5561550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5561550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c560eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c560eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.746542 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c560eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c560eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700bc42b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700bc42b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.775680 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700bc42b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700bc42b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c53d0588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c53d0588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.846318 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c53d0588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c53d0588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52aa908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52aa908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.872253 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52aa908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52aa908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700bc4978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700bc4978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.917384 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700bc4978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe700bc4978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5160668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5160668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:44.975624 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5160668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5160668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5253748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5253748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.003005 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5253748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5253748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700cebdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700cebdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.068422 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700cebdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe700cebdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700b5e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700b5e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.093751 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700b5e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe700b5e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6034e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6034e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.156400 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6034e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c6034e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.184055 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.247333 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.272770 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c52d2ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4fc5518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4fc5518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.339639 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4fc5518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4fc5518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5298fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5298fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.365530 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5298fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c5298fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.430459 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c52aa7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ecc780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ecc780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.455425 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ecc780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ecc780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c50002b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c50002b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.518006 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c50002b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c50002b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4fc59e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4fc59e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.542976 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4fc59e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4fc59e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c500dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c500dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.608006 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c500dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c500dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4d8ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4d8ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.638967 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4d8ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4d8ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4d94630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4d94630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.711800 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4d94630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4d94630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ee5080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ee5080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:45.738139 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ee5080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4ee5080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.306890 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.365960 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.428096 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c45e7e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.431166 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.488365 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.546720 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.549689 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.609976 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4e4a940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4e4a940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.676188 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4e4a940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4e4a940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.679169 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.735538 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.798338 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4604160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.801268 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.862765 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46043c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4507518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4507518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.921800 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4507518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4507518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 07:50:46.925765 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:46.997627 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c46040f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4457908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4457908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 07:50:47.059876 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4457908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c4457908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/variables_helper.py:126: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0517 07:50:47.066992 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/variables_helper.py:126: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0517 07:50:47.068689 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.068802 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.068868 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.068927 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.068984 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/depthwise_weights] is not available in checkpoint\n",
            "W0517 07:50:47.069060 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_1a_7x7/pointwise_weights] is not available in checkpoint\n",
            "W0517 07:50:47.069121 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.069177 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.069247 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.069303 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.069358 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.069414 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.069474 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.069531 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.069591 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.069646 140632426096512 variables_helper.py:144] Variable [InceptionV2/Conv2d_2c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.069700 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.069755 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.069810 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.069865 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.069919 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.069973 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.070051 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.070111 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.070167 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.070220 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.070275 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.070330 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.070384 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.070438 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.070502 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.070559 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.070613 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.070667 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.070722 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.070775 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.070830 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.070884 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.070938 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.070993 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.071063 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.071122 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.071179 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.071234 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.071289 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.071344 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.071398 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.071453 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.071514 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.071568 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.071624 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.071679 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.071733 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.071799 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.071854 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.071909 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.071965 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.072021 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.072093 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.072148 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.072204 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.072259 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.072313 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.072369 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.072423 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.072483 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.072538 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.072593 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.072647 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.072708 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.072762 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.072819 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.072874 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.072928 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.072983 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.073063 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.073126 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.073187 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.073249 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.073309 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.073377 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.073441 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.073515 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.073580 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.073643 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.073709 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.073776 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.073846 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.073915 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.073985 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.074076 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.074149 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.074218 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.074288 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.074358 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.074429 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.074510 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.074582 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.074651 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.074720 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.074790 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.074860 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.074930 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.075003 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.075093 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.075164 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.075246 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.075318 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.075390 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.075460 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.075541 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.075621 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.075708 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.075779 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.075851 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.075921 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.075992 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.076084 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.076155 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.076223 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.076292 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.076364 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.076433 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.076516 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.076588 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.076656 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.076726 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.076795 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.076865 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.076935 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.077003 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.077090 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.077162 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.077233 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.077304 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.077373 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.077444 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.077532 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.077605 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.077674 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.077742 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.077812 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.077881 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.077951 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.078023 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.078114 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.078184 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.078254 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.078324 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.078394 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.078472 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.078543 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.078613 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.078682 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.078751 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.078821 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.078891 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.078970 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.079053 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.079128 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.079212 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.079281 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.079353 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.079423 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.079504 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.079575 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.079646 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.079718 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.079788 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.079857 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.079927 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.079999 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.080088 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.080161 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.080231 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.080302 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.080374 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.080442 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.080522 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.080595 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.080665 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.080735 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.080804 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.080873 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.080943 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.081014 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.081104 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.081176 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.081247 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.081317 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.081389 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.081460 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.081542 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.081612 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.081682 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.081753 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.081822 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.081892 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.081960 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.082056 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.082132 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.082204 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.082275 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.082345 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.082415 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.082492 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.082565 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.082635 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.082705 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.082775 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.082845 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.082914 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.082984 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.083070 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.083143 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.083214 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.083286 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.083352 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.083437 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.083525 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.083596 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.083666 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.083736 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.083806 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.083877 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.083947 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.084018 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.084107 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.084178 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.084249 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.084316 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.084386 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.084456 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.084538 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.084608 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.084678 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.084748 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.084817 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.084887 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.084957 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.085043 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.085119 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.085189 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.085257 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.085326 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.085396 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.085474 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.085548 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.085619 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.085689 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.085792 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.085868 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.085940 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.086012 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.086114 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.086187 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.086258 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.086328 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.086460 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.086574 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.086650 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.086723 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.086794 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.086899 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.086972 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.087059 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.087135 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.087207 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.087278 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.087348 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.087419 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.087497 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.087569 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.087639 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.087710 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.087784 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.087854 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.087925 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.087996 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.088083 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.088156 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.088226 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.088296 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.088366 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.088436 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.088516 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.088587 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.088658 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.088729 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.088798 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.088867 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.088936 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.089007 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.089108 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.089183 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.089254 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.089324 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.089395 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.089472 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.089546 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.089617 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.089688 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.089760 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.089830 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.089900 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.089970 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.090056 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.090130 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.090201 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.090270 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.090339 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.090410 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.090488 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.090562 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.090631 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.090701 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.090771 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.090840 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.090910 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.090981 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.091063 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.091137 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.091207 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.091279 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.091350 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.091420 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.091500 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.091572 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.091643 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.091714 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.091784 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.091855 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.091926 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.091996 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.092083 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.092156 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.092226 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.092293 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.092363 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.092432 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.092511 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights] is not available in checkpoint\n",
            "W0517 07:50:47.092584 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.092651 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.092720 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.092790 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.092860 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights] is not available in checkpoint\n",
            "W0517 07:50:47.092931 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_2_1x1_256/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.093002 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_2_1x1_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.093090 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_2_1x1_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.093163 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_2_1x1_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.093233 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_2_1x1_256/weights] is not available in checkpoint\n",
            "W0517 07:50:47.093303 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_3_1x1_128/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.093380 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_3_1x1_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.093453 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_3_1x1_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.093533 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_3_1x1_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.093605 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_3_1x1_128/weights] is not available in checkpoint\n",
            "W0517 07:50:47.093674 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_4_1x1_128/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.093743 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_4_1x1_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.093811 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_4_1x1_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.093881 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_4_1x1_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.093951 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_4_1x1_128/weights] is not available in checkpoint\n",
            "W0517 07:50:47.094022 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_5_1x1_64/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.094111 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_5_1x1_64/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.094183 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_5_1x1_64/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.094251 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_5_1x1_64/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.094321 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_1_Conv2d_5_1x1_64/weights] is not available in checkpoint\n",
            "W0517 07:50:47.094391 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_2_3x3_s2_512/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.094461 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.094542 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.094613 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.094684 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_2_3x3_s2_512/weights] is not available in checkpoint\n",
            "W0517 07:50:47.094755 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_3_3x3_s2_256/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.094825 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.094893 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.094963 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.095056 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_3_3x3_s2_256/weights] is not available in checkpoint\n",
            "W0517 07:50:47.095131 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_4_3x3_s2_256/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.095202 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.095290 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.095386 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.095455 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_4_3x3_s2_256/weights] is not available in checkpoint\n",
            "W0517 07:50:47.095538 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_5_3x3_s2_128/BatchNorm/beta] is not available in checkpoint\n",
            "W0517 07:50:47.095608 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W0517 07:50:47.095678 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W0517 07:50:47.095749 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W0517 07:50:47.095819 140632426096512 variables_helper.py:144] Variable [InceptionV2/Mixed_5c_2_Conv2d_5_3x3_s2_128/weights] is not available in checkpoint\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:317: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0517 07:50:47.096017 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:317: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:1012: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0517 07:50:48.504533 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:1012: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0517 07:50:48.515451 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/core/losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0517 07:50:48.516649 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/core/losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:341: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0517 07:50:48.750638 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:341: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0517 07:50:48.750986 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/optimizer_builder.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0517 07:50:48.759846 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/optimizer_builder.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0517 07:50:51.056134 140632426096512 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0517 07:50:59.359127 140632426096512 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0517 07:50:59.360527 140632426096512 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0517 07:51:02.883957 140632426096512 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-17 07:51:02.884357: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-05-17 07:51:02.985324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.985877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14904140 executing computations on platform CUDA. Devices:\n",
            "2020-05-17 07:51:02.985915: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-05-17 07:51:02.988063: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-05-17 07:51:02.988247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14904680 executing computations on platform Host. Devices:\n",
            "2020-05-17 07:51:02.988274: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-05-17 07:51:02.988469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.988819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-17 07:51:02.988892: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-17 07:51:02.988916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-17 07:51:02.988937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-17 07:51:02.988958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-17 07:51:02.988985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-17 07:51:02.989014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-17 07:51:02.989050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-17 07:51:02.989134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.989554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.989870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-05-17 07:51:02.989934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-17 07:51:02.990941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-17 07:51:02.990967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-05-17 07:51:02.990985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-05-17 07:51:02.991114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.991500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 07:51:02.991824: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-17 07:51:02.991861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0517 07:51:02.993251 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3177\n",
            "I0517 07:51:02.994540 140632426096512 saver.py:1280] Restoring parameters from training/model.ckpt-3177\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0517 07:51:05.409807 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2020-05-17 07:51:06.440493: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0517 07:51:06.593222 140632426096512 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0517 07:51:06.827501 140632426096512 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 3177 into training/model.ckpt.\n",
            "I0517 07:51:15.720163 140632426096512 basic_session_run_hooks.py:606] Saving checkpoints for 3177 into training/model.ckpt.\n",
            "2020-05-17 07:51:24.205466: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 2.4755154, step = 3177\n",
            "I0517 07:51:26.811578 140632426096512 basic_session_run_hooks.py:262] loss = 2.4755154, step = 3177\n",
            "INFO:tensorflow:global_step/sec: 2.02827\n",
            "I0517 07:52:16.114124 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.02827\n",
            "INFO:tensorflow:loss = 3.5402546, step = 3277 (49.304 sec)\n",
            "I0517 07:52:16.115120 140632426096512 basic_session_run_hooks.py:260] loss = 3.5402546, step = 3277 (49.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1719\n",
            "I0517 07:53:02.156647 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.1719\n",
            "INFO:tensorflow:loss = 4.7151747, step = 3377 (46.042 sec)\n",
            "I0517 07:53:02.157616 140632426096512 basic_session_run_hooks.py:260] loss = 4.7151747, step = 3377 (46.042 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18998\n",
            "I0517 07:53:47.819248 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.18998\n",
            "INFO:tensorflow:loss = 2.9729114, step = 3477 (45.663 sec)\n",
            "I0517 07:53:47.820219 140632426096512 basic_session_run_hooks.py:260] loss = 2.9729114, step = 3477 (45.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.17417\n",
            "I0517 07:54:33.813739 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.17417\n",
            "INFO:tensorflow:loss = 3.306611, step = 3577 (45.995 sec)\n",
            "I0517 07:54:33.814852 140632426096512 basic_session_run_hooks.py:260] loss = 3.306611, step = 3577 (45.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19613\n",
            "I0517 07:55:19.348444 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.19613\n",
            "INFO:tensorflow:loss = 3.2271378, step = 3677 (45.535 sec)\n",
            "I0517 07:55:19.349762 140632426096512 basic_session_run_hooks.py:260] loss = 3.2271378, step = 3677 (45.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18744\n",
            "I0517 07:56:05.064006 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.18744\n",
            "INFO:tensorflow:loss = 3.536709, step = 3777 (45.715 sec)\n",
            "I0517 07:56:05.065134 140632426096512 basic_session_run_hooks.py:260] loss = 3.536709, step = 3777 (45.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1798\n",
            "I0517 07:56:50.939683 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.1798\n",
            "INFO:tensorflow:loss = 2.3556998, step = 3877 (45.876 sec)\n",
            "I0517 07:56:50.940772 140632426096512 basic_session_run_hooks.py:260] loss = 2.3556998, step = 3877 (45.876 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19124\n",
            "I0517 07:57:36.575905 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.19124\n",
            "INFO:tensorflow:loss = 3.358317, step = 3977 (45.636 sec)\n",
            "I0517 07:57:36.577243 140632426096512 basic_session_run_hooks.py:260] loss = 3.358317, step = 3977 (45.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18405\n",
            "I0517 07:58:22.362386 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.18405\n",
            "INFO:tensorflow:loss = 2.6111627, step = 4077 (45.786 sec)\n",
            "I0517 07:58:22.363621 140632426096512 basic_session_run_hooks.py:260] loss = 2.6111627, step = 4077 (45.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.17399\n",
            "I0517 07:59:08.360685 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.17399\n",
            "INFO:tensorflow:loss = 4.1207557, step = 4177 (45.998 sec)\n",
            "I0517 07:59:08.361904 140632426096512 basic_session_run_hooks.py:260] loss = 4.1207557, step = 4177 (45.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18589\n",
            "I0517 07:59:54.108747 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.18589\n",
            "INFO:tensorflow:loss = 2.888707, step = 4277 (45.748 sec)\n",
            "I0517 07:59:54.110075 140632426096512 basic_session_run_hooks.py:260] loss = 2.888707, step = 4277 (45.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18437\n",
            "I0517 08:00:39.888422 140632426096512 basic_session_run_hooks.py:692] global_step/sec: 2.18437\n",
            "INFO:tensorflow:loss = 2.9229927, step = 4377 (45.780 sec)\n",
            "I0517 08:00:39.889733 140632426096512 basic_session_run_hooks.py:260] loss = 2.9229927, step = 4377 (45.780 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4462 into training/model.ckpt.\n",
            "I0517 08:01:18.368761 140632426096512 basic_session_run_hooks.py:606] Saving checkpoints for 4462 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0517 08:01:21.280850 140632426096512 estimator.py:1145] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe5a1596518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe5a1596518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.366173 140632426096512 ag_logging.py:145] Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe5a1596518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fe5a1596518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a156d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a156d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.394616 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a156d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a156d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.431268 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1596630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1596630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.485667 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1596630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1596630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1556f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1556f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.510749 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1556f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1556f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15965c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15965c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.570001 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15965c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15965c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4c6d0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4c6d0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.595837 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4c6d0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c4c6d0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.632416 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a1596d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.686470 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a148fef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a148fef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.711537 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a148fef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a148fef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1509748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1509748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.768348 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1509748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1509748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a143b940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a143b940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.793697 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a143b940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a143b940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.849071 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe6c5bb5780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c440a668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c440a668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.873878 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c440a668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c440a668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.934315 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:21.970143 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.030237 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1572630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1572630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.061871 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1572630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1572630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a13dae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a13dae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.120668 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a13dae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a13dae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1381d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1381d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.150670 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1381d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1381d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1381550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1381550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.188309 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1381550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1381550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.244152 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123ed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123ed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.271314 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123ed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123ed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.332650 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1483a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.361169 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.418835 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a14107f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a14107f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.445343 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a14107f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a14107f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.502280 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a10f62e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a10f62e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.528675 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a10f62e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a10f62e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.588286 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12c2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.615385 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1410080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fcdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fcdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.672249 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fcdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fcdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1062e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1062e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.702937 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1062e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1062e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.762734 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a142f358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a12c2630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a12c2630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.789221 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a12c2630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a12c2630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a143b5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a143b5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.826292 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a143b5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a143b5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12aef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12aef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.882241 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12aef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a12aef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f6f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f6f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.907502 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f6f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f6f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.970777 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123e0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123e0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:22.999774 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123e0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a123e0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.060160 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f88908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f88908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.086754 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f88908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0f88908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0edd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0edd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.143604 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0edd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0edd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.171476 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.227723 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11fc240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.253461 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a1095a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0eddac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0eddac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.308477 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0eddac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0eddac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.334584 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a0edd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a0edd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.373149 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a0edd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a0edd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1095d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1095d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.428279 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1095d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1095d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0cb8710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0cb8710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.453205 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0cb8710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0cb8710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.513470 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db50f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db50f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.538941 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db50f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0db50f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11bdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11bdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.597125 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11bdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a11bdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b8fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b8fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.623004 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b8fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b8fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c57b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c57b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.678255 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c57b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c57b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd8160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd8160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.703639 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd8160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd8160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.760994 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bb2dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bb2dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.786664 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bb2dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bb2dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c76e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c76e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.842273 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c76e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0c76e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b7af98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b7af98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.868385 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b7af98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0b7af98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.905364 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1062860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1062860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0d19eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0d19eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.962322 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0d19eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0d19eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:23.993628 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.055305 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c507cb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c507cb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.087544 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c507cb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe6c507cb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0bd8b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0bd8b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.160778 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0bd8b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0bd8b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa32b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa32b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.191551 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa32b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa32b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0ed6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0ed6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.249993 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0ed6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0ed6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.277544 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0bd80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0a33320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0a33320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.335530 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0a33320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0a33320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08ca978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.365026 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08ca978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1573630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1573630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.428813 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1573630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1573630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.455054 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0aa5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0934320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0934320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.514119 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0934320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0934320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a09a0f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a09a0f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.540503 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a09a0f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a09a0f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a08f12e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a08f12e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.578001 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a08f12e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a08f12e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa3908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.639092 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0aa3908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a07109b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a07109b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.670546 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a07109b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a07109b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.730353 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.758617 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07ea438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07ea438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.817099 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07ea438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07ea438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.843390 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0a33da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a074f320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a074f320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.900365 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a074f320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a074f320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08caf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08caf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.926682 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08caf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a08caf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:24.985972 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a09a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05ef320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05ef320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.017080 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05ef320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05ef320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0663b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0663b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.075699 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0663b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0663b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05b6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05b6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.105295 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05b6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a05b6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.160741 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1306ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.192234 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a0907320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a0907320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.229450 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a0907320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a0907320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a064cbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a064cbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.284636 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a064cbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a064cbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0710710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0710710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.309951 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0710710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0710710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0556da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0556da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.368294 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0556da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0556da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a064cb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a064cb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.394715 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a064cb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a064cb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.449706 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a04cf550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a04cf550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.475140 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a04cf550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a04cf550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a05b6f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a05b6f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.530509 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a05b6f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a05b6f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0343518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0343518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.555530 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0343518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0343518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a038cf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a038cf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.615361 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a038cf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a038cf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a02dccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a02dccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.641853 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a02dccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a02dccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0b8f5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0b8f5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.697555 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0b8f5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0b8f5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.723004 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a060b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.781161 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0271eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0271eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.807123 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0271eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0271eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1306ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1306ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.843313 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1306ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a1306ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.897849 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a049a908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a01d8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a01d8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.923006 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a01d8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a01d8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:25.982149 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a016c278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a016c278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.008965 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a016c278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a016c278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.073068 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a00e6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a00e6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.103660 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a00e6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a00e6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a01d8dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a01d8dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.159854 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a01d8dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a01d8dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.187537 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.243544 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0271f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.269371 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.324855 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0218eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.350385 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0096e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a045e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a045e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.392505 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a045e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe5a045e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0253550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0253550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.450277 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0253550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0253550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e7e09e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e7e09e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.476114 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e7e09e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e7e09e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0022f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0022f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.531508 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0022f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0022f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.557086 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a012b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a050deb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a050deb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.614702 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a050deb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a050deb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.640519 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.696984 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.722383 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe5a0140a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a016c630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a016c630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.779186 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a016c630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a016c630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.805416 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0612a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0612a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.860712 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0612a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a0612a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e575be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e575be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.887761 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e575be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e575be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a00e6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a00e6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.924445 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a00e6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fe5a00e6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:26.979054 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4d9b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4d9b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.006128 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4d9b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4d9b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e451668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e451668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.073129 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e451668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e451668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4df128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4df128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.115629 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4df128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4df128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.177834 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e5d3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4a93c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4a93c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.203676 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4a93c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e4a93c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e4a93c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e4a93c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.259974 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e4a93c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e4a93c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e379cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e379cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.289182 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e379cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e379cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e58e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e58e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.346539 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e58e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e58e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.372846 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.429568 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e69ce48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.456226 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e64ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e376d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e376d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.519776 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e376d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e376d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.552291 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe59e2e4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe59e2e4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.597161 140632426096512 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe59e2e4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe59e2e4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e2a67b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e2a67b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.659237 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e2a67b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e2a67b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2380b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2380b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.689783 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2380b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2380b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15962b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15962b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.748593 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15962b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15962b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e13a278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e13a278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.775100 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e13a278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e13a278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1556f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1556f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.835244 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1556f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1556f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2e8cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2e8cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.862074 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2e8cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e2e8cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07a78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07a78d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.926117 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07a78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a07a78d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e0f6fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e0f6fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:27.952238 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e0f6fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e0f6fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15963c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15963c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.010516 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15963c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a15963c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e3049b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e3049b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.036544 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e3049b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e3049b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1514b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1514b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.098604 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1514b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe5a1514b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59dfcdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59dfcdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.132098 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59dfcdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59dfcdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.191298 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.217351 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e39a128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.275975 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e10ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e002940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e002940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.302304 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e002940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59e002940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e39a160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e39a160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.358021 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e39a160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59e39a160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59df074e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59df074e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:28.383409 140632426096512 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59df074e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe59df074e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:28.961179 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.021707 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.082302 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:29.085293 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d6047b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d6047b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.156885 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d6047b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d6047b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5df2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5df2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.226510 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5df2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5df2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:29.229801 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.290687 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d604c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d59b6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d59b6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.351051 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d59b6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d59b6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:29.353962 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5954a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5954a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.413476 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5954a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d5954a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d595470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d595470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.473198 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d595470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d595470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:29.476125 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59df81c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59df81c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.532808 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59df81c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59df81c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.598696 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0517 08:01:29.601902 140632426096512 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.658830 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0517 08:01:29.718665 140632426096512 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe59d43b780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 08:01:30.326718 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0517 08:01:30.510702 140632426096512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0517 08:01:30.693018 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:441: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0517 08:01:30.786046 140632426096512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:441: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0517 08:01:31.533432 140632426096512 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-17T08:01:31Z\n",
            "I0517 08:01:31.551410 140632426096512 evaluation.py:255] Starting evaluation at 2020-05-17T08:01:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0517 08:01:32.072836 140632426096512 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-17 08:01:32.074242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 08:01:32.074576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-17 08:01:32.074679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-17 08:01:32.074707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-17 08:01:32.074733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-17 08:01:32.074757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-17 08:01:32.074783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-17 08:01:32.074807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-17 08:01:32.074832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-17 08:01:32.074917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 08:01:32.075323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 08:01:32.075587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-05-17 08:01:32.075725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-17 08:01:32.075740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-05-17 08:01:32.075750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-05-17 08:01:32.075853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 08:01:32.076185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-17 08:01:32.076459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4462\n",
            "I0517 08:01:32.077521 140632426096512 saver.py:1280] Restoring parameters from training/model.ckpt-4462\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0517 08:01:33.143832 140632426096512 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0517 08:01:33.262046 140632426096512 session_manager.py:502] Done running local_init_op.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0517 08:01:37.671256 140628688082688 coco_tools.py:109] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0517 08:01:37.673788 140628688082688 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "2020-05-17 08:01:37.677470: W tensorflow/core/framework/op_kernel.cc:1490] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 358, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 209, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_tools.py\", line 170, in __init__\n",
            "    iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/evaluation.py\", line 272, in _evaluate_once\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1252, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1353, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1338, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1411, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1169, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n",
            "\t [[node IteratorGetNext (defined at model_main.py:108) ]]\n",
            "\n",
            "Original stack trace for 'IteratorGetNext':\n",
            "  File \"model_main.py\", line 112, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 108, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1192, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1484, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1252, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1338, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1419, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 477, in evaluate\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 519, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 501, in _evaluate\n",
            "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1501, in _evaluate_build_graph\n",
            "    self._call_model_fn_eval(input_fn, self.config))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1534, in _call_model_fn_eval\n",
            "    input_fn, ModeKeys.EVAL)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1022, in _get_features_and_labels_from_input_fn\n",
            "    self._call_input_fn(input_fn, mode))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n",
            "    result = iterator.get_next()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 426, in get_next\n",
            "    output_shapes=self._structure._flat_shapes, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1947, in iterator_get_next\n",
            "    output_shapes=output_shapes, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 358, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 209, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_tools.py\", line 170, in __init__\n",
            "    iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc_3}}]]\n",
            "\t [[cond_3/Detections_Left_Groundtruth_Right/3/_2989]]\n",
            "  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 358, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 209, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_tools.py\", line 170, in __init__\n",
            "    iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc_3}}]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"model_main.py\", line 112, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 108, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1192, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1484, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1252, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1353, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1338, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1419, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 477, in evaluate\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 519, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 508, in _evaluate\n",
            "    output_dir=self.eval_dir(name))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1609, in _evaluate_run\n",
            "    config=self._session_config)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/evaluation.py\", line 272, in _evaluate_once\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 854, in __exit__\n",
            "    self._close_internal(exception_type)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 887, in _close_internal\n",
            "    h.end(self._coordinated_creator.tf_sess)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 951, in end\n",
            "    self._final_ops, feed_dict=self._final_ops_feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 358, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 209, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_tools.py\", line 170, in __init__\n",
            "    iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[node PyFunc_3 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py:368) ]]\n",
            "\t [[cond_3/Detections_Left_Groundtruth_Right/3/_2989]]\n",
            "  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 358, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 209, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_tools.py\", line 170, in __init__\n",
            "    iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[node PyFunc_3 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py:368) ]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "Original stack trace for 'PyFunc_3':\n",
            "  File \"model_main.py\", line 112, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 108, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1192, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1484, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1252, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1338, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1419, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 477, in evaluate\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 519, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 501, in _evaluate\n",
            "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1501, in _evaluate_build_graph\n",
            "    self._call_model_fn_eval(input_fn, self.config))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _call_model_fn_eval\n",
            "    features, labels, ModeKeys.EVAL, config)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n",
            "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py\", line 439, in model_fn\n",
            "    eval_config, list(category_index.values()), eval_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py\", line 881, in get_eval_metric_ops_for_evaluators\n",
            "    eval_dict))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/metrics/coco_evaluation.py\", line 368, in get_estimator_eval_metric_ops\n",
            "    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 480, in py_func\n",
            "    return py_func_common(func, inp, Tout, stateful, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 462, in py_func_common\n",
            "    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 285, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 159, in py_func\n",
            "    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rol32jADaGZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}